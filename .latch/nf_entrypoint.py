import glob
import json
import os
import re
import shutil
import stat
import subprocess
import sys
import time
import traceback
import typing
from dataclasses import asdict, dataclass, fields, is_dataclass
from enum import Enum
from itertools import chain, repeat
from pathlib import Path
from subprocess import CalledProcessError
from typing import Dict, List, NamedTuple

from flytekit.extras.persistence import LatchPersistence
from latch_cli.extras.nextflow.file_persistence import download_files, upload_files
from latch_cli.extras.nextflow.workflow import get_flags
from latch_cli.extras.nextflow.channel import get_mapper_inputs, get_boolean_value, get_mapper_outputs
from latch_cli.utils import check_exists_and_rename, get_parameter_json_value, urljoins
from latch_cli.utils.workflow import _override_task_status

from latch.resources.tasks import custom_task
from latch.types.directory import LatchDir, LatchOutputDir
from latch.types.file import LatchFile

sys.stdout.reconfigure(line_buffering=True)
sys.stderr.reconfigure(line_buffering=True)

task = custom_task(cpu=-1, memory=-1) # these limits are a lie and are ignored when generating the task spec

from latch_metadata.parameters import construct_samplesheet
@dataclass
class Sample:
    sample: typing.Union[str, None]
    fastq_1: typing.Union[LatchFile, None]
    fastq_2: typing.Union[LatchFile, None]


class Genome(Enum):
    GRCh37 = 'GRCh37'
    GRCh38 = 'GRCh38'
    mm10 = 'mm10'


class Aligner(Enum):
    bismark = 'bismark'
    bwameth = 'bwameth'




class Res_params_aligner____bismark__710(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def _params_aligner____bismark__710(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str
) -> Res_params_aligner____bismark__710:
    cond = True

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = []



        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome.nf', '-lib', 'lib', '-entry', 'PREPARE_GENOME', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"BinaryExpression":{"leftExpression":{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"aligner"}},"operation":"==","rightExpression":{"ConstantExpression":"bismark"}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Res_params_aligner____bismark__710(
        res=out_channels.get("res")
    )


class Res_params_aligner____bismark_hisat__711(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def _params_aligner____bismark_hisat__711(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str
) -> Res_params_aligner____bismark_hisat__711:
    cond = True

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = []



        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome.nf', '-lib', 'lib', '-entry', 'PREPARE_GENOME', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"BinaryExpression":{"leftExpression":{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"aligner"}},"operation":"==","rightExpression":{"ConstantExpression":"bismark_hisat"}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Res_params_aligner____bismark_hisat__711(
        res=out_channels.get("res")
    )


class Res__params_aligner____bismark______params_aligner____bismark_hisat_712(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def __params_aligner____bismark______params_aligner____bismark_hisat_712(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    channel_710: typing.Union[str, None],
    channel_711: typing.Union[str, None]
) -> Res__params_aligner____bismark______params_aligner____bismark_hisat_712:
    cond = ((channel_710 is not None) and (channel_711 is not None))

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = [json.loads(channel_710), json.loads(channel_711)]



        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome.nf', '-lib', 'lib', '-entry', 'PREPARE_GENOME', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"binaryOp","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"ConstantExpression":"||"}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Res__params_aligner____bismark______params_aligner____bismark_hisat_712(
        res=out_channels.get("res")
    )


class Res__params_aligner____bismark______params_aligner____bismark_hisat_713(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def __params_aligner____bismark______params_aligner____bismark_hisat_713(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    channel_712: typing.Union[str, None]
) -> Res__params_aligner____bismark______params_aligner____bismark_hisat_713:
    cond = ((channel_712 is not None))

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = [json.loads(channel_712)]



        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome.nf', '-lib', 'lib', '-entry', 'PREPARE_GENOME', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"toBoolean","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Res__params_aligner____bismark______params_aligner____bismark_hisat_713(
        res=out_channels.get("res")
    )


class Resconditional___params_aligner____bismark______params_aligner____bismark_hisat_714(NamedTuple):
    condition: typing.Union[bool, None]

@task(cache=True)
def conditional___params_aligner____bismark______params_aligner____bismark_hisat_714(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    channel_713: typing.Union[str, None]
) -> Resconditional___params_aligner____bismark______params_aligner____bismark_hisat_714:
    cond = ((channel_713 is not None))

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = [json.loads(channel_713)]



        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome.nf', '-lib', 'lib', '-entry', 'PREPARE_GENOME', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"condition"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"condition\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'condition': None}

    res = out_channels.get("condition")

    if res is not None:
        res = get_boolean_value(res)

    return Resconditional___params_aligner____bismark______params_aligner____bismark_hisat_714(condition=res)


class Resparams_bismark_index_715(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def params_bismark_index_715(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_714: typing.Union[bool, None]
) -> Resparams_bismark_index_715:
    cond = ((condition_714 == True))

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = []



        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome.nf', '-lib', 'lib', '-entry', 'PREPARE_GENOME', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"NotExpression":{"NotExpression":{"BooleanExpression":{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"bismark_index"}}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resparams_bismark_index_715(
        res=out_channels.get("res")
    )


class Resconditional_params_bismark_index_716(NamedTuple):
    condition: typing.Union[bool, None]

@task(cache=True)
def conditional_params_bismark_index_716(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_714: typing.Union[bool, None],
    channel_715: typing.Union[str, None]
) -> Resconditional_params_bismark_index_716:
    cond = ((condition_714 == True) and (channel_715 is not None))

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = [json.loads(channel_715)]



        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome.nf', '-lib', 'lib', '-entry', 'PREPARE_GENOME', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"condition"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"condition\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'condition': None}

    res = out_channels.get("condition")

    if res is not None:
        res = get_boolean_value(res)

    return Resconditional_params_bismark_index_716(condition=res)


class Resparams_bismark_index_endsWith__gz__717(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def params_bismark_index_endsWith__gz__717(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_714: typing.Union[bool, None],
    condition_716: typing.Union[bool, None]
) -> Resparams_bismark_index_endsWith__gz__717:
    cond = ((condition_714 == True) and (condition_716 == True))

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = []



        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome.nf', '-lib', 'lib', '-entry', 'PREPARE_GENOME', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"bismark_index"}},"method":"endsWith","arguments":{"ArgumentListExpression":{"expressions":[{"ConstantExpression":".gz"}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resparams_bismark_index_endsWith__gz__717(
        res=out_channels.get("res")
    )


class Resparams_bismark_index_endsWith__gz__718(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def params_bismark_index_endsWith__gz__718(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_714: typing.Union[bool, None],
    condition_716: typing.Union[bool, None],
    channel_717: typing.Union[str, None]
) -> Resparams_bismark_index_endsWith__gz__718:
    cond = ((condition_714 == True) and (condition_716 == True) and (channel_717 is not None))

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = [json.loads(channel_717)]



        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome.nf', '-lib', 'lib', '-entry', 'PREPARE_GENOME', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"toBoolean","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resparams_bismark_index_endsWith__gz__718(
        res=out_channels.get("res")
    )


class Resconditional_params_bismark_index_endsWith__gz__719(NamedTuple):
    condition: typing.Union[bool, None]

@task(cache=True)
def conditional_params_bismark_index_endsWith__gz__719(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_714: typing.Union[bool, None],
    condition_716: typing.Union[bool, None],
    channel_718: typing.Union[str, None]
) -> Resconditional_params_bismark_index_endsWith__gz__719:
    cond = ((condition_714 == True) and (condition_716 == True) and (channel_718 is not None))

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = [json.loads(channel_718)]



        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome.nf', '-lib', 'lib', '-entry', 'PREPARE_GENOME', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"condition"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"condition\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'condition': None}

    res = out_channels.get("condition")

    if res is not None:
        res = get_boolean_value(res)

    return Resconditional_params_bismark_index_endsWith__gz__719(condition=res)


class Resthis_file_params_bismark_index__720(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def this_file_params_bismark_index__720(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_714: typing.Union[bool, None],
    condition_716: typing.Union[bool, None],
    condition_719: typing.Union[bool, None]
) -> Resthis_file_params_bismark_index__720:
    cond = ((condition_714 == True) and (condition_716 == True) and (condition_719 == True))

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = []



        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome.nf', '-lib', 'lib', '-entry', 'PREPARE_GENOME', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"file","arguments":{"ArgumentListExpression":{"expressions":[{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"bismark_index"}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resthis_file_params_bismark_index__720(
        res=out_channels.get("res")
    )


class Res______this_file_params_bismark_index___721(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def ______this_file_params_bismark_index___721(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_714: typing.Union[bool, None],
    condition_716: typing.Union[bool, None],
    condition_719: typing.Union[bool, None],
    channel_720: typing.Union[str, None]
) -> Res______this_file_params_bismark_index___721:
    cond = ((condition_714 == True) and (condition_716 == True) and (condition_719 == True) and (channel_720 is not None))

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = [json.loads(channel_720)]



        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome.nf', '-lib', 'lib', '-entry', 'PREPARE_GENOME', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"ListExpression":[{"MapExpression":[]},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Res______this_file_params_bismark_index___721(
        res=out_channels.get("res")
    )


@dataclass
class Dataclass_722_pre:
    wf_input: typing.List[Sample]
    wf_genome: Genome
    wf_save_reference: bool
    wf_save_align_intermeds: bool
    wf_aligner: Aligner
    wf_clip_r1: int
    wf_clip_r2: int
    wf_three_prime_clip_r1: int
    wf_three_prime_clip_r2: int
    wf_nextseq_trim: int
    wf_cytosine_report: bool
    wf_num_mismatches: float
    wf_skip_trimming: bool
    wf_skip_deduplication: bool
    wf_skip_multiqc: bool
    wf_outdir: str
    channel_721: str


class Res_722_pre(NamedTuple):
    default: typing.List[Dataclass_722_pre]
    is_skipped: bool

@task(cache=True)
def pre_adapter_UNTAR_722_pre(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_714: typing.Union[bool, None],
    condition_716: typing.Union[bool, None],
    condition_719: typing.Union[bool, None],
    channel_721: typing.Union[str, None]
) -> Res_722_pre:
    cond = ((condition_714 == True) and (condition_716 == True) and (condition_719 == True) and (channel_721 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_722_pre, {'wf_input': wf_input, 'wf_genome': wf_genome, 'wf_save_reference': wf_save_reference, 'wf_save_align_intermeds': wf_save_align_intermeds, 'wf_aligner': wf_aligner, 'wf_clip_r1': wf_clip_r1, 'wf_clip_r2': wf_clip_r2, 'wf_three_prime_clip_r1': wf_three_prime_clip_r1, 'wf_three_prime_clip_r2': wf_three_prime_clip_r2, 'wf_nextseq_trim': wf_nextseq_trim, 'wf_cytosine_report': wf_cytosine_report, 'wf_num_mismatches': wf_num_mismatches, 'wf_skip_trimming': wf_skip_trimming, 'wf_skip_deduplication': wf_skip_deduplication, 'wf_skip_multiqc': wf_skip_multiqc, 'wf_outdir': wf_outdir}, {'channel_721': channel_721})
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        result = []

    return Res_722_pre(default=result, is_skipped = not cond)

class Respost_adapter_UNTAR_722_post(NamedTuple):
    untar: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_722_post:
    untar: str
    versions: str

@task(cache=True)
def post_adapter_UNTAR_722_post(
    default: List[Dataclass_722_post],
    is_skipped: bool,
) -> Respost_adapter_UNTAR_722_post:
    return get_mapper_outputs(Respost_adapter_UNTAR_722_post, default, is_skipped)


def _read_resources() -> Dict:
    try:
        with open(".latch/resources.json") as f:
            return json.load(f)
    except FileNotFoundError:
        return {}

def allocate_cpu(default: Dataclass_722_pre) -> int:
    res = _read_resources()
    return max(1, res['cpu_cores']) if res.get('cpu_cores') is not None else 4

def allocate_memory(default: Dataclass_722_pre) -> int:
    res = _read_resources()
    return max(1, res['memory_bytes'] // 1024**3) if res.get('memory_bytes') is not None else 16

def allocate_disk(default: Dataclass_722_pre) -> int:
    res = _read_resources()
    return max(1, res['disk_bytes'] // 1024**3) if res.get('disk_bytes') is not None else 4800

def get_resources(default: Dataclass_722_pre):
    wf_paths = {}
    wf_input = default.wf_input
    wf_input = construct_samplesheet(wf_input)
    wf_genome = default.wf_genome
    wf_save_reference = default.wf_save_reference
    wf_save_align_intermeds = default.wf_save_align_intermeds
    wf_aligner = default.wf_aligner
    wf_clip_r1 = default.wf_clip_r1
    wf_clip_r2 = default.wf_clip_r2
    wf_three_prime_clip_r1 = default.wf_three_prime_clip_r1
    wf_three_prime_clip_r2 = default.wf_three_prime_clip_r2
    wf_nextseq_trim = default.wf_nextseq_trim
    wf_cytosine_report = default.wf_cytosine_report
    wf_num_mismatches = default.wf_num_mismatches
    wf_skip_trimming = default.wf_skip_trimming
    wf_skip_deduplication = default.wf_skip_deduplication
    wf_skip_multiqc = default.wf_skip_multiqc
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_721)]

    if not True:
        download_files(channel_vals, LatchDir('latch:///methylseq-outputs'))

    flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/local/prepare_genome.nf','-lib','lib','-profile','mamba','-entry','PREPARE_GENOME', *flags],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"UNTAR","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"untar\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"UNTAR\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"UNTAR\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'True',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

@custom_task(cpu=allocate_cpu, memory=allocate_memory, storage_gib=allocate_disk, pre_execute=get_resources, cache=True)
def UNTAR_722(
    default: Dataclass_722_pre
) -> Dataclass_722_post:
    wf_paths = {}
    wf_input = default.wf_input
    wf_input = construct_samplesheet(wf_input)
    wf_genome = default.wf_genome
    wf_save_reference = default.wf_save_reference
    wf_save_align_intermeds = default.wf_save_align_intermeds
    wf_aligner = default.wf_aligner
    wf_clip_r1 = default.wf_clip_r1
    wf_clip_r2 = default.wf_clip_r2
    wf_three_prime_clip_r1 = default.wf_three_prime_clip_r1
    wf_three_prime_clip_r2 = default.wf_three_prime_clip_r2
    wf_nextseq_trim = default.wf_nextseq_trim
    wf_cytosine_report = default.wf_cytosine_report
    wf_num_mismatches = default.wf_num_mismatches
    wf_skip_trimming = default.wf_skip_trimming
    wf_skip_deduplication = default.wf_skip_deduplication
    wf_skip_multiqc = default.wf_skip_multiqc
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_721)]

    if not False:
        download_files(channel_vals, LatchDir('latch:///methylseq-outputs'))

    flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/local/prepare_genome.nf','-lib','lib','-profile','mamba','-entry','PREPARE_GENOME', *flags],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"UNTAR","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"untar\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"UNTAR\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"UNTAR\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'False',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = json.loads(file.read_text())

    print(out_channels)

    publish_dir = None
    upload_files(out_channels, LatchDir('latch:///methylseq-outputs'), publish_dir)

    out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    return Dataclass_722_post(
        untar=out_channels.get(f"untar"),
        versions=out_channels.get(f"versions")
    )


class Res_params_aligner____bwameth__730(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def _params_aligner____bwameth__730(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_714: typing.Union[bool, None]
) -> Res_params_aligner____bwameth__730:
    cond = ((condition_714 == False))

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = []



        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome.nf', '-lib', 'lib', '-entry', 'PREPARE_GENOME', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"BinaryExpression":{"leftExpression":{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"aligner"}},"operation":"==","rightExpression":{"ConstantExpression":"bwameth"}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Res_params_aligner____bwameth__730(
        res=out_channels.get("res")
    )


class Res_params_aligner____bwameth__731(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def _params_aligner____bwameth__731(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_714: typing.Union[bool, None],
    channel_730: typing.Union[str, None]
) -> Res_params_aligner____bwameth__731:
    cond = ((condition_714 == False) and (channel_730 is not None))

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = [json.loads(channel_730)]



        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome.nf', '-lib', 'lib', '-entry', 'PREPARE_GENOME', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"toBoolean","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Res_params_aligner____bwameth__731(
        res=out_channels.get("res")
    )


class Resconditional__params_aligner____bwameth__732(NamedTuple):
    condition: typing.Union[bool, None]

@task(cache=True)
def conditional__params_aligner____bwameth__732(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_714: typing.Union[bool, None],
    channel_731: typing.Union[str, None]
) -> Resconditional__params_aligner____bwameth__732:
    cond = ((condition_714 == False) and (channel_731 is not None))

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = [json.loads(channel_731)]



        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome.nf', '-lib', 'lib', '-entry', 'PREPARE_GENOME', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"condition"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"condition\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'condition': None}

    res = out_channels.get("condition")

    if res is not None:
        res = get_boolean_value(res)

    return Resconditional__params_aligner____bwameth__732(condition=res)


class Resparams_bwa_meth_index_733(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def params_bwa_meth_index_733(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_714: typing.Union[bool, None],
    condition_732: typing.Union[bool, None]
) -> Resparams_bwa_meth_index_733:
    cond = ((condition_714 == False) and (condition_732 == True))

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = []



        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome.nf', '-lib', 'lib', '-entry', 'PREPARE_GENOME', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"NotExpression":{"NotExpression":{"BooleanExpression":{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"bwa_meth_index"}}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resparams_bwa_meth_index_733(
        res=out_channels.get("res")
    )


class Resconditional_params_bwa_meth_index_734(NamedTuple):
    condition: typing.Union[bool, None]

@task(cache=True)
def conditional_params_bwa_meth_index_734(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_714: typing.Union[bool, None],
    condition_732: typing.Union[bool, None],
    channel_733: typing.Union[str, None]
) -> Resconditional_params_bwa_meth_index_734:
    cond = ((condition_714 == False) and (condition_732 == True) and (channel_733 is not None))

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = [json.loads(channel_733)]



        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome.nf', '-lib', 'lib', '-entry', 'PREPARE_GENOME', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"condition"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"condition\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'condition': None}

    res = out_channels.get("condition")

    if res is not None:
        res = get_boolean_value(res)

    return Resconditional_params_bwa_meth_index_734(condition=res)


class Resparams_bwa_meth_index_endsWith__tar_gz__735(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def params_bwa_meth_index_endsWith__tar_gz__735(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_714: typing.Union[bool, None],
    condition_732: typing.Union[bool, None],
    condition_734: typing.Union[bool, None]
) -> Resparams_bwa_meth_index_endsWith__tar_gz__735:
    cond = ((condition_714 == False) and (condition_732 == True) and (condition_734 == True))

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = []



        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome.nf', '-lib', 'lib', '-entry', 'PREPARE_GENOME', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"bwa_meth_index"}},"method":"endsWith","arguments":{"ArgumentListExpression":{"expressions":[{"ConstantExpression":".tar.gz"}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resparams_bwa_meth_index_endsWith__tar_gz__735(
        res=out_channels.get("res")
    )


class Resparams_bwa_meth_index_endsWith__tar_gz__736(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def params_bwa_meth_index_endsWith__tar_gz__736(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_714: typing.Union[bool, None],
    condition_732: typing.Union[bool, None],
    condition_734: typing.Union[bool, None],
    channel_735: typing.Union[str, None]
) -> Resparams_bwa_meth_index_endsWith__tar_gz__736:
    cond = ((condition_714 == False) and (condition_732 == True) and (condition_734 == True) and (channel_735 is not None))

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = [json.loads(channel_735)]



        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome.nf', '-lib', 'lib', '-entry', 'PREPARE_GENOME', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"toBoolean","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resparams_bwa_meth_index_endsWith__tar_gz__736(
        res=out_channels.get("res")
    )


class Resconditional_params_bwa_meth_index_endsWith__tar_gz__737(NamedTuple):
    condition: typing.Union[bool, None]

@task(cache=True)
def conditional_params_bwa_meth_index_endsWith__tar_gz__737(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_714: typing.Union[bool, None],
    condition_732: typing.Union[bool, None],
    condition_734: typing.Union[bool, None],
    channel_736: typing.Union[str, None]
) -> Resconditional_params_bwa_meth_index_endsWith__tar_gz__737:
    cond = ((condition_714 == False) and (condition_732 == True) and (condition_734 == True) and (channel_736 is not None))

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = [json.loads(channel_736)]



        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome.nf', '-lib', 'lib', '-entry', 'PREPARE_GENOME', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"condition"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"condition\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'condition': None}

    res = out_channels.get("condition")

    if res is not None:
        res = get_boolean_value(res)

    return Resconditional_params_bwa_meth_index_endsWith__tar_gz__737(condition=res)


class Resthis_file_params_bwa_meth_index__738(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def this_file_params_bwa_meth_index__738(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_714: typing.Union[bool, None],
    condition_732: typing.Union[bool, None],
    condition_734: typing.Union[bool, None],
    condition_737: typing.Union[bool, None]
) -> Resthis_file_params_bwa_meth_index__738:
    cond = ((condition_714 == False) and (condition_732 == True) and (condition_734 == True) and (condition_737 == True))

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = []



        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome.nf', '-lib', 'lib', '-entry', 'PREPARE_GENOME', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"file","arguments":{"ArgumentListExpression":{"expressions":[{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"bwa_meth_index"}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resthis_file_params_bwa_meth_index__738(
        res=out_channels.get("res")
    )


class Res______this_file_params_bwa_meth_index___739(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def ______this_file_params_bwa_meth_index___739(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_714: typing.Union[bool, None],
    condition_732: typing.Union[bool, None],
    condition_734: typing.Union[bool, None],
    condition_737: typing.Union[bool, None],
    channel_738: typing.Union[str, None]
) -> Res______this_file_params_bwa_meth_index___739:
    cond = ((condition_714 == False) and (condition_732 == True) and (condition_734 == True) and (condition_737 == True) and (channel_738 is not None))

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = [json.loads(channel_738)]



        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome.nf', '-lib', 'lib', '-entry', 'PREPARE_GENOME', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"ListExpression":[{"MapExpression":[]},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Res______this_file_params_bwa_meth_index___739(
        res=out_channels.get("res")
    )


@dataclass
class Dataclass_740_pre:
    wf_input: typing.List[Sample]
    wf_genome: Genome
    wf_save_reference: bool
    wf_save_align_intermeds: bool
    wf_aligner: Aligner
    wf_clip_r1: int
    wf_clip_r2: int
    wf_three_prime_clip_r1: int
    wf_three_prime_clip_r2: int
    wf_nextseq_trim: int
    wf_cytosine_report: bool
    wf_num_mismatches: float
    wf_skip_trimming: bool
    wf_skip_deduplication: bool
    wf_skip_multiqc: bool
    wf_outdir: str
    channel_739: str


class Res_740_pre(NamedTuple):
    default: typing.List[Dataclass_740_pre]
    is_skipped: bool

@task(cache=True)
def pre_adapter_UNTAR_740_pre(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_714: typing.Union[bool, None],
    condition_732: typing.Union[bool, None],
    condition_734: typing.Union[bool, None],
    condition_737: typing.Union[bool, None],
    channel_739: typing.Union[str, None]
) -> Res_740_pre:
    cond = ((condition_714 == False) and (condition_732 == True) and (condition_734 == True) and (condition_737 == True) and (channel_739 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_740_pre, {'wf_input': wf_input, 'wf_genome': wf_genome, 'wf_save_reference': wf_save_reference, 'wf_save_align_intermeds': wf_save_align_intermeds, 'wf_aligner': wf_aligner, 'wf_clip_r1': wf_clip_r1, 'wf_clip_r2': wf_clip_r2, 'wf_three_prime_clip_r1': wf_three_prime_clip_r1, 'wf_three_prime_clip_r2': wf_three_prime_clip_r2, 'wf_nextseq_trim': wf_nextseq_trim, 'wf_cytosine_report': wf_cytosine_report, 'wf_num_mismatches': wf_num_mismatches, 'wf_skip_trimming': wf_skip_trimming, 'wf_skip_deduplication': wf_skip_deduplication, 'wf_skip_multiqc': wf_skip_multiqc, 'wf_outdir': wf_outdir}, {'channel_739': channel_739})
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        result = []

    return Res_740_pre(default=result, is_skipped = not cond)

class Respost_adapter_UNTAR_740_post(NamedTuple):
    untar: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_740_post:
    untar: str
    versions: str

@task(cache=True)
def post_adapter_UNTAR_740_post(
    default: List[Dataclass_740_post],
    is_skipped: bool,
) -> Respost_adapter_UNTAR_740_post:
    return get_mapper_outputs(Respost_adapter_UNTAR_740_post, default, is_skipped)


def _read_resources() -> Dict:
    try:
        with open(".latch/resources.json") as f:
            return json.load(f)
    except FileNotFoundError:
        return {}

def allocate_cpu(default: Dataclass_740_pre) -> int:
    res = _read_resources()
    return max(1, res['cpu_cores']) if res.get('cpu_cores') is not None else 4

def allocate_memory(default: Dataclass_740_pre) -> int:
    res = _read_resources()
    return max(1, res['memory_bytes'] // 1024**3) if res.get('memory_bytes') is not None else 16

def allocate_disk(default: Dataclass_740_pre) -> int:
    res = _read_resources()
    return max(1, res['disk_bytes'] // 1024**3) if res.get('disk_bytes') is not None else 4800

def get_resources(default: Dataclass_740_pre):
    wf_paths = {}
    wf_input = default.wf_input
    wf_input = construct_samplesheet(wf_input)
    wf_genome = default.wf_genome
    wf_save_reference = default.wf_save_reference
    wf_save_align_intermeds = default.wf_save_align_intermeds
    wf_aligner = default.wf_aligner
    wf_clip_r1 = default.wf_clip_r1
    wf_clip_r2 = default.wf_clip_r2
    wf_three_prime_clip_r1 = default.wf_three_prime_clip_r1
    wf_three_prime_clip_r2 = default.wf_three_prime_clip_r2
    wf_nextseq_trim = default.wf_nextseq_trim
    wf_cytosine_report = default.wf_cytosine_report
    wf_num_mismatches = default.wf_num_mismatches
    wf_skip_trimming = default.wf_skip_trimming
    wf_skip_deduplication = default.wf_skip_deduplication
    wf_skip_multiqc = default.wf_skip_multiqc
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_739)]

    if not True:
        download_files(channel_vals, LatchDir('latch:///methylseq-outputs'))

    flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/local/prepare_genome.nf','-lib','lib','-profile','mamba','-entry','PREPARE_GENOME', *flags],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"UNTAR","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"untar\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"UNTAR\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"UNTAR\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'True',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

@custom_task(cpu=allocate_cpu, memory=allocate_memory, storage_gib=allocate_disk, pre_execute=get_resources, cache=True)
def UNTAR_740(
    default: Dataclass_740_pre
) -> Dataclass_740_post:
    wf_paths = {}
    wf_input = default.wf_input
    wf_input = construct_samplesheet(wf_input)
    wf_genome = default.wf_genome
    wf_save_reference = default.wf_save_reference
    wf_save_align_intermeds = default.wf_save_align_intermeds
    wf_aligner = default.wf_aligner
    wf_clip_r1 = default.wf_clip_r1
    wf_clip_r2 = default.wf_clip_r2
    wf_three_prime_clip_r1 = default.wf_three_prime_clip_r1
    wf_three_prime_clip_r2 = default.wf_three_prime_clip_r2
    wf_nextseq_trim = default.wf_nextseq_trim
    wf_cytosine_report = default.wf_cytosine_report
    wf_num_mismatches = default.wf_num_mismatches
    wf_skip_trimming = default.wf_skip_trimming
    wf_skip_deduplication = default.wf_skip_deduplication
    wf_skip_multiqc = default.wf_skip_multiqc
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_739)]

    if not False:
        download_files(channel_vals, LatchDir('latch:///methylseq-outputs'))

    flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/local/prepare_genome.nf','-lib','lib','-profile','mamba','-entry','PREPARE_GENOME', *flags],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"UNTAR","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"untar\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"UNTAR\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"UNTAR\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'False',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = json.loads(file.read_text())

    print(out_channels)

    publish_dir = None
    upload_files(out_channels, LatchDir('latch:///methylseq-outputs'), publish_dir)

    out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    return Dataclass_740_post(
        untar=out_channels.get(f"untar"),
        versions=out_channels.get(f"versions")
    )


class ResMerge_UNTAR_763(NamedTuple):
    untar: typing.Union[str, None]
    versions: typing.Union[str, None]

@task(cache=True)
def Merge_UNTAR_763(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    channel_722_0: typing.Union[str, None],
    channel_722_1: typing.Union[str, None],
    channel_740_0: typing.Union[str, None],
    channel_740_1: typing.Union[str, None]
) -> ResMerge_UNTAR_763:
    cond = True

    if cond:
        res = { 'untar': channel_722_0 or channel_740_0, 'versions': channel_722_1 or channel_740_1 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_UNTAR_763(
        untar=res.get('untar'),
        versions=res.get('versions')
    )


class Res_params_aligner____bismark__790(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def _params_aligner____bismark__790(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str
) -> Res_params_aligner____bismark__790:
    cond = True

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = []



        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/methylseq.nf', '-lib', 'lib', '-entry', 'METHYLSEQ', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"BinaryExpression":{"leftExpression":{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"aligner"}},"operation":"==","rightExpression":{"ConstantExpression":"bismark"}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Res_params_aligner____bismark__790(
        res=out_channels.get("res")
    )


class Res_params_aligner____bismark_hisat__791(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def _params_aligner____bismark_hisat__791(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str
) -> Res_params_aligner____bismark_hisat__791:
    cond = True

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = []



        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/methylseq.nf', '-lib', 'lib', '-entry', 'METHYLSEQ', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"BinaryExpression":{"leftExpression":{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"aligner"}},"operation":"==","rightExpression":{"ConstantExpression":"bismark_hisat"}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Res_params_aligner____bismark_hisat__791(
        res=out_channels.get("res")
    )


class Res__params_aligner____bismark______params_aligner____bismark_hisat_792(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def __params_aligner____bismark______params_aligner____bismark_hisat_792(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    channel_790: typing.Union[str, None],
    channel_791: typing.Union[str, None]
) -> Res__params_aligner____bismark______params_aligner____bismark_hisat_792:
    cond = ((channel_790 is not None) and (channel_791 is not None))

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = [json.loads(channel_790), json.loads(channel_791)]



        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/methylseq.nf', '-lib', 'lib', '-entry', 'METHYLSEQ', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"binaryOp","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"ConstantExpression":"||"}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Res__params_aligner____bismark______params_aligner____bismark_hisat_792(
        res=out_channels.get("res")
    )


class Res__params_aligner____bismark______params_aligner____bismark_hisat_793(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def __params_aligner____bismark______params_aligner____bismark_hisat_793(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    channel_792: typing.Union[str, None]
) -> Res__params_aligner____bismark______params_aligner____bismark_hisat_793:
    cond = ((channel_792 is not None))

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = [json.loads(channel_792)]



        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/methylseq.nf', '-lib', 'lib', '-entry', 'METHYLSEQ', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"toBoolean","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Res__params_aligner____bismark______params_aligner____bismark_hisat_793(
        res=out_channels.get("res")
    )


class Resconditional___params_aligner____bismark______params_aligner____bismark_hisat_794(NamedTuple):
    condition: typing.Union[bool, None]

@task(cache=True)
def conditional___params_aligner____bismark______params_aligner____bismark_hisat_794(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    channel_793: typing.Union[str, None]
) -> Resconditional___params_aligner____bismark______params_aligner____bismark_hisat_794:
    cond = ((channel_793 is not None))

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = [json.loads(channel_793)]



        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/methylseq.nf', '-lib', 'lib', '-entry', 'METHYLSEQ', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"condition"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"condition\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'condition': None}

    res = out_channels.get("condition")

    if res is not None:
        res = get_boolean_value(res)

    return Resconditional___params_aligner____bismark______params_aligner____bismark_hisat_794(condition=res)


class Res_params_aligner____bwameth__849(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def _params_aligner____bwameth__849(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_794: typing.Union[bool, None]
) -> Res_params_aligner____bwameth__849:
    cond = ((condition_794 == False))

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = []



        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/methylseq.nf', '-lib', 'lib', '-entry', 'METHYLSEQ', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"BinaryExpression":{"leftExpression":{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"aligner"}},"operation":"==","rightExpression":{"ConstantExpression":"bwameth"}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Res_params_aligner____bwameth__849(
        res=out_channels.get("res")
    )


class Res_params_aligner____bwameth__850(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def _params_aligner____bwameth__850(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_794: typing.Union[bool, None],
    channel_849: typing.Union[str, None]
) -> Res_params_aligner____bwameth__850:
    cond = ((condition_794 == False) and (channel_849 is not None))

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = [json.loads(channel_849)]



        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/methylseq.nf', '-lib', 'lib', '-entry', 'METHYLSEQ', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"toBoolean","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Res_params_aligner____bwameth__850(
        res=out_channels.get("res")
    )


class Resconditional__params_aligner____bwameth__851(NamedTuple):
    condition: typing.Union[bool, None]

@task(cache=True)
def conditional__params_aligner____bwameth__851(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_794: typing.Union[bool, None],
    channel_850: typing.Union[str, None]
) -> Resconditional__params_aligner____bwameth__851:
    cond = ((condition_794 == False) and (channel_850 is not None))

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = [json.loads(channel_850)]



        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/methylseq.nf', '-lib', 'lib', '-entry', 'METHYLSEQ', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"condition"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"condition\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'condition': None}

    res = out_channels.get("condition")

    if res is not None:
        res = get_boolean_value(res)

    return Resconditional__params_aligner____bwameth__851(condition=res)


class Res_params_skip_deduplication____params_rrbs__852(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def _params_skip_deduplication____params_rrbs__852(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_794: typing.Union[bool, None],
    condition_851: typing.Union[bool, None]
) -> Res_params_skip_deduplication____params_rrbs__852:
    cond = ((condition_794 == False) and (condition_851 == True))

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = []



        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/methylseq.nf', '-lib', 'lib', '-entry', 'METHYLSEQ', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"value","arguments":{"ArgumentListExpression":{"expressions":[{"BinaryExpression":{"leftExpression":{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"skip_deduplication"}},"operation":"||","rightExpression":{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"rrbs"}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Res_params_skip_deduplication____params_rrbs__852(
        res=out_channels.get("res")
    )


class Resskip_deduplication_866(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def skip_deduplication_866(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_794: typing.Union[bool, None],
    condition_851: typing.Union[bool, None],
    channel_852: typing.Union[str, None]
) -> Resskip_deduplication_866:
    cond = ((condition_794 == False) and (condition_851 == True) and (channel_852 is not None))

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = [json.loads(channel_852)]



        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/bwameth.nf', '-lib', 'lib', '-entry', 'BWAMETH', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"toBoolean","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resskip_deduplication_866(
        res=out_channels.get("res")
    )


class Resconditional_skip_deduplication_867(NamedTuple):
    condition: typing.Union[bool, None]

@task(cache=True)
def conditional_skip_deduplication_867(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_794: typing.Union[bool, None],
    condition_851: typing.Union[bool, None],
    channel_866: typing.Union[str, None]
) -> Resconditional_skip_deduplication_867:
    cond = ((condition_794 == False) and (condition_851 == True) and (channel_866 is not None))

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = [json.loads(channel_866)]



        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/bwameth.nf', '-lib', 'lib', '-entry', 'BWAMETH', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"condition"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"condition\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'condition': None}

    res = out_channels.get("condition")

    if res is not None:
        res = get_boolean_value(res)

    return Resconditional_skip_deduplication_867(condition=res)


class ResChannel_empty___869(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_empty___869(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_794: typing.Union[bool, None],
    condition_851: typing.Union[bool, None],
    condition_867: typing.Union[bool, None]
) -> ResChannel_empty___869:
    cond = ((condition_794 == False) and (condition_851 == True) and (condition_867 == True))

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = []



        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/bwameth.nf', '-lib', 'lib', '-entry', 'BWAMETH', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"empty","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResChannel_empty___869(
        res=out_channels.get("res")
    )


class Resparams_skip_trimming_782(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def params_skip_trimming_782(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str
) -> Resparams_skip_trimming_782:
    cond = True

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = []



        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/methylseq.nf', '-lib', 'lib', '-entry', 'METHYLSEQ', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"NotExpression":{"NotExpression":{"NotExpression":{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"skip_trimming"}}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resparams_skip_trimming_782(
        res=out_channels.get("res")
    )


class Resparams_skip_trimming_783(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def params_skip_trimming_783(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    channel_782: typing.Union[str, None]
) -> Resparams_skip_trimming_783:
    cond = ((channel_782 is not None))

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = [json.loads(channel_782)]



        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/methylseq.nf', '-lib', 'lib', '-entry', 'METHYLSEQ', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"toBoolean","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resparams_skip_trimming_783(
        res=out_channels.get("res")
    )


class Resconditional_params_skip_trimming_784(NamedTuple):
    condition: typing.Union[bool, None]

@task(cache=True)
def conditional_params_skip_trimming_784(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    channel_783: typing.Union[str, None]
) -> Resconditional_params_skip_trimming_784:
    cond = ((channel_783 is not None))

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = [json.loads(channel_783)]



        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/methylseq.nf', '-lib', 'lib', '-entry', 'METHYLSEQ', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"condition"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"condition\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'condition': None}

    res = out_channels.get("condition")

    if res is not None:
        res = get_boolean_value(res)

    return Resconditional_params_skip_trimming_784(condition=res)


class ResChannel_fromSamplesheet_input__769(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_fromSamplesheet_input__769(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str
) -> ResChannel_fromSamplesheet_input__769:
    cond = True

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = []



        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/methylseq.nf', '-lib', 'lib', '-entry', 'METHYLSEQ', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"fromSamplesheet","arguments":{"ArgumentListExpression":{"expressions":[{"ConstantExpression":"input"}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResChannel_fromSamplesheet_input__769(
        res=out_channels.get("res")
    )


class Resmap_770(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def map_770(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    channel_769: typing.Union[str, None]
) -> Resmap_770:
    cond = ((channel_769 is not None))

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = [json.loads(channel_769)]



        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/methylseq.nf', '-lib', 'lib', '-entry', 'METHYLSEQ', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"map","arguments":{"ArgumentListExpression":{"expressions":[{"ClosureExpression":{"code":{"BlockStatement":{"statements":[{"IfStatement":{"booleanExpression":{"BooleanExpression":{"NotExpression":{"VariableExpression":"fastq_2"}}},"ifBlock":{"BlockStatement":{"statements":[{"ReturnStatement":{"ListExpression":[{"BinaryExpression":{"leftExpression":{"VariableExpression":"meta"},"operation":"+","rightExpression":{"MapExpression":[{"MapEntryExpression":{"keyExpression":{"ConstantExpression":"single_end"},"valueExpression":{"ConstantExpression":true}}}]}}},{"ListExpression":[{"VariableExpression":"fastq_1"}]}]}}],"scope":{"declaredVariables":[],"referencedClassVariables":[]},"labels":[]}},"elseBlock":{"BlockStatement":{"statements":[{"ReturnStatement":{"ListExpression":[{"BinaryExpression":{"leftExpression":{"VariableExpression":"meta"},"operation":"+","rightExpression":{"MapExpression":[{"MapEntryExpression":{"keyExpression":{"ConstantExpression":"single_end"},"valueExpression":{"ConstantExpression":false}}}]}}},{"ListExpression":[{"VariableExpression":"fastq_1"},{"VariableExpression":"fastq_2"}]}]}}],"scope":{"declaredVariables":[],"referencedClassVariables":[]},"labels":[]}},"labels":[]}}],"scope":{"declaredVariables":[],"referencedClassVariables":[]},"labels":[]}},"parameters":["meta","fastq_1","fastq_2"]}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmap_770(
        res=out_channels.get("res")
    )


class ResgroupTuple_771(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def groupTuple_771(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    channel_770: typing.Union[str, None]
) -> ResgroupTuple_771:
    cond = ((channel_770 is not None))

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = [json.loads(channel_770)]



        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/methylseq.nf', '-lib', 'lib', '-entry', 'METHYLSEQ', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"groupTuple","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResgroupTuple_771(
        res=out_channels.get("res")
    )


class Resmap_772(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def map_772(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    channel_771: typing.Union[str, None]
) -> Resmap_772:
    cond = ((channel_771 is not None))

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = [json.loads(channel_771)]



        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/methylseq.nf', '-lib', 'lib', '-entry', 'METHYLSEQ', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"map","arguments":{"ArgumentListExpression":{"expressions":[{"ClosureExpression":{"code":{"BlockStatement":{"statements":[{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"meta_clone"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"meta"},"method":"clone","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}},{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"parts"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"PropertyExpression":{"objectExpression":{"VariableExpression":"meta_clone"},"property":"id"}},"method":"split","arguments":{"ArgumentListExpression":{"expressions":[{"ConstantExpression":"_"}]}}}}}},"labels":[]}},{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"PropertyExpression":{"objectExpression":{"VariableExpression":"meta_clone"},"property":"id"}},"operation":"=","rightExpression":{"TernaryExpression":{"booleanExpression":{"BooleanExpression":{"MethodCallExpression":{"objectExpression":{"ClassExpression":{"type":"nextflow.ast.LangHelpers"}},"method":"compareGreaterThan","arguments":{"ArgumentListExpression":{"expressions":[{"PropertyExpression":{"objectExpression":{"VariableExpression":"parts"},"property":"length"}},{"ConstantExpression":1}]}}}}},"trueExpression":{"MethodCallExpression":{"objectExpression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"parts"},"operation":"[","rightExpression":{"RangeExpression":{"from":{"ConstantExpression":0},"to":{"ConstantExpression":-2},"inclusive":true}}}},"method":"join","arguments":{"ArgumentListExpression":{"expressions":[{"ConstantExpression":"_"}]}}}},"falseExpression":{"PropertyExpression":{"objectExpression":{"VariableExpression":"meta_clone"},"property":"id"}}}}}},"labels":[]}},{"ReturnStatement":{"ListExpression":[{"VariableExpression":"meta_clone"},{"VariableExpression":"fastq"}]}}],"scope":{"declaredVariables":["meta_clone"],"referencedClassVariables":["parts","compareGreaterThan"]},"labels":[]}},"parameters":["meta","fastq"]}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmap_772(
        res=out_channels.get("res")
    )


class ResgroupTuple_773(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def groupTuple_773(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    channel_772: typing.Union[str, None]
) -> ResgroupTuple_773:
    cond = ((channel_772 is not None))

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = [json.loads(channel_772)]



        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/methylseq.nf', '-lib', 'lib', '-entry', 'METHYLSEQ', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"groupTuple","arguments":{"ArgumentListExpression":{"expressions":[{"MapExpression":[{"MapEntryExpression":{"keyExpression":{"ConstantExpression":"by"},"valueExpression":{"ListExpression":[{"ConstantExpression":0}]}}}]}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResgroupTuple_773(
        res=out_channels.get("res")
    )


class Resbranch_774(NamedTuple):
    single: typing.Union[str, None]
    multiple: typing.Union[str, None]

@task(cache=True)
def branch_774(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    channel_773: typing.Union[str, None]
) -> Resbranch_774:
    cond = ((channel_773 is not None))

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = [json.loads(channel_773)]



        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/methylseq.nf', '-lib', 'lib', '-entry', 'METHYLSEQ', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"branch","arguments":{"ArgumentListExpression":{"expressions":[{"ClosureExpression":{"code":{"BlockStatement":{"statements":[{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"ClassExpression":{"type":"nextflow.ast.LangHelpers"}},"method":"compareEqual","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"fastq"},"method":"size","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"ConstantExpression":1}]}}}},"labels":["single"]}},{"ReturnStatement":{"ConstructorCallExpression":{"type":"nextflow.script.TokenBranchChoice","arguments":{"ArgumentListExpression":{"expressions":[{"ListExpression":[{"VariableExpression":"meta"},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"fastq"},"method":"flatten","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]},{"ConstantExpression":"single"}]}}}}},{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"ClassExpression":{"type":"nextflow.ast.LangHelpers"}},"method":"compareGreaterThan","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"fastq"},"method":"size","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"ConstantExpression":1}]}}}},"labels":["multiple"]}},{"ReturnStatement":{"ConstructorCallExpression":{"type":"nextflow.script.TokenBranchChoice","arguments":{"ArgumentListExpression":{"expressions":[{"ListExpression":[{"VariableExpression":"meta"},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"fastq"},"method":"flatten","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]},{"ConstantExpression":"multiple"}]}}}}}],"scope":{"declaredVariables":[],"referencedClassVariables":[]},"labels":[]}},"parameters":["meta","fastq"]}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"single\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"res\\"},\\"property\\":\\"single\\"}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"multiple\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"res\\"},\\"property\\":\\"multiple\\"}}}},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'single': None, 'multiple': None}

    return Resbranch_774(
        single=out_channels.get("single"),
        multiple=out_channels.get("multiple")
    )


@dataclass
class Dataclass_775_pre:
    wf_input: typing.List[Sample]
    wf_genome: Genome
    wf_save_reference: bool
    wf_save_align_intermeds: bool
    wf_aligner: Aligner
    wf_clip_r1: int
    wf_clip_r2: int
    wf_three_prime_clip_r1: int
    wf_three_prime_clip_r2: int
    wf_nextseq_trim: int
    wf_cytosine_report: bool
    wf_num_mismatches: float
    wf_skip_trimming: bool
    wf_skip_deduplication: bool
    wf_skip_multiqc: bool
    wf_outdir: str
    channel_774_1: str


class Res_775_pre(NamedTuple):
    default: typing.List[Dataclass_775_pre]
    is_skipped: bool

@task(cache=True)
def pre_adapter_CAT_FASTQ_775_pre(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    channel_774_1: typing.Union[str, None]
) -> Res_775_pre:
    cond = ((channel_774_1 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_775_pre, {'wf_input': wf_input, 'wf_genome': wf_genome, 'wf_save_reference': wf_save_reference, 'wf_save_align_intermeds': wf_save_align_intermeds, 'wf_aligner': wf_aligner, 'wf_clip_r1': wf_clip_r1, 'wf_clip_r2': wf_clip_r2, 'wf_three_prime_clip_r1': wf_three_prime_clip_r1, 'wf_three_prime_clip_r2': wf_three_prime_clip_r2, 'wf_nextseq_trim': wf_nextseq_trim, 'wf_cytosine_report': wf_cytosine_report, 'wf_num_mismatches': wf_num_mismatches, 'wf_skip_trimming': wf_skip_trimming, 'wf_skip_deduplication': wf_skip_deduplication, 'wf_skip_multiqc': wf_skip_multiqc, 'wf_outdir': wf_outdir}, {'channel_774_1': channel_774_1})
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        result = []

    return Res_775_pre(default=result, is_skipped = not cond)

class Respost_adapter_CAT_FASTQ_775_post(NamedTuple):
    reads: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_775_post:
    reads: str
    versions: str

@task(cache=True)
def post_adapter_CAT_FASTQ_775_post(
    default: List[Dataclass_775_post],
    is_skipped: bool,
) -> Respost_adapter_CAT_FASTQ_775_post:
    return get_mapper_outputs(Respost_adapter_CAT_FASTQ_775_post, default, is_skipped)


def _read_resources() -> Dict:
    try:
        with open(".latch/resources.json") as f:
            return json.load(f)
    except FileNotFoundError:
        return {}

def allocate_cpu(default: Dataclass_775_pre) -> int:
    res = _read_resources()
    return max(1, res['cpu_cores']) if res.get('cpu_cores') is not None else 4

def allocate_memory(default: Dataclass_775_pre) -> int:
    res = _read_resources()
    return max(1, res['memory_bytes'] // 1024**3) if res.get('memory_bytes') is not None else 16

def allocate_disk(default: Dataclass_775_pre) -> int:
    res = _read_resources()
    return max(1, res['disk_bytes'] // 1024**3) if res.get('disk_bytes') is not None else 4800

def get_resources(default: Dataclass_775_pre):
    wf_paths = {}
    wf_input = default.wf_input
    wf_input = construct_samplesheet(wf_input)
    wf_genome = default.wf_genome
    wf_save_reference = default.wf_save_reference
    wf_save_align_intermeds = default.wf_save_align_intermeds
    wf_aligner = default.wf_aligner
    wf_clip_r1 = default.wf_clip_r1
    wf_clip_r2 = default.wf_clip_r2
    wf_three_prime_clip_r1 = default.wf_three_prime_clip_r1
    wf_three_prime_clip_r2 = default.wf_three_prime_clip_r2
    wf_nextseq_trim = default.wf_nextseq_trim
    wf_cytosine_report = default.wf_cytosine_report
    wf_num_mismatches = default.wf_num_mismatches
    wf_skip_trimming = default.wf_skip_trimming
    wf_skip_deduplication = default.wf_skip_deduplication
    wf_skip_multiqc = default.wf_skip_multiqc
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_774_1)]

    if not True:
        download_files(channel_vals, LatchDir('latch:///methylseq-outputs'))

    flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/workflows/methylseq.nf','-lib','lib','-profile','mamba','-entry','METHYLSEQ', *flags],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"CAT_FASTQ","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"reads\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"CAT_FASTQ\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"CAT_FASTQ\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'True',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

@custom_task(cpu=allocate_cpu, memory=allocate_memory, storage_gib=allocate_disk, pre_execute=get_resources, cache=True)
def CAT_FASTQ_775(
    default: Dataclass_775_pre
) -> Dataclass_775_post:
    wf_paths = {}
    wf_input = default.wf_input
    wf_input = construct_samplesheet(wf_input)
    wf_genome = default.wf_genome
    wf_save_reference = default.wf_save_reference
    wf_save_align_intermeds = default.wf_save_align_intermeds
    wf_aligner = default.wf_aligner
    wf_clip_r1 = default.wf_clip_r1
    wf_clip_r2 = default.wf_clip_r2
    wf_three_prime_clip_r1 = default.wf_three_prime_clip_r1
    wf_three_prime_clip_r2 = default.wf_three_prime_clip_r2
    wf_nextseq_trim = default.wf_nextseq_trim
    wf_cytosine_report = default.wf_cytosine_report
    wf_num_mismatches = default.wf_num_mismatches
    wf_skip_trimming = default.wf_skip_trimming
    wf_skip_deduplication = default.wf_skip_deduplication
    wf_skip_multiqc = default.wf_skip_multiqc
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_774_1)]

    if not False:
        download_files(channel_vals, LatchDir('latch:///methylseq-outputs'))

    flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/workflows/methylseq.nf','-lib','lib','-profile','mamba','-entry','METHYLSEQ', *flags],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"CAT_FASTQ","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"reads\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"CAT_FASTQ\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"CAT_FASTQ\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'False',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = json.loads(file.read_text())

    print(out_channels)

    publish_dir = None
    upload_files(out_channels, LatchDir('latch:///methylseq-outputs'), publish_dir)

    out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    return Dataclass_775_post(
        reads=out_channels.get(f"reads"),
        versions=out_channels.get(f"versions")
    )


class Resmix_776(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_776(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    channel_775_0: typing.Union[str, None],
    channel_774_0: typing.Union[str, None]
) -> Resmix_776:
    cond = ((channel_775_0 is not None) and (channel_774_0 is not None))

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = [json.loads(channel_775_0), json.loads(channel_774_0)]



        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/methylseq.nf', '-lib', 'lib', '-entry', 'METHYLSEQ', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_776(
        res=out_channels.get("res")
    )


@dataclass
class Dataclass_785_pre:
    wf_input: typing.List[Sample]
    wf_genome: Genome
    wf_save_reference: bool
    wf_save_align_intermeds: bool
    wf_aligner: Aligner
    wf_clip_r1: int
    wf_clip_r2: int
    wf_three_prime_clip_r1: int
    wf_three_prime_clip_r2: int
    wf_nextseq_trim: int
    wf_cytosine_report: bool
    wf_num_mismatches: float
    wf_skip_trimming: bool
    wf_skip_deduplication: bool
    wf_skip_multiqc: bool
    wf_outdir: str
    channel_776: str


class Res_785_pre(NamedTuple):
    default: typing.List[Dataclass_785_pre]
    is_skipped: bool

@task(cache=True)
def pre_adapter_TRIMGALORE_785_pre(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_784: typing.Union[bool, None],
    channel_776: typing.Union[str, None]
) -> Res_785_pre:
    cond = ((condition_784 == True) and (channel_776 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_785_pre, {'wf_input': wf_input, 'wf_genome': wf_genome, 'wf_save_reference': wf_save_reference, 'wf_save_align_intermeds': wf_save_align_intermeds, 'wf_aligner': wf_aligner, 'wf_clip_r1': wf_clip_r1, 'wf_clip_r2': wf_clip_r2, 'wf_three_prime_clip_r1': wf_three_prime_clip_r1, 'wf_three_prime_clip_r2': wf_three_prime_clip_r2, 'wf_nextseq_trim': wf_nextseq_trim, 'wf_cytosine_report': wf_cytosine_report, 'wf_num_mismatches': wf_num_mismatches, 'wf_skip_trimming': wf_skip_trimming, 'wf_skip_deduplication': wf_skip_deduplication, 'wf_skip_multiqc': wf_skip_multiqc, 'wf_outdir': wf_outdir}, {'channel_776': channel_776})
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        result = []

    return Res_785_pre(default=result, is_skipped = not cond)

class Respost_adapter_TRIMGALORE_785_post(NamedTuple):
    reads: typing.Union[str, None]
    log: typing.Union[str, None]
    unpaired: typing.Union[str, None]
    html: typing.Union[str, None]
    zip: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_785_post:
    reads: str
    log: str
    unpaired: str
    html: str
    zip: str
    versions: str

@task(cache=True)
def post_adapter_TRIMGALORE_785_post(
    default: List[Dataclass_785_post],
    is_skipped: bool,
) -> Respost_adapter_TRIMGALORE_785_post:
    return get_mapper_outputs(Respost_adapter_TRIMGALORE_785_post, default, is_skipped)


def _read_resources() -> Dict:
    try:
        with open(".latch/resources.json") as f:
            return json.load(f)
    except FileNotFoundError:
        return {}

def allocate_cpu(default: Dataclass_785_pre) -> int:
    res = _read_resources()
    return max(1, res['cpu_cores']) if res.get('cpu_cores') is not None else 12

def allocate_memory(default: Dataclass_785_pre) -> int:
    res = _read_resources()
    return max(1, res['memory_bytes'] // 1024**3) if res.get('memory_bytes') is not None else 72

def allocate_disk(default: Dataclass_785_pre) -> int:
    res = _read_resources()
    return max(1, res['disk_bytes'] // 1024**3) if res.get('disk_bytes') is not None else 4800

def get_resources(default: Dataclass_785_pre):
    wf_paths = {}
    wf_input = default.wf_input
    wf_input = construct_samplesheet(wf_input)
    wf_genome = default.wf_genome
    wf_save_reference = default.wf_save_reference
    wf_save_align_intermeds = default.wf_save_align_intermeds
    wf_aligner = default.wf_aligner
    wf_clip_r1 = default.wf_clip_r1
    wf_clip_r2 = default.wf_clip_r2
    wf_three_prime_clip_r1 = default.wf_three_prime_clip_r1
    wf_three_prime_clip_r2 = default.wf_three_prime_clip_r2
    wf_nextseq_trim = default.wf_nextseq_trim
    wf_cytosine_report = default.wf_cytosine_report
    wf_num_mismatches = default.wf_num_mismatches
    wf_skip_trimming = default.wf_skip_trimming
    wf_skip_deduplication = default.wf_skip_deduplication
    wf_skip_multiqc = default.wf_skip_multiqc
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_776)]

    if not True:
        download_files(channel_vals, LatchDir('latch:///methylseq-outputs'))

    flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/workflows/methylseq.nf','-lib','lib','-profile','mamba','-entry','METHYLSEQ', *flags],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"TRIMGALORE","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"reads\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"TRIMGALORE\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"_latch_placeholder_log\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"TRIMGALORE\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"unpaired\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"TRIMGALORE\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":2}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"html\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"TRIMGALORE\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":3}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"zip\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"TRIMGALORE\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":4}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"TRIMGALORE\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":5}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'True',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

@custom_task(cpu=allocate_cpu, memory=allocate_memory, storage_gib=allocate_disk, pre_execute=get_resources, cache=True)
def TRIMGALORE_785(
    default: Dataclass_785_pre
) -> Dataclass_785_post:
    wf_paths = {}
    wf_input = default.wf_input
    wf_input = construct_samplesheet(wf_input)
    wf_genome = default.wf_genome
    wf_save_reference = default.wf_save_reference
    wf_save_align_intermeds = default.wf_save_align_intermeds
    wf_aligner = default.wf_aligner
    wf_clip_r1 = default.wf_clip_r1
    wf_clip_r2 = default.wf_clip_r2
    wf_three_prime_clip_r1 = default.wf_three_prime_clip_r1
    wf_three_prime_clip_r2 = default.wf_three_prime_clip_r2
    wf_nextseq_trim = default.wf_nextseq_trim
    wf_cytosine_report = default.wf_cytosine_report
    wf_num_mismatches = default.wf_num_mismatches
    wf_skip_trimming = default.wf_skip_trimming
    wf_skip_deduplication = default.wf_skip_deduplication
    wf_skip_multiqc = default.wf_skip_multiqc
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_776)]

    if not False:
        download_files(channel_vals, LatchDir('latch:///methylseq-outputs'))

    flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/workflows/methylseq.nf','-lib','lib','-profile','mamba','-entry','METHYLSEQ', *flags],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"TRIMGALORE","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"reads\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"TRIMGALORE\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"_latch_placeholder_log\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"TRIMGALORE\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"unpaired\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"TRIMGALORE\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":2}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"html\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"TRIMGALORE\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":3}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"zip\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"TRIMGALORE\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":4}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"TRIMGALORE\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":5}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'False',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = json.loads(file.read_text())

    print(out_channels)

    publish_dir = None
    upload_files(out_channels, LatchDir('latch:///methylseq-outputs'), publish_dir)

    out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    return Dataclass_785_post(
        reads=out_channels.get(f"reads"),
        log=out_channels.get(f"log"),
        unpaired=out_channels.get(f"unpaired"),
        html=out_channels.get(f"html"),
        zip=out_channels.get(f"zip"),
        versions=out_channels.get(f"versions")
    )


class ResMerge_reads_788(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_reads_788(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    channel_785_0: typing.Union[str, None],
    channel_776: typing.Union[str, None]
) -> ResMerge_reads_788:
    cond = True

    if cond:
        res = { 'res': channel_785_0 or channel_776 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_reads_788(
        res=res.get('res')
    )


class ResChannel_empty___704(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_empty___704(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str
) -> ResChannel_empty___704:
    cond = True

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = []



        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome.nf', '-lib', 'lib', '-entry', 'PREPARE_GENOME', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"empty","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResChannel_empty___704(
        res=out_channels.get("res")
    )


class Resparams_fasta_706(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def params_fasta_706(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str
) -> Resparams_fasta_706:
    cond = True

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = []



        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome.nf', '-lib', 'lib', '-entry', 'PREPARE_GENOME', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"NotExpression":{"NotExpression":{"BooleanExpression":{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"fasta"}}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resparams_fasta_706(
        res=out_channels.get("res")
    )


class Resconditional_params_fasta_707(NamedTuple):
    condition: typing.Union[bool, None]

@task(cache=True)
def conditional_params_fasta_707(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    channel_706: typing.Union[str, None]
) -> Resconditional_params_fasta_707:
    cond = ((channel_706 is not None))

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = [json.loads(channel_706)]



        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome.nf', '-lib', 'lib', '-entry', 'PREPARE_GENOME', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"condition"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"condition\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'condition': None}

    res = out_channels.get("condition")

    if res is not None:
        res = get_boolean_value(res)

    return Resconditional_params_fasta_707(condition=res)


class ResChannel_value_this_file_params_fasta___708(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_value_this_file_params_fasta___708(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_707: typing.Union[bool, None]
) -> ResChannel_value_this_file_params_fasta___708:
    cond = ((condition_707 == True))

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = []



        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome.nf', '-lib', 'lib', '-entry', 'PREPARE_GENOME', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"value","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"file","arguments":{"ArgumentListExpression":{"expressions":[{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"fasta"}}]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResChannel_value_this_file_params_fasta___708(
        res=out_channels.get("res")
    )


class ResChannel_empty___702(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_empty___702(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str
) -> ResChannel_empty___702:
    cond = True

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = []



        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome.nf', '-lib', 'lib', '-entry', 'PREPARE_GENOME', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"empty","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResChannel_empty___702(
        res=out_channels.get("res")
    )


class ResMerge_ch_fasta_709(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_fasta_709(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    channel_708: typing.Union[str, None],
    channel_702: typing.Union[str, None]
) -> ResMerge_ch_fasta_709:
    cond = True

    if cond:
        res = { 'res': channel_708 or channel_702 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_fasta_709(
        res=res.get('res')
    )


@dataclass
class Dataclass_744_pre:
    wf_input: typing.List[Sample]
    wf_genome: Genome
    wf_save_reference: bool
    wf_save_align_intermeds: bool
    wf_aligner: Aligner
    wf_clip_r1: int
    wf_clip_r2: int
    wf_three_prime_clip_r1: int
    wf_three_prime_clip_r2: int
    wf_nextseq_trim: int
    wf_cytosine_report: bool
    wf_num_mismatches: float
    wf_skip_trimming: bool
    wf_skip_deduplication: bool
    wf_skip_multiqc: bool
    wf_outdir: str
    channel_709: str


class Res_744_pre(NamedTuple):
    default: typing.List[Dataclass_744_pre]
    is_skipped: bool

@task(cache=True)
def pre_adapter_BWAMETH_INDEX_744_pre(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_714: typing.Union[bool, None],
    condition_732: typing.Union[bool, None],
    condition_734: typing.Union[bool, None],
    channel_709: typing.Union[str, None]
) -> Res_744_pre:
    cond = ((condition_714 == False) and (condition_732 == True) and (condition_734 == False) and (channel_709 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_744_pre, {'wf_input': wf_input, 'wf_genome': wf_genome, 'wf_save_reference': wf_save_reference, 'wf_save_align_intermeds': wf_save_align_intermeds, 'wf_aligner': wf_aligner, 'wf_clip_r1': wf_clip_r1, 'wf_clip_r2': wf_clip_r2, 'wf_three_prime_clip_r1': wf_three_prime_clip_r1, 'wf_three_prime_clip_r2': wf_three_prime_clip_r2, 'wf_nextseq_trim': wf_nextseq_trim, 'wf_cytosine_report': wf_cytosine_report, 'wf_num_mismatches': wf_num_mismatches, 'wf_skip_trimming': wf_skip_trimming, 'wf_skip_deduplication': wf_skip_deduplication, 'wf_skip_multiqc': wf_skip_multiqc, 'wf_outdir': wf_outdir}, {'channel_709': channel_709})
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        result = []

    return Res_744_pre(default=result, is_skipped = not cond)

class Respost_adapter_BWAMETH_INDEX_744_post(NamedTuple):
    index: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_744_post:
    index: str
    versions: str

@task(cache=True)
def post_adapter_BWAMETH_INDEX_744_post(
    default: List[Dataclass_744_post],
    is_skipped: bool,
) -> Respost_adapter_BWAMETH_INDEX_744_post:
    return get_mapper_outputs(Respost_adapter_BWAMETH_INDEX_744_post, default, is_skipped)


def _read_resources() -> Dict:
    try:
        with open(".latch/resources.json") as f:
            return json.load(f)
    except FileNotFoundError:
        return {}

def allocate_cpu(default: Dataclass_744_pre) -> int:
    res = _read_resources()
    return max(1, res['cpu_cores']) if res.get('cpu_cores') is not None else 12

def allocate_memory(default: Dataclass_744_pre) -> int:
    res = _read_resources()
    return max(1, res['memory_bytes'] // 1024**3) if res.get('memory_bytes') is not None else 72

def allocate_disk(default: Dataclass_744_pre) -> int:
    res = _read_resources()
    return max(1, res['disk_bytes'] // 1024**3) if res.get('disk_bytes') is not None else 4800

def get_resources(default: Dataclass_744_pre):
    wf_paths = {}
    wf_input = default.wf_input
    wf_input = construct_samplesheet(wf_input)
    wf_genome = default.wf_genome
    wf_save_reference = default.wf_save_reference
    wf_save_align_intermeds = default.wf_save_align_intermeds
    wf_aligner = default.wf_aligner
    wf_clip_r1 = default.wf_clip_r1
    wf_clip_r2 = default.wf_clip_r2
    wf_three_prime_clip_r1 = default.wf_three_prime_clip_r1
    wf_three_prime_clip_r2 = default.wf_three_prime_clip_r2
    wf_nextseq_trim = default.wf_nextseq_trim
    wf_cytosine_report = default.wf_cytosine_report
    wf_num_mismatches = default.wf_num_mismatches
    wf_skip_trimming = default.wf_skip_trimming
    wf_skip_deduplication = default.wf_skip_deduplication
    wf_skip_multiqc = default.wf_skip_multiqc
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_709)]

    if not True:
        download_files(channel_vals, LatchDir('latch:///methylseq-outputs'))

    flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/local/prepare_genome.nf','-lib','lib','-profile','mamba','-entry','PREPARE_GENOME', *flags],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"BWAMETH_INDEX","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"index\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"BWAMETH_INDEX\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"BWAMETH_INDEX\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'True',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

@custom_task(cpu=allocate_cpu, memory=allocate_memory, storage_gib=allocate_disk, pre_execute=get_resources, cache=True)
def BWAMETH_INDEX_744(
    default: Dataclass_744_pre
) -> Dataclass_744_post:
    wf_paths = {}
    wf_input = default.wf_input
    wf_input = construct_samplesheet(wf_input)
    wf_genome = default.wf_genome
    wf_save_reference = default.wf_save_reference
    wf_save_align_intermeds = default.wf_save_align_intermeds
    wf_aligner = default.wf_aligner
    wf_clip_r1 = default.wf_clip_r1
    wf_clip_r2 = default.wf_clip_r2
    wf_three_prime_clip_r1 = default.wf_three_prime_clip_r1
    wf_three_prime_clip_r2 = default.wf_three_prime_clip_r2
    wf_nextseq_trim = default.wf_nextseq_trim
    wf_cytosine_report = default.wf_cytosine_report
    wf_num_mismatches = default.wf_num_mismatches
    wf_skip_trimming = default.wf_skip_trimming
    wf_skip_deduplication = default.wf_skip_deduplication
    wf_skip_multiqc = default.wf_skip_multiqc
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_709)]

    if not False:
        download_files(channel_vals, LatchDir('latch:///methylseq-outputs'))

    flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/local/prepare_genome.nf','-lib','lib','-profile','mamba','-entry','PREPARE_GENOME', *flags],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"BWAMETH_INDEX","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"index\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"BWAMETH_INDEX\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"BWAMETH_INDEX\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'False',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = json.loads(file.read_text())

    print(out_channels)

    publish_dir = None
    upload_files(out_channels, LatchDir('latch:///methylseq-outputs'), publish_dir)

    out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    return Dataclass_744_post(
        index=out_channels.get(f"index"),
        versions=out_channels.get(f"versions")
    )


class ResMerge_ch_bwameth_index_747(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_bwameth_index_747(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_714: typing.Union[bool, None],
    condition_732: typing.Union[bool, None],
    channel_704: typing.Union[str, None],
    channel_744_0: typing.Union[str, None]
) -> ResMerge_ch_bwameth_index_747:
    cond = ((condition_714 == False) and (condition_732 == True))

    if cond:
        res = { 'res': channel_704 or channel_744_0 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_bwameth_index_747(
        res=res.get('res')
    )


class ResMerge_ch_bwameth_index_760(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_bwameth_index_760(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_714: typing.Union[bool, None],
    channel_747: typing.Union[str, None],
    channel_704: typing.Union[str, None]
) -> ResMerge_ch_bwameth_index_760:
    cond = ((condition_714 == False))

    if cond:
        res = { 'res': channel_747 or channel_704 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_bwameth_index_760(
        res=res.get('res')
    )


class ResMerge_ch_bwameth_index_766(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_bwameth_index_766(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    channel_704: typing.Union[str, None],
    channel_760: typing.Union[str, None]
) -> ResMerge_ch_bwameth_index_766:
    cond = True

    if cond:
        res = { 'res': channel_704 or channel_760 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_bwameth_index_766(
        res=res.get('res')
    )


@dataclass
class Dataclass_854_pre:
    wf_input: typing.List[Sample]
    wf_genome: Genome
    wf_save_reference: bool
    wf_save_align_intermeds: bool
    wf_aligner: Aligner
    wf_clip_r1: int
    wf_clip_r2: int
    wf_three_prime_clip_r1: int
    wf_three_prime_clip_r2: int
    wf_nextseq_trim: int
    wf_cytosine_report: bool
    wf_num_mismatches: float
    wf_skip_trimming: bool
    wf_skip_deduplication: bool
    wf_skip_multiqc: bool
    wf_outdir: str
    channel_788: str
    channel_766: str


class Res_854_pre(NamedTuple):
    default: typing.List[Dataclass_854_pre]
    is_skipped: bool

@task(cache=True)
def pre_adapter_BWAMETH_ALIGN_854_pre(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_794: typing.Union[bool, None],
    condition_851: typing.Union[bool, None],
    channel_788: typing.Union[str, None],
    channel_766: typing.Union[str, None]
) -> Res_854_pre:
    cond = ((condition_794 == False) and (condition_851 == True) and (channel_788 is not None) and (channel_766 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_854_pre, {'wf_input': wf_input, 'wf_genome': wf_genome, 'wf_save_reference': wf_save_reference, 'wf_save_align_intermeds': wf_save_align_intermeds, 'wf_aligner': wf_aligner, 'wf_clip_r1': wf_clip_r1, 'wf_clip_r2': wf_clip_r2, 'wf_three_prime_clip_r1': wf_three_prime_clip_r1, 'wf_three_prime_clip_r2': wf_three_prime_clip_r2, 'wf_nextseq_trim': wf_nextseq_trim, 'wf_cytosine_report': wf_cytosine_report, 'wf_num_mismatches': wf_num_mismatches, 'wf_skip_trimming': wf_skip_trimming, 'wf_skip_deduplication': wf_skip_deduplication, 'wf_skip_multiqc': wf_skip_multiqc, 'wf_outdir': wf_outdir}, {'channel_788': channel_788, 'channel_766': channel_766})
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        result = []

    return Res_854_pre(default=result, is_skipped = not cond)

class Respost_adapter_BWAMETH_ALIGN_854_post(NamedTuple):
    bam: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_854_post:
    bam: str
    versions: str

@task(cache=True)
def post_adapter_BWAMETH_ALIGN_854_post(
    default: List[Dataclass_854_post],
    is_skipped: bool,
) -> Respost_adapter_BWAMETH_ALIGN_854_post:
    return get_mapper_outputs(Respost_adapter_BWAMETH_ALIGN_854_post, default, is_skipped)


def _read_resources() -> Dict:
    try:
        with open(".latch/resources.json") as f:
            return json.load(f)
    except FileNotFoundError:
        return {}

def allocate_cpu(default: Dataclass_854_pre) -> int:
    res = _read_resources()
    return max(1, res['cpu_cores']) if res.get('cpu_cores') is not None else 12

def allocate_memory(default: Dataclass_854_pre) -> int:
    res = _read_resources()
    return max(1, res['memory_bytes'] // 1024**3) if res.get('memory_bytes') is not None else 72

def allocate_disk(default: Dataclass_854_pre) -> int:
    res = _read_resources()
    return max(1, res['disk_bytes'] // 1024**3) if res.get('disk_bytes') is not None else 4800

def get_resources(default: Dataclass_854_pre):
    wf_paths = {}
    wf_input = default.wf_input
    wf_input = construct_samplesheet(wf_input)
    wf_genome = default.wf_genome
    wf_save_reference = default.wf_save_reference
    wf_save_align_intermeds = default.wf_save_align_intermeds
    wf_aligner = default.wf_aligner
    wf_clip_r1 = default.wf_clip_r1
    wf_clip_r2 = default.wf_clip_r2
    wf_three_prime_clip_r1 = default.wf_three_prime_clip_r1
    wf_three_prime_clip_r2 = default.wf_three_prime_clip_r2
    wf_nextseq_trim = default.wf_nextseq_trim
    wf_cytosine_report = default.wf_cytosine_report
    wf_num_mismatches = default.wf_num_mismatches
    wf_skip_trimming = default.wf_skip_trimming
    wf_skip_deduplication = default.wf_skip_deduplication
    wf_skip_multiqc = default.wf_skip_multiqc
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_788),json.loads(default.channel_766)]

    if not True:
        download_files(channel_vals, LatchDir('latch:///methylseq-outputs'))

    flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/local/bwameth.nf','-lib','lib','-profile','mamba','-entry','BWAMETH', *flags],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"BWAMETH_ALIGN","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"bam\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"BWAMETH_ALIGN\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"BWAMETH_ALIGN\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'True',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

@custom_task(cpu=allocate_cpu, memory=allocate_memory, storage_gib=allocate_disk, pre_execute=get_resources, cache=True)
def BWAMETH_ALIGN_854(
    default: Dataclass_854_pre
) -> Dataclass_854_post:
    wf_paths = {}
    wf_input = default.wf_input
    wf_input = construct_samplesheet(wf_input)
    wf_genome = default.wf_genome
    wf_save_reference = default.wf_save_reference
    wf_save_align_intermeds = default.wf_save_align_intermeds
    wf_aligner = default.wf_aligner
    wf_clip_r1 = default.wf_clip_r1
    wf_clip_r2 = default.wf_clip_r2
    wf_three_prime_clip_r1 = default.wf_three_prime_clip_r1
    wf_three_prime_clip_r2 = default.wf_three_prime_clip_r2
    wf_nextseq_trim = default.wf_nextseq_trim
    wf_cytosine_report = default.wf_cytosine_report
    wf_num_mismatches = default.wf_num_mismatches
    wf_skip_trimming = default.wf_skip_trimming
    wf_skip_deduplication = default.wf_skip_deduplication
    wf_skip_multiqc = default.wf_skip_multiqc
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_788),json.loads(default.channel_766)]

    if not False:
        download_files(channel_vals, LatchDir('latch:///methylseq-outputs'))

    flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/local/bwameth.nf','-lib','lib','-profile','mamba','-entry','BWAMETH', *flags],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"BWAMETH_ALIGN","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"bam\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"BWAMETH_ALIGN\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"BWAMETH_ALIGN\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'False',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = json.loads(file.read_text())

    print(out_channels)

    publish_dir = None
    upload_files(out_channels, LatchDir('latch:///methylseq-outputs'), publish_dir)

    out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    return Dataclass_854_post(
        bam=out_channels.get(f"bam"),
        versions=out_channels.get(f"versions")
    )


@dataclass
class Dataclass_856_pre:
    wf_input: typing.List[Sample]
    wf_genome: Genome
    wf_save_reference: bool
    wf_save_align_intermeds: bool
    wf_aligner: Aligner
    wf_clip_r1: int
    wf_clip_r2: int
    wf_three_prime_clip_r1: int
    wf_three_prime_clip_r2: int
    wf_nextseq_trim: int
    wf_cytosine_report: bool
    wf_num_mismatches: float
    wf_skip_trimming: bool
    wf_skip_deduplication: bool
    wf_skip_multiqc: bool
    wf_outdir: str
    channel_854_0: str


class Res_856_pre(NamedTuple):
    default: typing.List[Dataclass_856_pre]
    is_skipped: bool

@task(cache=True)
def pre_adapter_SAMTOOLS_SORT_856_pre(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_794: typing.Union[bool, None],
    condition_851: typing.Union[bool, None],
    channel_854_0: typing.Union[str, None]
) -> Res_856_pre:
    cond = ((condition_794 == False) and (condition_851 == True) and (channel_854_0 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_856_pre, {'wf_input': wf_input, 'wf_genome': wf_genome, 'wf_save_reference': wf_save_reference, 'wf_save_align_intermeds': wf_save_align_intermeds, 'wf_aligner': wf_aligner, 'wf_clip_r1': wf_clip_r1, 'wf_clip_r2': wf_clip_r2, 'wf_three_prime_clip_r1': wf_three_prime_clip_r1, 'wf_three_prime_clip_r2': wf_three_prime_clip_r2, 'wf_nextseq_trim': wf_nextseq_trim, 'wf_cytosine_report': wf_cytosine_report, 'wf_num_mismatches': wf_num_mismatches, 'wf_skip_trimming': wf_skip_trimming, 'wf_skip_deduplication': wf_skip_deduplication, 'wf_skip_multiqc': wf_skip_multiqc, 'wf_outdir': wf_outdir}, {'channel_854_0': channel_854_0})
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        result = []

    return Res_856_pre(default=result, is_skipped = not cond)

class Respost_adapter_SAMTOOLS_SORT_856_post(NamedTuple):
    bam: typing.Union[str, None]
    csi: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_856_post:
    bam: str
    csi: str
    versions: str

@task(cache=True)
def post_adapter_SAMTOOLS_SORT_856_post(
    default: List[Dataclass_856_post],
    is_skipped: bool,
) -> Respost_adapter_SAMTOOLS_SORT_856_post:
    return get_mapper_outputs(Respost_adapter_SAMTOOLS_SORT_856_post, default, is_skipped)


def _read_resources() -> Dict:
    try:
        with open(".latch/resources.json") as f:
            return json.load(f)
    except FileNotFoundError:
        return {}

def allocate_cpu(default: Dataclass_856_pre) -> int:
    res = _read_resources()
    return max(1, res['cpu_cores']) if res.get('cpu_cores') is not None else 8

def allocate_memory(default: Dataclass_856_pre) -> int:
    res = _read_resources()
    return max(1, res['memory_bytes'] // 1024**3) if res.get('memory_bytes') is not None else 48

def allocate_disk(default: Dataclass_856_pre) -> int:
    res = _read_resources()
    return max(1, res['disk_bytes'] // 1024**3) if res.get('disk_bytes') is not None else 4800

def get_resources(default: Dataclass_856_pre):
    wf_paths = {}
    wf_input = default.wf_input
    wf_input = construct_samplesheet(wf_input)
    wf_genome = default.wf_genome
    wf_save_reference = default.wf_save_reference
    wf_save_align_intermeds = default.wf_save_align_intermeds
    wf_aligner = default.wf_aligner
    wf_clip_r1 = default.wf_clip_r1
    wf_clip_r2 = default.wf_clip_r2
    wf_three_prime_clip_r1 = default.wf_three_prime_clip_r1
    wf_three_prime_clip_r2 = default.wf_three_prime_clip_r2
    wf_nextseq_trim = default.wf_nextseq_trim
    wf_cytosine_report = default.wf_cytosine_report
    wf_num_mismatches = default.wf_num_mismatches
    wf_skip_trimming = default.wf_skip_trimming
    wf_skip_deduplication = default.wf_skip_deduplication
    wf_skip_multiqc = default.wf_skip_multiqc
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_854_0)]

    if not True:
        download_files(channel_vals, LatchDir('latch:///methylseq-outputs'))

    flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/local/bwameth.nf','-lib','lib','-profile','mamba','-entry','BWAMETH', *flags],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"SAMTOOLS_SORT","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"bam\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_SORT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"csi\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_SORT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_SORT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":2}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'True',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

@custom_task(cpu=allocate_cpu, memory=allocate_memory, storage_gib=allocate_disk, pre_execute=get_resources, cache=True)
def SAMTOOLS_SORT_856(
    default: Dataclass_856_pre
) -> Dataclass_856_post:
    wf_paths = {}
    wf_input = default.wf_input
    wf_input = construct_samplesheet(wf_input)
    wf_genome = default.wf_genome
    wf_save_reference = default.wf_save_reference
    wf_save_align_intermeds = default.wf_save_align_intermeds
    wf_aligner = default.wf_aligner
    wf_clip_r1 = default.wf_clip_r1
    wf_clip_r2 = default.wf_clip_r2
    wf_three_prime_clip_r1 = default.wf_three_prime_clip_r1
    wf_three_prime_clip_r2 = default.wf_three_prime_clip_r2
    wf_nextseq_trim = default.wf_nextseq_trim
    wf_cytosine_report = default.wf_cytosine_report
    wf_num_mismatches = default.wf_num_mismatches
    wf_skip_trimming = default.wf_skip_trimming
    wf_skip_deduplication = default.wf_skip_deduplication
    wf_skip_multiqc = default.wf_skip_multiqc
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_854_0)]

    if not False:
        download_files(channel_vals, LatchDir('latch:///methylseq-outputs'))

    flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/local/bwameth.nf','-lib','lib','-profile','mamba','-entry','BWAMETH', *flags],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"SAMTOOLS_SORT","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"bam\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_SORT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"csi\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_SORT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_SORT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":2}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'False',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = json.loads(file.read_text())

    print(out_channels)

    publish_dir = None
    upload_files(out_channels, LatchDir('latch:///methylseq-outputs'), publish_dir)

    out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    return Dataclass_856_post(
        bam=out_channels.get(f"bam"),
        csi=out_channels.get(f"csi"),
        versions=out_channels.get(f"versions")
    )


class ResChannel_empty___705(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_empty___705(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str
) -> ResChannel_empty___705:
    cond = True

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = []



        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome.nf', '-lib', 'lib', '-entry', 'PREPARE_GENOME', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"empty","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResChannel_empty___705(
        res=out_channels.get("res")
    )


class Resparams_fasta_index_749(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def params_fasta_index_749(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_714: typing.Union[bool, None],
    condition_732: typing.Union[bool, None]
) -> Resparams_fasta_index_749:
    cond = ((condition_714 == False) and (condition_732 == True))

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = []



        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome.nf', '-lib', 'lib', '-entry', 'PREPARE_GENOME', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"NotExpression":{"NotExpression":{"BooleanExpression":{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"fasta_index"}}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resparams_fasta_index_749(
        res=out_channels.get("res")
    )


class Resconditional_params_fasta_index_750(NamedTuple):
    condition: typing.Union[bool, None]

@task(cache=True)
def conditional_params_fasta_index_750(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_714: typing.Union[bool, None],
    condition_732: typing.Union[bool, None],
    channel_749: typing.Union[str, None]
) -> Resconditional_params_fasta_index_750:
    cond = ((condition_714 == False) and (condition_732 == True) and (channel_749 is not None))

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = [json.loads(channel_749)]



        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome.nf', '-lib', 'lib', '-entry', 'PREPARE_GENOME', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"condition"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"condition\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'condition': None}

    res = out_channels.get("condition")

    if res is not None:
        res = get_boolean_value(res)

    return Resconditional_params_fasta_index_750(condition=res)


class ResChannel_value_this_file_params_fasta_index___751(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_value_this_file_params_fasta_index___751(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_714: typing.Union[bool, None],
    condition_732: typing.Union[bool, None],
    condition_750: typing.Union[bool, None]
) -> ResChannel_value_this_file_params_fasta_index___751:
    cond = ((condition_714 == False) and (condition_732 == True) and (condition_750 == True))

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = []



        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome.nf', '-lib', 'lib', '-entry', 'PREPARE_GENOME', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"value","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"file","arguments":{"ArgumentListExpression":{"expressions":[{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"fasta_index"}}]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResChannel_value_this_file_params_fasta_index___751(
        res=out_channels.get("res")
    )


class Res______ch_fasta__752(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def ______ch_fasta__752(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_714: typing.Union[bool, None],
    condition_732: typing.Union[bool, None],
    condition_750: typing.Union[bool, None],
    channel_709: typing.Union[str, None]
) -> Res______ch_fasta__752:
    cond = ((condition_714 == False) and (condition_732 == True) and (condition_750 == False) and (channel_709 is not None))

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = [json.loads(channel_709)]



        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome.nf', '-lib', 'lib', '-entry', 'PREPARE_GENOME', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"ListExpression":[{"MapExpression":[]},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Res______ch_fasta__752(
        res=out_channels.get("res")
    )


@dataclass
class Dataclass_753_pre:
    wf_input: typing.List[Sample]
    wf_genome: Genome
    wf_save_reference: bool
    wf_save_align_intermeds: bool
    wf_aligner: Aligner
    wf_clip_r1: int
    wf_clip_r2: int
    wf_three_prime_clip_r1: int
    wf_three_prime_clip_r2: int
    wf_nextseq_trim: int
    wf_cytosine_report: bool
    wf_num_mismatches: float
    wf_skip_trimming: bool
    wf_skip_deduplication: bool
    wf_skip_multiqc: bool
    wf_outdir: str
    channel_752: str


class Res_753_pre(NamedTuple):
    default: typing.List[Dataclass_753_pre]
    is_skipped: bool

@task(cache=True)
def pre_adapter_SAMTOOLS_FAIDX_753_pre(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_714: typing.Union[bool, None],
    condition_732: typing.Union[bool, None],
    condition_750: typing.Union[bool, None],
    channel_752: typing.Union[str, None]
) -> Res_753_pre:
    cond = ((condition_714 == False) and (condition_732 == True) and (condition_750 == False) and (channel_752 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_753_pre, {'wf_input': wf_input, 'wf_genome': wf_genome, 'wf_save_reference': wf_save_reference, 'wf_save_align_intermeds': wf_save_align_intermeds, 'wf_aligner': wf_aligner, 'wf_clip_r1': wf_clip_r1, 'wf_clip_r2': wf_clip_r2, 'wf_three_prime_clip_r1': wf_three_prime_clip_r1, 'wf_three_prime_clip_r2': wf_three_prime_clip_r2, 'wf_nextseq_trim': wf_nextseq_trim, 'wf_cytosine_report': wf_cytosine_report, 'wf_num_mismatches': wf_num_mismatches, 'wf_skip_trimming': wf_skip_trimming, 'wf_skip_deduplication': wf_skip_deduplication, 'wf_skip_multiqc': wf_skip_multiqc, 'wf_outdir': wf_outdir}, {'channel_752': channel_752})
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        result = []

    return Res_753_pre(default=result, is_skipped = not cond)

class Respost_adapter_SAMTOOLS_FAIDX_753_post(NamedTuple):
    fai: typing.Union[str, None]
    gzi: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_753_post:
    fai: str
    gzi: str
    versions: str

@task(cache=True)
def post_adapter_SAMTOOLS_FAIDX_753_post(
    default: List[Dataclass_753_post],
    is_skipped: bool,
) -> Respost_adapter_SAMTOOLS_FAIDX_753_post:
    return get_mapper_outputs(Respost_adapter_SAMTOOLS_FAIDX_753_post, default, is_skipped)


def _read_resources() -> Dict:
    try:
        with open(".latch/resources.json") as f:
            return json.load(f)
    except FileNotFoundError:
        return {}

def allocate_cpu(default: Dataclass_753_pre) -> int:
    res = _read_resources()
    return max(1, res['cpu_cores']) if res.get('cpu_cores') is not None else 4

def allocate_memory(default: Dataclass_753_pre) -> int:
    res = _read_resources()
    return max(1, res['memory_bytes'] // 1024**3) if res.get('memory_bytes') is not None else 16

def allocate_disk(default: Dataclass_753_pre) -> int:
    res = _read_resources()
    return max(1, res['disk_bytes'] // 1024**3) if res.get('disk_bytes') is not None else 4800

def get_resources(default: Dataclass_753_pre):
    wf_paths = {}
    wf_input = default.wf_input
    wf_input = construct_samplesheet(wf_input)
    wf_genome = default.wf_genome
    wf_save_reference = default.wf_save_reference
    wf_save_align_intermeds = default.wf_save_align_intermeds
    wf_aligner = default.wf_aligner
    wf_clip_r1 = default.wf_clip_r1
    wf_clip_r2 = default.wf_clip_r2
    wf_three_prime_clip_r1 = default.wf_three_prime_clip_r1
    wf_three_prime_clip_r2 = default.wf_three_prime_clip_r2
    wf_nextseq_trim = default.wf_nextseq_trim
    wf_cytosine_report = default.wf_cytosine_report
    wf_num_mismatches = default.wf_num_mismatches
    wf_skip_trimming = default.wf_skip_trimming
    wf_skip_deduplication = default.wf_skip_deduplication
    wf_skip_multiqc = default.wf_skip_multiqc
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_752)]

    if not True:
        download_files(channel_vals, LatchDir('latch:///methylseq-outputs'))

    flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/local/prepare_genome.nf','-lib','lib','-profile','mamba','-entry','PREPARE_GENOME', *flags],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"SAMTOOLS_FAIDX","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"fai\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_FAIDX\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"gzi\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_FAIDX\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_FAIDX\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":2}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'True',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

@custom_task(cpu=allocate_cpu, memory=allocate_memory, storage_gib=allocate_disk, pre_execute=get_resources, cache=True)
def SAMTOOLS_FAIDX_753(
    default: Dataclass_753_pre
) -> Dataclass_753_post:
    wf_paths = {}
    wf_input = default.wf_input
    wf_input = construct_samplesheet(wf_input)
    wf_genome = default.wf_genome
    wf_save_reference = default.wf_save_reference
    wf_save_align_intermeds = default.wf_save_align_intermeds
    wf_aligner = default.wf_aligner
    wf_clip_r1 = default.wf_clip_r1
    wf_clip_r2 = default.wf_clip_r2
    wf_three_prime_clip_r1 = default.wf_three_prime_clip_r1
    wf_three_prime_clip_r2 = default.wf_three_prime_clip_r2
    wf_nextseq_trim = default.wf_nextseq_trim
    wf_cytosine_report = default.wf_cytosine_report
    wf_num_mismatches = default.wf_num_mismatches
    wf_skip_trimming = default.wf_skip_trimming
    wf_skip_deduplication = default.wf_skip_deduplication
    wf_skip_multiqc = default.wf_skip_multiqc
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_752)]

    if not False:
        download_files(channel_vals, LatchDir('latch:///methylseq-outputs'))

    flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/local/prepare_genome.nf','-lib','lib','-profile','mamba','-entry','PREPARE_GENOME', *flags],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"SAMTOOLS_FAIDX","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"fai\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_FAIDX\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"gzi\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_FAIDX\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_FAIDX\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":2}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'False',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = json.loads(file.read_text())

    print(out_channels)

    publish_dir = None
    upload_files(out_channels, LatchDir('latch:///methylseq-outputs'), publish_dir)

    out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    return Dataclass_753_post(
        fai=out_channels.get(f"fai"),
        gzi=out_channels.get(f"gzi"),
        versions=out_channels.get(f"versions")
    )


class Resmap_754(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def map_754(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_714: typing.Union[bool, None],
    condition_732: typing.Union[bool, None],
    condition_750: typing.Union[bool, None],
    channel_753_0: typing.Union[str, None]
) -> Resmap_754:
    cond = ((condition_714 == False) and (condition_732 == True) and (condition_750 == False) and (channel_753_0 is not None))

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = [json.loads(channel_753_0)]



        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome.nf', '-lib', 'lib', '-entry', 'PREPARE_GENOME', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"map","arguments":{"ArgumentListExpression":{"expressions":[{"ClosureExpression":{"code":{"BlockStatement":{"statements":[{"ReturnStatement":{"BinaryExpression":{"leftExpression":{"VariableExpression":"it"},"operation":"[","rightExpression":{"ConstantExpression":1}}}}],"scope":{"declaredVariables":[],"referencedClassVariables":[]},"labels":[]}},"parameters":[]}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmap_754(
        res=out_channels.get("res")
    )


class ResMerge_ch_fasta_index_756(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_fasta_index_756(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_714: typing.Union[bool, None],
    condition_732: typing.Union[bool, None],
    channel_751: typing.Union[str, None],
    channel_754: typing.Union[str, None]
) -> ResMerge_ch_fasta_index_756:
    cond = ((condition_714 == False) and (condition_732 == True))

    if cond:
        res = { 'res': channel_751 or channel_754 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_fasta_index_756(
        res=res.get('res')
    )


class ResMerge_ch_fasta_index_759(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_fasta_index_759(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_714: typing.Union[bool, None],
    channel_756: typing.Union[str, None],
    channel_705: typing.Union[str, None]
) -> ResMerge_ch_fasta_index_759:
    cond = ((condition_714 == False))

    if cond:
        res = { 'res': channel_756 or channel_705 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_fasta_index_759(
        res=res.get('res')
    )


class ResMerge_ch_fasta_index_765(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_fasta_index_765(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    channel_705: typing.Union[str, None],
    channel_759: typing.Union[str, None]
) -> ResMerge_ch_fasta_index_765:
    cond = True

    if cond:
        res = { 'res': channel_705 or channel_759 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_fasta_index_765(
        res=res.get('res')
    )


@dataclass
class Dataclass_870_pre:
    wf_input: typing.List[Sample]
    wf_genome: Genome
    wf_save_reference: bool
    wf_save_align_intermeds: bool
    wf_aligner: Aligner
    wf_clip_r1: int
    wf_clip_r2: int
    wf_three_prime_clip_r1: int
    wf_three_prime_clip_r2: int
    wf_nextseq_trim: int
    wf_cytosine_report: bool
    wf_num_mismatches: float
    wf_skip_trimming: bool
    wf_skip_deduplication: bool
    wf_skip_multiqc: bool
    wf_outdir: str
    channel_856_0: str
    channel_709: str
    channel_765: str


class Res_870_pre(NamedTuple):
    default: typing.List[Dataclass_870_pre]
    is_skipped: bool

@task(cache=True)
def pre_adapter_PICARD_MARKDUPLICATES_870_pre(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_794: typing.Union[bool, None],
    condition_851: typing.Union[bool, None],
    condition_867: typing.Union[bool, None],
    channel_856_0: typing.Union[str, None],
    channel_709: typing.Union[str, None],
    channel_765: typing.Union[str, None]
) -> Res_870_pre:
    cond = ((condition_794 == False) and (condition_851 == True) and (condition_867 == False) and (channel_856_0 is not None) and (channel_709 is not None) and (channel_765 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_870_pre, {'wf_input': wf_input, 'wf_genome': wf_genome, 'wf_save_reference': wf_save_reference, 'wf_save_align_intermeds': wf_save_align_intermeds, 'wf_aligner': wf_aligner, 'wf_clip_r1': wf_clip_r1, 'wf_clip_r2': wf_clip_r2, 'wf_three_prime_clip_r1': wf_three_prime_clip_r1, 'wf_three_prime_clip_r2': wf_three_prime_clip_r2, 'wf_nextseq_trim': wf_nextseq_trim, 'wf_cytosine_report': wf_cytosine_report, 'wf_num_mismatches': wf_num_mismatches, 'wf_skip_trimming': wf_skip_trimming, 'wf_skip_deduplication': wf_skip_deduplication, 'wf_skip_multiqc': wf_skip_multiqc, 'wf_outdir': wf_outdir}, {'channel_856_0': channel_856_0, 'channel_709': channel_709, 'channel_765': channel_765})
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        result = []

    return Res_870_pre(default=result, is_skipped = not cond)

class Respost_adapter_PICARD_MARKDUPLICATES_870_post(NamedTuple):
    bam: typing.Union[str, None]
    bai: typing.Union[str, None]
    metrics: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_870_post:
    bam: str
    bai: str
    metrics: str
    versions: str

@task(cache=True)
def post_adapter_PICARD_MARKDUPLICATES_870_post(
    default: List[Dataclass_870_post],
    is_skipped: bool,
) -> Respost_adapter_PICARD_MARKDUPLICATES_870_post:
    return get_mapper_outputs(Respost_adapter_PICARD_MARKDUPLICATES_870_post, default, is_skipped)


def _read_resources() -> Dict:
    try:
        with open(".latch/resources.json") as f:
            return json.load(f)
    except FileNotFoundError:
        return {}

def allocate_cpu(default: Dataclass_870_pre) -> int:
    res = _read_resources()
    return max(1, res['cpu_cores']) if res.get('cpu_cores') is not None else 8

def allocate_memory(default: Dataclass_870_pre) -> int:
    res = _read_resources()
    return max(1, res['memory_bytes'] // 1024**3) if res.get('memory_bytes') is not None else 48

def allocate_disk(default: Dataclass_870_pre) -> int:
    res = _read_resources()
    return max(1, res['disk_bytes'] // 1024**3) if res.get('disk_bytes') is not None else 4800

def get_resources(default: Dataclass_870_pre):
    wf_paths = {}
    wf_input = default.wf_input
    wf_input = construct_samplesheet(wf_input)
    wf_genome = default.wf_genome
    wf_save_reference = default.wf_save_reference
    wf_save_align_intermeds = default.wf_save_align_intermeds
    wf_aligner = default.wf_aligner
    wf_clip_r1 = default.wf_clip_r1
    wf_clip_r2 = default.wf_clip_r2
    wf_three_prime_clip_r1 = default.wf_three_prime_clip_r1
    wf_three_prime_clip_r2 = default.wf_three_prime_clip_r2
    wf_nextseq_trim = default.wf_nextseq_trim
    wf_cytosine_report = default.wf_cytosine_report
    wf_num_mismatches = default.wf_num_mismatches
    wf_skip_trimming = default.wf_skip_trimming
    wf_skip_deduplication = default.wf_skip_deduplication
    wf_skip_multiqc = default.wf_skip_multiqc
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_856_0),json.loads(default.channel_709),json.loads(default.channel_765)]

    if not True:
        download_files(channel_vals, LatchDir('latch:///methylseq-outputs'))

    flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/local/bwameth.nf','-lib','lib','-profile','mamba','-entry','BWAMETH', *flags],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"PICARD_MARKDUPLICATES","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"bam\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"PICARD_MARKDUPLICATES\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"bai\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"PICARD_MARKDUPLICATES\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"metrics\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"PICARD_MARKDUPLICATES\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":2}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"PICARD_MARKDUPLICATES\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":3}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'True',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

@custom_task(cpu=allocate_cpu, memory=allocate_memory, storage_gib=allocate_disk, pre_execute=get_resources, cache=True)
def PICARD_MARKDUPLICATES_870(
    default: Dataclass_870_pre
) -> Dataclass_870_post:
    wf_paths = {}
    wf_input = default.wf_input
    wf_input = construct_samplesheet(wf_input)
    wf_genome = default.wf_genome
    wf_save_reference = default.wf_save_reference
    wf_save_align_intermeds = default.wf_save_align_intermeds
    wf_aligner = default.wf_aligner
    wf_clip_r1 = default.wf_clip_r1
    wf_clip_r2 = default.wf_clip_r2
    wf_three_prime_clip_r1 = default.wf_three_prime_clip_r1
    wf_three_prime_clip_r2 = default.wf_three_prime_clip_r2
    wf_nextseq_trim = default.wf_nextseq_trim
    wf_cytosine_report = default.wf_cytosine_report
    wf_num_mismatches = default.wf_num_mismatches
    wf_skip_trimming = default.wf_skip_trimming
    wf_skip_deduplication = default.wf_skip_deduplication
    wf_skip_multiqc = default.wf_skip_multiqc
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_856_0),json.loads(default.channel_709),json.loads(default.channel_765)]

    if not False:
        download_files(channel_vals, LatchDir('latch:///methylseq-outputs'))

    flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/local/bwameth.nf','-lib','lib','-profile','mamba','-entry','BWAMETH', *flags],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"PICARD_MARKDUPLICATES","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"bam\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"PICARD_MARKDUPLICATES\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"bai\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"PICARD_MARKDUPLICATES\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"metrics\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"PICARD_MARKDUPLICATES\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":2}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"PICARD_MARKDUPLICATES\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":3}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'False',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = json.loads(file.read_text())

    print(out_channels)

    publish_dir = None
    upload_files(out_channels, LatchDir('latch:///methylseq-outputs'), publish_dir)

    out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    return Dataclass_870_post(
        bam=out_channels.get(f"bam"),
        bai=out_channels.get(f"bai"),
        metrics=out_channels.get(f"metrics"),
        versions=out_channels.get(f"versions")
    )


class ResMerge_picard_version_876(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_picard_version_876(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_794: typing.Union[bool, None],
    condition_851: typing.Union[bool, None],
    channel_869: typing.Union[str, None],
    channel_870_3: typing.Union[str, None]
) -> ResMerge_picard_version_876:
    cond = ((condition_794 == False) and (condition_851 == True))

    if cond:
        res = { 'res': channel_869 or channel_870_3 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_picard_version_876(
        res=res.get('res')
    )


class Resmap_723(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def map_723(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_714: typing.Union[bool, None],
    condition_716: typing.Union[bool, None],
    condition_719: typing.Union[bool, None],
    channel_722_0: typing.Union[str, None]
) -> Resmap_723:
    cond = ((condition_714 == True) and (condition_716 == True) and (condition_719 == True) and (channel_722_0 is not None))

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = [json.loads(channel_722_0)]



        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome.nf', '-lib', 'lib', '-entry', 'PREPARE_GENOME', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"map","arguments":{"ArgumentListExpression":{"expressions":[{"ClosureExpression":{"code":{"BlockStatement":{"statements":[{"ReturnStatement":{"BinaryExpression":{"leftExpression":{"VariableExpression":"it"},"operation":"[","rightExpression":{"ConstantExpression":1}}}}],"scope":{"declaredVariables":[],"referencedClassVariables":[]},"labels":[]}},"parameters":[]}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmap_723(
        res=out_channels.get("res")
    )


class ResChannel_value_this_file_params_bismark_index___724(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_value_this_file_params_bismark_index___724(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_714: typing.Union[bool, None],
    condition_716: typing.Union[bool, None],
    condition_719: typing.Union[bool, None]
) -> ResChannel_value_this_file_params_bismark_index___724:
    cond = ((condition_714 == True) and (condition_716 == True) and (condition_719 == False))

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = []



        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome.nf', '-lib', 'lib', '-entry', 'PREPARE_GENOME', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"value","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"file","arguments":{"ArgumentListExpression":{"expressions":[{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"bismark_index"}}]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResChannel_value_this_file_params_bismark_index___724(
        res=out_channels.get("res")
    )


class ResMerge_ch_bismark_index_725(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_bismark_index_725(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_714: typing.Union[bool, None],
    condition_716: typing.Union[bool, None],
    channel_723: typing.Union[str, None],
    channel_724: typing.Union[str, None]
) -> ResMerge_ch_bismark_index_725:
    cond = ((condition_714 == True) and (condition_716 == True))

    if cond:
        res = { 'res': channel_723 or channel_724 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_bismark_index_725(
        res=res.get('res')
    )


@dataclass
class Dataclass_726_pre:
    wf_input: typing.List[Sample]
    wf_genome: Genome
    wf_save_reference: bool
    wf_save_align_intermeds: bool
    wf_aligner: Aligner
    wf_clip_r1: int
    wf_clip_r2: int
    wf_three_prime_clip_r1: int
    wf_three_prime_clip_r2: int
    wf_nextseq_trim: int
    wf_cytosine_report: bool
    wf_num_mismatches: float
    wf_skip_trimming: bool
    wf_skip_deduplication: bool
    wf_skip_multiqc: bool
    wf_outdir: str
    channel_709: str


class Res_726_pre(NamedTuple):
    default: typing.List[Dataclass_726_pre]
    is_skipped: bool

@task(cache=True)
def pre_adapter_BISMARK_GENOMEPREPARATION_726_pre(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_714: typing.Union[bool, None],
    condition_716: typing.Union[bool, None],
    channel_709: typing.Union[str, None]
) -> Res_726_pre:
    cond = ((condition_714 == True) and (condition_716 == False) and (channel_709 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_726_pre, {'wf_input': wf_input, 'wf_genome': wf_genome, 'wf_save_reference': wf_save_reference, 'wf_save_align_intermeds': wf_save_align_intermeds, 'wf_aligner': wf_aligner, 'wf_clip_r1': wf_clip_r1, 'wf_clip_r2': wf_clip_r2, 'wf_three_prime_clip_r1': wf_three_prime_clip_r1, 'wf_three_prime_clip_r2': wf_three_prime_clip_r2, 'wf_nextseq_trim': wf_nextseq_trim, 'wf_cytosine_report': wf_cytosine_report, 'wf_num_mismatches': wf_num_mismatches, 'wf_skip_trimming': wf_skip_trimming, 'wf_skip_deduplication': wf_skip_deduplication, 'wf_skip_multiqc': wf_skip_multiqc, 'wf_outdir': wf_outdir}, {'channel_709': channel_709})
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        result = []

    return Res_726_pre(default=result, is_skipped = not cond)

class Respost_adapter_BISMARK_GENOMEPREPARATION_726_post(NamedTuple):
    index: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_726_post:
    index: str
    versions: str

@task(cache=True)
def post_adapter_BISMARK_GENOMEPREPARATION_726_post(
    default: List[Dataclass_726_post],
    is_skipped: bool,
) -> Respost_adapter_BISMARK_GENOMEPREPARATION_726_post:
    return get_mapper_outputs(Respost_adapter_BISMARK_GENOMEPREPARATION_726_post, default, is_skipped)


def _read_resources() -> Dict:
    try:
        with open(".latch/resources.json") as f:
            return json.load(f)
    except FileNotFoundError:
        return {}

def allocate_cpu(default: Dataclass_726_pre) -> int:
    res = _read_resources()
    return max(1, res['cpu_cores']) if res.get('cpu_cores') is not None else 12

def allocate_memory(default: Dataclass_726_pre) -> int:
    res = _read_resources()
    return max(1, res['memory_bytes'] // 1024**3) if res.get('memory_bytes') is not None else 72

def allocate_disk(default: Dataclass_726_pre) -> int:
    res = _read_resources()
    return max(1, res['disk_bytes'] // 1024**3) if res.get('disk_bytes') is not None else 4800

def get_resources(default: Dataclass_726_pre):
    wf_paths = {}
    wf_input = default.wf_input
    wf_input = construct_samplesheet(wf_input)
    wf_genome = default.wf_genome
    wf_save_reference = default.wf_save_reference
    wf_save_align_intermeds = default.wf_save_align_intermeds
    wf_aligner = default.wf_aligner
    wf_clip_r1 = default.wf_clip_r1
    wf_clip_r2 = default.wf_clip_r2
    wf_three_prime_clip_r1 = default.wf_three_prime_clip_r1
    wf_three_prime_clip_r2 = default.wf_three_prime_clip_r2
    wf_nextseq_trim = default.wf_nextseq_trim
    wf_cytosine_report = default.wf_cytosine_report
    wf_num_mismatches = default.wf_num_mismatches
    wf_skip_trimming = default.wf_skip_trimming
    wf_skip_deduplication = default.wf_skip_deduplication
    wf_skip_multiqc = default.wf_skip_multiqc
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_709)]

    if not True:
        download_files(channel_vals, LatchDir('latch:///methylseq-outputs'))

    flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/local/prepare_genome.nf','-lib','lib','-profile','mamba','-entry','PREPARE_GENOME', *flags],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"BISMARK_GENOMEPREPARATION","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"index\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"BISMARK_GENOMEPREPARATION\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"BISMARK_GENOMEPREPARATION\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'True',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

@custom_task(cpu=allocate_cpu, memory=allocate_memory, storage_gib=allocate_disk, pre_execute=get_resources, cache=True)
def BISMARK_GENOMEPREPARATION_726(
    default: Dataclass_726_pre
) -> Dataclass_726_post:
    wf_paths = {}
    wf_input = default.wf_input
    wf_input = construct_samplesheet(wf_input)
    wf_genome = default.wf_genome
    wf_save_reference = default.wf_save_reference
    wf_save_align_intermeds = default.wf_save_align_intermeds
    wf_aligner = default.wf_aligner
    wf_clip_r1 = default.wf_clip_r1
    wf_clip_r2 = default.wf_clip_r2
    wf_three_prime_clip_r1 = default.wf_three_prime_clip_r1
    wf_three_prime_clip_r2 = default.wf_three_prime_clip_r2
    wf_nextseq_trim = default.wf_nextseq_trim
    wf_cytosine_report = default.wf_cytosine_report
    wf_num_mismatches = default.wf_num_mismatches
    wf_skip_trimming = default.wf_skip_trimming
    wf_skip_deduplication = default.wf_skip_deduplication
    wf_skip_multiqc = default.wf_skip_multiqc
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_709)]

    if not False:
        download_files(channel_vals, LatchDir('latch:///methylseq-outputs'))

    flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/local/prepare_genome.nf','-lib','lib','-profile','mamba','-entry','PREPARE_GENOME', *flags],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"BISMARK_GENOMEPREPARATION","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"index\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"BISMARK_GENOMEPREPARATION\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"BISMARK_GENOMEPREPARATION\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'False',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = json.loads(file.read_text())

    print(out_channels)

    publish_dir = None
    upload_files(out_channels, LatchDir('latch:///methylseq-outputs'), publish_dir)

    out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    return Dataclass_726_post(
        index=out_channels.get(f"index"),
        versions=out_channels.get(f"versions")
    )


class ResMerge_ch_bismark_index_728(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_bismark_index_728(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_714: typing.Union[bool, None],
    channel_725: typing.Union[str, None],
    channel_726_0: typing.Union[str, None]
) -> ResMerge_ch_bismark_index_728:
    cond = ((condition_714 == True))

    if cond:
        res = { 'res': channel_725 or channel_726_0 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_bismark_index_728(
        res=res.get('res')
    )


class Resmap_741(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def map_741(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_714: typing.Union[bool, None],
    condition_732: typing.Union[bool, None],
    condition_734: typing.Union[bool, None],
    condition_737: typing.Union[bool, None],
    channel_740_0: typing.Union[str, None]
) -> Resmap_741:
    cond = ((condition_714 == False) and (condition_732 == True) and (condition_734 == True) and (condition_737 == True) and (channel_740_0 is not None))

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = [json.loads(channel_740_0)]



        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome.nf', '-lib', 'lib', '-entry', 'PREPARE_GENOME', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"map","arguments":{"ArgumentListExpression":{"expressions":[{"ClosureExpression":{"code":{"BlockStatement":{"statements":[{"ReturnStatement":{"BinaryExpression":{"leftExpression":{"VariableExpression":"it"},"operation":"[","rightExpression":{"ConstantExpression":1}}}}],"scope":{"declaredVariables":[],"referencedClassVariables":[]},"labels":[]}},"parameters":[]}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmap_741(
        res=out_channels.get("res")
    )


class ResChannel_value_this_file_params_bwa_meth_index___742(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_value_this_file_params_bwa_meth_index___742(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_714: typing.Union[bool, None],
    condition_732: typing.Union[bool, None],
    condition_734: typing.Union[bool, None],
    condition_737: typing.Union[bool, None]
) -> ResChannel_value_this_file_params_bwa_meth_index___742:
    cond = ((condition_714 == False) and (condition_732 == True) and (condition_734 == True) and (condition_737 == False))

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = []



        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome.nf', '-lib', 'lib', '-entry', 'PREPARE_GENOME', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"value","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"file","arguments":{"ArgumentListExpression":{"expressions":[{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"bwa_meth_index"}}]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResChannel_value_this_file_params_bwa_meth_index___742(
        res=out_channels.get("res")
    )


class ResMerge_ch_bismark_index_743(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_bismark_index_743(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_714: typing.Union[bool, None],
    condition_732: typing.Union[bool, None],
    condition_734: typing.Union[bool, None],
    channel_741: typing.Union[str, None],
    channel_742: typing.Union[str, None]
) -> ResMerge_ch_bismark_index_743:
    cond = ((condition_714 == False) and (condition_732 == True) and (condition_734 == True))

    if cond:
        res = { 'res': channel_741 or channel_742 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_bismark_index_743(
        res=res.get('res')
    )


class ResChannel_empty___703(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_empty___703(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str
) -> ResChannel_empty___703:
    cond = True

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = []



        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome.nf', '-lib', 'lib', '-entry', 'PREPARE_GENOME', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"empty","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResChannel_empty___703(
        res=out_channels.get("res")
    )


class ResMerge_ch_bismark_index_746(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_bismark_index_746(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_714: typing.Union[bool, None],
    condition_732: typing.Union[bool, None],
    channel_743: typing.Union[str, None],
    channel_703: typing.Union[str, None]
) -> ResMerge_ch_bismark_index_746:
    cond = ((condition_714 == False) and (condition_732 == True))

    if cond:
        res = { 'res': channel_743 or channel_703 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_bismark_index_746(
        res=res.get('res')
    )


class ResMerge_ch_bismark_index_758(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_bismark_index_758(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_714: typing.Union[bool, None],
    channel_746: typing.Union[str, None],
    channel_703: typing.Union[str, None]
) -> ResMerge_ch_bismark_index_758:
    cond = ((condition_714 == False))

    if cond:
        res = { 'res': channel_746 or channel_703 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_bismark_index_758(
        res=res.get('res')
    )


class ResMerge_ch_bismark_index_762(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_bismark_index_762(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    channel_728: typing.Union[str, None],
    channel_758: typing.Union[str, None]
) -> ResMerge_ch_bismark_index_762:
    cond = True

    if cond:
        res = { 'res': channel_728 or channel_758 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_bismark_index_762(
        res=res.get('res')
    )


@dataclass
class Dataclass_798_pre:
    wf_input: typing.List[Sample]
    wf_genome: Genome
    wf_save_reference: bool
    wf_save_align_intermeds: bool
    wf_aligner: Aligner
    wf_clip_r1: int
    wf_clip_r2: int
    wf_three_prime_clip_r1: int
    wf_three_prime_clip_r2: int
    wf_nextseq_trim: int
    wf_cytosine_report: bool
    wf_num_mismatches: float
    wf_skip_trimming: bool
    wf_skip_deduplication: bool
    wf_skip_multiqc: bool
    wf_outdir: str
    channel_788: str
    channel_762: str


class Res_798_pre(NamedTuple):
    default: typing.List[Dataclass_798_pre]
    is_skipped: bool

@task(cache=True)
def pre_adapter_BISMARK_ALIGN_798_pre(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_794: typing.Union[bool, None],
    channel_788: typing.Union[str, None],
    channel_762: typing.Union[str, None]
) -> Res_798_pre:
    cond = ((condition_794 == True) and (channel_788 is not None) and (channel_762 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_798_pre, {'wf_input': wf_input, 'wf_genome': wf_genome, 'wf_save_reference': wf_save_reference, 'wf_save_align_intermeds': wf_save_align_intermeds, 'wf_aligner': wf_aligner, 'wf_clip_r1': wf_clip_r1, 'wf_clip_r2': wf_clip_r2, 'wf_three_prime_clip_r1': wf_three_prime_clip_r1, 'wf_three_prime_clip_r2': wf_three_prime_clip_r2, 'wf_nextseq_trim': wf_nextseq_trim, 'wf_cytosine_report': wf_cytosine_report, 'wf_num_mismatches': wf_num_mismatches, 'wf_skip_trimming': wf_skip_trimming, 'wf_skip_deduplication': wf_skip_deduplication, 'wf_skip_multiqc': wf_skip_multiqc, 'wf_outdir': wf_outdir}, {'channel_788': channel_788, 'channel_762': channel_762})
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        result = []

    return Res_798_pre(default=result, is_skipped = not cond)

class Respost_adapter_BISMARK_ALIGN_798_post(NamedTuple):
    bam: typing.Union[str, None]
    report: typing.Union[str, None]
    unmapped: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_798_post:
    bam: str
    report: str
    unmapped: str
    versions: str

@task(cache=True)
def post_adapter_BISMARK_ALIGN_798_post(
    default: List[Dataclass_798_post],
    is_skipped: bool,
) -> Respost_adapter_BISMARK_ALIGN_798_post:
    return get_mapper_outputs(Respost_adapter_BISMARK_ALIGN_798_post, default, is_skipped)


def _read_resources() -> Dict:
    try:
        with open(".latch/resources.json") as f:
            return json.load(f)
    except FileNotFoundError:
        return {}

def allocate_cpu(default: Dataclass_798_pre) -> int:
    res = _read_resources()
    return max(1, res['cpu_cores']) if res.get('cpu_cores') is not None else 4

def allocate_memory(default: Dataclass_798_pre) -> int:
    res = _read_resources()
    return max(1, res['memory_bytes'] // 1024**3) if res.get('memory_bytes') is not None else 16

def allocate_disk(default: Dataclass_798_pre) -> int:
    res = _read_resources()
    return max(1, res['disk_bytes'] // 1024**3) if res.get('disk_bytes') is not None else 4800

def get_resources(default: Dataclass_798_pre):
    wf_paths = {}
    wf_input = default.wf_input
    wf_input = construct_samplesheet(wf_input)
    wf_genome = default.wf_genome
    wf_save_reference = default.wf_save_reference
    wf_save_align_intermeds = default.wf_save_align_intermeds
    wf_aligner = default.wf_aligner
    wf_clip_r1 = default.wf_clip_r1
    wf_clip_r2 = default.wf_clip_r2
    wf_three_prime_clip_r1 = default.wf_three_prime_clip_r1
    wf_three_prime_clip_r2 = default.wf_three_prime_clip_r2
    wf_nextseq_trim = default.wf_nextseq_trim
    wf_cytosine_report = default.wf_cytosine_report
    wf_num_mismatches = default.wf_num_mismatches
    wf_skip_trimming = default.wf_skip_trimming
    wf_skip_deduplication = default.wf_skip_deduplication
    wf_skip_multiqc = default.wf_skip_multiqc
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_788),json.loads(default.channel_762)]

    if not True:
        download_files(channel_vals, LatchDir('latch:///methylseq-outputs'))

    flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/local/bismark.nf','-lib','lib','-profile','mamba','-entry','BISMARK', *flags],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"BISMARK_ALIGN","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"bam\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"BISMARK_ALIGN\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"report\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"BISMARK_ALIGN\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"unmapped\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"BISMARK_ALIGN\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":2}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"BISMARK_ALIGN\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":3}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'True',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

@custom_task(cpu=allocate_cpu, memory=allocate_memory, storage_gib=allocate_disk, pre_execute=get_resources, cache=True)
def BISMARK_ALIGN_798(
    default: Dataclass_798_pre
) -> Dataclass_798_post:
    wf_paths = {}
    wf_input = default.wf_input
    wf_input = construct_samplesheet(wf_input)
    wf_genome = default.wf_genome
    wf_save_reference = default.wf_save_reference
    wf_save_align_intermeds = default.wf_save_align_intermeds
    wf_aligner = default.wf_aligner
    wf_clip_r1 = default.wf_clip_r1
    wf_clip_r2 = default.wf_clip_r2
    wf_three_prime_clip_r1 = default.wf_three_prime_clip_r1
    wf_three_prime_clip_r2 = default.wf_three_prime_clip_r2
    wf_nextseq_trim = default.wf_nextseq_trim
    wf_cytosine_report = default.wf_cytosine_report
    wf_num_mismatches = default.wf_num_mismatches
    wf_skip_trimming = default.wf_skip_trimming
    wf_skip_deduplication = default.wf_skip_deduplication
    wf_skip_multiqc = default.wf_skip_multiqc
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_788),json.loads(default.channel_762)]

    if not False:
        download_files(channel_vals, LatchDir('latch:///methylseq-outputs'))

    flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/local/bismark.nf','-lib','lib','-profile','mamba','-entry','BISMARK', *flags],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"BISMARK_ALIGN","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"bam\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"BISMARK_ALIGN\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"report\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"BISMARK_ALIGN\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"unmapped\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"BISMARK_ALIGN\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":2}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"BISMARK_ALIGN\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":3}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'False',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = json.loads(file.read_text())

    print(out_channels)

    publish_dir = None
    upload_files(out_channels, LatchDir('latch:///methylseq-outputs'), publish_dir)

    out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    return Dataclass_798_post(
        bam=out_channels.get(f"bam"),
        report=out_channels.get(f"report"),
        unmapped=out_channels.get(f"unmapped"),
        versions=out_channels.get(f"versions")
    )


@dataclass
class Dataclass_800_pre:
    wf_input: typing.List[Sample]
    wf_genome: Genome
    wf_save_reference: bool
    wf_save_align_intermeds: bool
    wf_aligner: Aligner
    wf_clip_r1: int
    wf_clip_r2: int
    wf_three_prime_clip_r1: int
    wf_three_prime_clip_r2: int
    wf_nextseq_trim: int
    wf_cytosine_report: bool
    wf_num_mismatches: float
    wf_skip_trimming: bool
    wf_skip_deduplication: bool
    wf_skip_multiqc: bool
    wf_outdir: str
    channel_798_0: str


class Res_800_pre(NamedTuple):
    default: typing.List[Dataclass_800_pre]
    is_skipped: bool

@task(cache=True)
def pre_adapter_SAMTOOLS_SORT_ALIGNED_800_pre(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_794: typing.Union[bool, None],
    channel_798_0: typing.Union[str, None]
) -> Res_800_pre:
    cond = ((condition_794 == True) and (channel_798_0 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_800_pre, {'wf_input': wf_input, 'wf_genome': wf_genome, 'wf_save_reference': wf_save_reference, 'wf_save_align_intermeds': wf_save_align_intermeds, 'wf_aligner': wf_aligner, 'wf_clip_r1': wf_clip_r1, 'wf_clip_r2': wf_clip_r2, 'wf_three_prime_clip_r1': wf_three_prime_clip_r1, 'wf_three_prime_clip_r2': wf_three_prime_clip_r2, 'wf_nextseq_trim': wf_nextseq_trim, 'wf_cytosine_report': wf_cytosine_report, 'wf_num_mismatches': wf_num_mismatches, 'wf_skip_trimming': wf_skip_trimming, 'wf_skip_deduplication': wf_skip_deduplication, 'wf_skip_multiqc': wf_skip_multiqc, 'wf_outdir': wf_outdir}, {'channel_798_0': channel_798_0})
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        result = []

    return Res_800_pre(default=result, is_skipped = not cond)

class Respost_adapter_SAMTOOLS_SORT_ALIGNED_800_post(NamedTuple):
    bam: typing.Union[str, None]
    csi: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_800_post:
    bam: str
    csi: str
    versions: str

@task(cache=True)
def post_adapter_SAMTOOLS_SORT_ALIGNED_800_post(
    default: List[Dataclass_800_post],
    is_skipped: bool,
) -> Respost_adapter_SAMTOOLS_SORT_ALIGNED_800_post:
    return get_mapper_outputs(Respost_adapter_SAMTOOLS_SORT_ALIGNED_800_post, default, is_skipped)


def _read_resources() -> Dict:
    try:
        with open(".latch/resources.json") as f:
            return json.load(f)
    except FileNotFoundError:
        return {}

def allocate_cpu(default: Dataclass_800_pre) -> int:
    res = _read_resources()
    return max(1, res['cpu_cores']) if res.get('cpu_cores') is not None else 8

def allocate_memory(default: Dataclass_800_pre) -> int:
    res = _read_resources()
    return max(1, res['memory_bytes'] // 1024**3) if res.get('memory_bytes') is not None else 48

def allocate_disk(default: Dataclass_800_pre) -> int:
    res = _read_resources()
    return max(1, res['disk_bytes'] // 1024**3) if res.get('disk_bytes') is not None else 4800

def get_resources(default: Dataclass_800_pre):
    wf_paths = {}
    wf_input = default.wf_input
    wf_input = construct_samplesheet(wf_input)
    wf_genome = default.wf_genome
    wf_save_reference = default.wf_save_reference
    wf_save_align_intermeds = default.wf_save_align_intermeds
    wf_aligner = default.wf_aligner
    wf_clip_r1 = default.wf_clip_r1
    wf_clip_r2 = default.wf_clip_r2
    wf_three_prime_clip_r1 = default.wf_three_prime_clip_r1
    wf_three_prime_clip_r2 = default.wf_three_prime_clip_r2
    wf_nextseq_trim = default.wf_nextseq_trim
    wf_cytosine_report = default.wf_cytosine_report
    wf_num_mismatches = default.wf_num_mismatches
    wf_skip_trimming = default.wf_skip_trimming
    wf_skip_deduplication = default.wf_skip_deduplication
    wf_skip_multiqc = default.wf_skip_multiqc
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_798_0)]

    if not True:
        download_files(channel_vals, LatchDir('latch:///methylseq-outputs'))

    flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/local/bismark.nf','-lib','lib','-profile','mamba','-entry','BISMARK', *flags],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"SAMTOOLS_SORT_ALIGNED","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"bam\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_SORT_ALIGNED\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"csi\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_SORT_ALIGNED\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_SORT_ALIGNED\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":2}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'True',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

@custom_task(cpu=allocate_cpu, memory=allocate_memory, storage_gib=allocate_disk, pre_execute=get_resources, cache=True)
def SAMTOOLS_SORT_ALIGNED_800(
    default: Dataclass_800_pre
) -> Dataclass_800_post:
    wf_paths = {}
    wf_input = default.wf_input
    wf_input = construct_samplesheet(wf_input)
    wf_genome = default.wf_genome
    wf_save_reference = default.wf_save_reference
    wf_save_align_intermeds = default.wf_save_align_intermeds
    wf_aligner = default.wf_aligner
    wf_clip_r1 = default.wf_clip_r1
    wf_clip_r2 = default.wf_clip_r2
    wf_three_prime_clip_r1 = default.wf_three_prime_clip_r1
    wf_three_prime_clip_r2 = default.wf_three_prime_clip_r2
    wf_nextseq_trim = default.wf_nextseq_trim
    wf_cytosine_report = default.wf_cytosine_report
    wf_num_mismatches = default.wf_num_mismatches
    wf_skip_trimming = default.wf_skip_trimming
    wf_skip_deduplication = default.wf_skip_deduplication
    wf_skip_multiqc = default.wf_skip_multiqc
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_798_0)]

    if not False:
        download_files(channel_vals, LatchDir('latch:///methylseq-outputs'))

    flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/local/bismark.nf','-lib','lib','-profile','mamba','-entry','BISMARK', *flags],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"SAMTOOLS_SORT_ALIGNED","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"bam\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_SORT_ALIGNED\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"csi\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_SORT_ALIGNED\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_SORT_ALIGNED\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":2}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'False',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = json.loads(file.read_text())

    print(out_channels)

    publish_dir = None
    upload_files(out_channels, LatchDir('latch:///methylseq-outputs'), publish_dir)

    out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    return Dataclass_800_post(
        bam=out_channels.get(f"bam"),
        csi=out_channels.get(f"csi"),
        versions=out_channels.get(f"versions")
    )


class ResMerge_ch_bam_896(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_bam_896(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    channel_800_0: typing.Union[str, None],
    channel_856_0: typing.Union[str, None]
) -> ResMerge_ch_bam_896:
    cond = True

    if cond:
        res = { 'res': channel_800_0 or channel_856_0 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_bam_896(
        res=res.get('res')
    )


class Resparams_skip_multiqc_912(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def params_skip_multiqc_912(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str
) -> Resparams_skip_multiqc_912:
    cond = True

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = []



        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/methylseq.nf', '-lib', 'lib', '-entry', 'METHYLSEQ', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"NotExpression":{"NotExpression":{"NotExpression":{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"skip_multiqc"}}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resparams_skip_multiqc_912(
        res=out_channels.get("res")
    )


class Resparams_skip_multiqc_913(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def params_skip_multiqc_913(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    channel_912: typing.Union[str, None]
) -> Resparams_skip_multiqc_913:
    cond = ((channel_912 is not None))

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = [json.loads(channel_912)]



        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/methylseq.nf', '-lib', 'lib', '-entry', 'METHYLSEQ', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"toBoolean","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resparams_skip_multiqc_913(
        res=out_channels.get("res")
    )


class Resconditional_params_skip_multiqc_914(NamedTuple):
    condition: typing.Union[bool, None]

@task(cache=True)
def conditional_params_skip_multiqc_914(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    channel_913: typing.Union[str, None]
) -> Resconditional_params_skip_multiqc_914:
    cond = ((channel_913 is not None))

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = [json.loads(channel_913)]



        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/methylseq.nf', '-lib', 'lib', '-entry', 'METHYLSEQ', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"condition"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"condition\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'condition': None}

    res = out_channels.get("condition")

    if res is not None:
        res = get_boolean_value(res)

    return Resconditional_params_skip_multiqc_914(condition=res)


class Resparams_skip_trimming_929(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def params_skip_trimming_929(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_914: typing.Union[bool, None]
) -> Resparams_skip_trimming_929:
    cond = ((condition_914 == True))

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = []



        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/methylseq.nf', '-lib', 'lib', '-entry', 'METHYLSEQ', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"NotExpression":{"NotExpression":{"NotExpression":{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"skip_trimming"}}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resparams_skip_trimming_929(
        res=out_channels.get("res")
    )


class Resparams_skip_trimming_930(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def params_skip_trimming_930(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_914: typing.Union[bool, None],
    channel_929: typing.Union[str, None]
) -> Resparams_skip_trimming_930:
    cond = ((condition_914 == True) and (channel_929 is not None))

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = [json.loads(channel_929)]



        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/methylseq.nf', '-lib', 'lib', '-entry', 'METHYLSEQ', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"toBoolean","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resparams_skip_trimming_930(
        res=out_channels.get("res")
    )


class Resconditional_params_skip_trimming_931(NamedTuple):
    condition: typing.Union[bool, None]

@task(cache=True)
def conditional_params_skip_trimming_931(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_914: typing.Union[bool, None],
    channel_930: typing.Union[str, None]
) -> Resconditional_params_skip_trimming_931:
    cond = ((condition_914 == True) and (channel_930 is not None))

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = [json.loads(channel_930)]



        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/methylseq.nf', '-lib', 'lib', '-entry', 'METHYLSEQ', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"condition"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"condition\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'condition': None}

    res = out_channels.get("condition")

    if res is not None:
        res = get_boolean_value(res)

    return Resconditional_params_skip_trimming_931(condition=res)


class ResChannel_empty___917(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_empty___917(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_914: typing.Union[bool, None]
) -> ResChannel_empty___917:
    cond = ((condition_914 == True))

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = []



        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/methylseq.nf', '-lib', 'lib', '-entry', 'METHYLSEQ', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"empty","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResChannel_empty___917(
        res=out_channels.get("res")
    )


class ResChannel_value_WorkflowMethylseq_paramsSummaryMultiqc_workflow__s_915(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_value_WorkflowMethylseq_paramsSummaryMultiqc_workflow__s_915(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_914: typing.Union[bool, None]
) -> ResChannel_value_WorkflowMethylseq_paramsSummaryMultiqc_workflow__s_915:
    cond = ((condition_914 == True))

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = []



        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/methylseq.nf', '-lib', 'lib', '-entry', 'METHYLSEQ', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"value","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"WorkflowMethylseq"},"method":"paramsSummaryMultiqc","arguments":{"ArgumentListExpression":{"expressions":[{"VariableExpression":"workflow"},{"VariableExpression":"summary_params"}]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResChannel_value_WorkflowMethylseq_paramsSummaryMultiqc_workflow__s_915(
        res=out_channels.get("res")
    )


class RescollectFile_918(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def collectFile_918(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_914: typing.Union[bool, None],
    channel_915: typing.Union[str, None]
) -> RescollectFile_918:
    cond = ((condition_914 == True) and (channel_915 is not None))

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = [json.loads(channel_915)]

        download_files(channel_vals, LatchDir('latch:///methylseq-outputs'))

        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/methylseq.nf', '-lib', 'lib', '-entry', 'METHYLSEQ', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"collectFile","arguments":{"ArgumentListExpression":{"expressions":[{"MapExpression":[{"MapEntryExpression":{"keyExpression":{"ConstantExpression":"name"},"valueExpression":{"ConstantExpression":"workflow_summary_mqc.yaml"}}}]}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())

        upload_files(out_channels, LatchDir('latch:///methylseq-outputs'))

        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return RescollectFile_918(
        res=out_channels.get("res")
    )


class Resmix_919(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_919(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_914: typing.Union[bool, None],
    channel_917: typing.Union[str, None],
    channel_918: typing.Union[str, None]
) -> Resmix_919:
    cond = ((condition_914 == True) and (channel_917 is not None) and (channel_918 is not None))

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = [json.loads(channel_917), json.loads(channel_918)]



        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/methylseq.nf', '-lib', 'lib', '-entry', 'METHYLSEQ', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_919(
        res=out_channels.get("res")
    )


class ResChannel_value_WorkflowMethylseq_methodsDescriptionText_workflow__916(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_value_WorkflowMethylseq_methodsDescriptionText_workflow__916(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_914: typing.Union[bool, None]
) -> ResChannel_value_WorkflowMethylseq_methodsDescriptionText_workflow__916:
    cond = ((condition_914 == True))

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = []



        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/methylseq.nf', '-lib', 'lib', '-entry', 'METHYLSEQ', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"value","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"WorkflowMethylseq"},"method":"methodsDescriptionText","arguments":{"ArgumentListExpression":{"expressions":[{"VariableExpression":"workflow"},{"VariableExpression":"ch_multiqc_custom_methods_description"},{"VariableExpression":"params"}]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResChannel_value_WorkflowMethylseq_methodsDescriptionText_workflow__916(
        res=out_channels.get("res")
    )


class RescollectFile_920(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def collectFile_920(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_914: typing.Union[bool, None],
    channel_916: typing.Union[str, None]
) -> RescollectFile_920:
    cond = ((condition_914 == True) and (channel_916 is not None))

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = [json.loads(channel_916)]

        download_files(channel_vals, LatchDir('latch:///methylseq-outputs'))

        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/methylseq.nf', '-lib', 'lib', '-entry', 'METHYLSEQ', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"collectFile","arguments":{"ArgumentListExpression":{"expressions":[{"MapExpression":[{"MapEntryExpression":{"keyExpression":{"ConstantExpression":"name"},"valueExpression":{"ConstantExpression":"methods_description_mqc.yaml"}}}]}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())

        upload_files(out_channels, LatchDir('latch:///methylseq-outputs'))

        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return RescollectFile_920(
        res=out_channels.get("res")
    )


class Resmix_921(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_921(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_914: typing.Union[bool, None],
    channel_919: typing.Union[str, None],
    channel_920: typing.Union[str, None]
) -> Resmix_921:
    cond = ((condition_914 == True) and (channel_919 is not None) and (channel_920 is not None))

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = [json.loads(channel_919), json.loads(channel_920)]



        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/methylseq.nf', '-lib', 'lib', '-entry', 'METHYLSEQ', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_921(
        res=out_channels.get("res")
    )


class ResChannel_empty___689(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_empty___689(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str
) -> ResChannel_empty___689:
    cond = True

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = []



        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/methylseq.nf', '-lib', 'lib', '-entry', 'METHYLSEQ', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"empty","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResChannel_empty___689(
        res=out_channels.get("res")
    )


class ResChannel_empty___701(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_empty___701(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str
) -> ResChannel_empty___701:
    cond = True

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = []



        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome.nf', '-lib', 'lib', '-entry', 'PREPARE_GENOME', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"empty","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResChannel_empty___701(
        res=out_channels.get("res")
    )


class Resmix_727(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_727(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_714: typing.Union[bool, None],
    condition_716: typing.Union[bool, None],
    channel_701: typing.Union[str, None],
    channel_726_1: typing.Union[str, None]
) -> Resmix_727:
    cond = ((condition_714 == True) and (condition_716 == False) and (channel_701 is not None) and (channel_726_1 is not None))

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = [json.loads(channel_701), json.loads(channel_726_1)]



        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome.nf', '-lib', 'lib', '-entry', 'PREPARE_GENOME', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_727(
        res=out_channels.get("res")
    )


class ResMerge_ch_versions_729(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_versions_729(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_714: typing.Union[bool, None],
    channel_701: typing.Union[str, None],
    channel_727: typing.Union[str, None]
) -> ResMerge_ch_versions_729:
    cond = ((condition_714 == True))

    if cond:
        res = { 'res': channel_701 or channel_727 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_versions_729(
        res=res.get('res')
    )


class Resmix_745(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_745(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_714: typing.Union[bool, None],
    condition_732: typing.Union[bool, None],
    condition_734: typing.Union[bool, None],
    channel_701: typing.Union[str, None],
    channel_744_1: typing.Union[str, None]
) -> Resmix_745:
    cond = ((condition_714 == False) and (condition_732 == True) and (condition_734 == False) and (channel_701 is not None) and (channel_744_1 is not None))

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = [json.loads(channel_701), json.loads(channel_744_1)]



        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome.nf', '-lib', 'lib', '-entry', 'PREPARE_GENOME', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_745(
        res=out_channels.get("res")
    )


class ResMerge_ch_versions_748(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_versions_748(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_714: typing.Union[bool, None],
    condition_732: typing.Union[bool, None],
    channel_701: typing.Union[str, None],
    channel_745: typing.Union[str, None]
) -> ResMerge_ch_versions_748:
    cond = ((condition_714 == False) and (condition_732 == True))

    if cond:
        res = { 'res': channel_701 or channel_745 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_versions_748(
        res=res.get('res')
    )


class Resmix_755(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_755(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_714: typing.Union[bool, None],
    condition_732: typing.Union[bool, None],
    condition_750: typing.Union[bool, None],
    channel_748: typing.Union[str, None],
    channel_753_2: typing.Union[str, None]
) -> Resmix_755:
    cond = ((condition_714 == False) and (condition_732 == True) and (condition_750 == False) and (channel_748 is not None) and (channel_753_2 is not None))

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = [json.loads(channel_748), json.loads(channel_753_2)]



        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome.nf', '-lib', 'lib', '-entry', 'PREPARE_GENOME', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_755(
        res=out_channels.get("res")
    )


class ResMerge_ch_versions_757(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_versions_757(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_714: typing.Union[bool, None],
    condition_732: typing.Union[bool, None],
    channel_748: typing.Union[str, None],
    channel_755: typing.Union[str, None]
) -> ResMerge_ch_versions_757:
    cond = ((condition_714 == False) and (condition_732 == True))

    if cond:
        res = { 'res': channel_748 or channel_755 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_versions_757(
        res=res.get('res')
    )


class ResMerge_ch_versions_761(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_versions_761(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_714: typing.Union[bool, None],
    channel_757: typing.Union[str, None],
    channel_701: typing.Union[str, None]
) -> ResMerge_ch_versions_761:
    cond = ((condition_714 == False))

    if cond:
        res = { 'res': channel_757 or channel_701 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_versions_761(
        res=res.get('res')
    )


class ResMerge_ch_versions_764(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_versions_764(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    channel_729: typing.Union[str, None],
    channel_761: typing.Union[str, None]
) -> ResMerge_ch_versions_764:
    cond = True

    if cond:
        res = { 'res': channel_729 or channel_761 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_versions_764(
        res=res.get('res')
    )


class ResifEmpty_767(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def ifEmpty_767(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    channel_764: typing.Union[str, None]
) -> ResifEmpty_767:
    cond = ((channel_764 is not None))

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = [json.loads(channel_764)]



        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome.nf', '-lib', 'lib', '-entry', 'PREPARE_GENOME', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"ifEmpty","arguments":{"ArgumentListExpression":{"expressions":[{"ConstantExpression":null}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResifEmpty_767(
        res=out_channels.get("res")
    )


class Resmix_768(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_768(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    channel_689: typing.Union[str, None],
    channel_767: typing.Union[str, None]
) -> Resmix_768:
    cond = ((channel_689 is not None) and (channel_767 is not None))

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = [json.loads(channel_689), json.loads(channel_767)]



        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/methylseq.nf', '-lib', 'lib', '-entry', 'METHYLSEQ', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_768(
        res=out_channels.get("res")
    )


class Resfirst_777(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def first_777(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    channel_775_1: typing.Union[str, None]
) -> Resfirst_777:
    cond = ((channel_775_1 is not None))

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = [json.loads(channel_775_1)]



        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/methylseq.nf', '-lib', 'lib', '-entry', 'METHYLSEQ', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"first","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resfirst_777(
        res=out_channels.get("res")
    )


class Resmix_778(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_778(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    channel_768: typing.Union[str, None],
    channel_777: typing.Union[str, None]
) -> Resmix_778:
    cond = ((channel_768 is not None) and (channel_777 is not None))

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = [json.loads(channel_768), json.loads(channel_777)]



        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/methylseq.nf', '-lib', 'lib', '-entry', 'METHYLSEQ', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_778(
        res=out_channels.get("res")
    )


@dataclass
class Dataclass_779_pre:
    wf_input: typing.List[Sample]
    wf_genome: Genome
    wf_save_reference: bool
    wf_save_align_intermeds: bool
    wf_aligner: Aligner
    wf_clip_r1: int
    wf_clip_r2: int
    wf_three_prime_clip_r1: int
    wf_three_prime_clip_r2: int
    wf_nextseq_trim: int
    wf_cytosine_report: bool
    wf_num_mismatches: float
    wf_skip_trimming: bool
    wf_skip_deduplication: bool
    wf_skip_multiqc: bool
    wf_outdir: str
    channel_776: str


class Res_779_pre(NamedTuple):
    default: typing.List[Dataclass_779_pre]
    is_skipped: bool

@task(cache=True)
def pre_adapter_FASTQC_779_pre(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    channel_776: typing.Union[str, None]
) -> Res_779_pre:
    cond = ((channel_776 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_779_pre, {'wf_input': wf_input, 'wf_genome': wf_genome, 'wf_save_reference': wf_save_reference, 'wf_save_align_intermeds': wf_save_align_intermeds, 'wf_aligner': wf_aligner, 'wf_clip_r1': wf_clip_r1, 'wf_clip_r2': wf_clip_r2, 'wf_three_prime_clip_r1': wf_three_prime_clip_r1, 'wf_three_prime_clip_r2': wf_three_prime_clip_r2, 'wf_nextseq_trim': wf_nextseq_trim, 'wf_cytosine_report': wf_cytosine_report, 'wf_num_mismatches': wf_num_mismatches, 'wf_skip_trimming': wf_skip_trimming, 'wf_skip_deduplication': wf_skip_deduplication, 'wf_skip_multiqc': wf_skip_multiqc, 'wf_outdir': wf_outdir}, {'channel_776': channel_776})
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        result = []

    return Res_779_pre(default=result, is_skipped = not cond)

class Respost_adapter_FASTQC_779_post(NamedTuple):
    html: typing.Union[str, None]
    zip: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_779_post:
    html: str
    zip: str
    versions: str

@task(cache=True)
def post_adapter_FASTQC_779_post(
    default: List[Dataclass_779_post],
    is_skipped: bool,
) -> Respost_adapter_FASTQC_779_post:
    return get_mapper_outputs(Respost_adapter_FASTQC_779_post, default, is_skipped)


def _read_resources() -> Dict:
    try:
        with open(".latch/resources.json") as f:
            return json.load(f)
    except FileNotFoundError:
        return {}

def allocate_cpu(default: Dataclass_779_pre) -> int:
    res = _read_resources()
    return max(1, res['cpu_cores']) if res.get('cpu_cores') is not None else 8

def allocate_memory(default: Dataclass_779_pre) -> int:
    res = _read_resources()
    return max(1, res['memory_bytes'] // 1024**3) if res.get('memory_bytes') is not None else 48

def allocate_disk(default: Dataclass_779_pre) -> int:
    res = _read_resources()
    return max(1, res['disk_bytes'] // 1024**3) if res.get('disk_bytes') is not None else 4800

def get_resources(default: Dataclass_779_pre):
    wf_paths = {}
    wf_input = default.wf_input
    wf_input = construct_samplesheet(wf_input)
    wf_genome = default.wf_genome
    wf_save_reference = default.wf_save_reference
    wf_save_align_intermeds = default.wf_save_align_intermeds
    wf_aligner = default.wf_aligner
    wf_clip_r1 = default.wf_clip_r1
    wf_clip_r2 = default.wf_clip_r2
    wf_three_prime_clip_r1 = default.wf_three_prime_clip_r1
    wf_three_prime_clip_r2 = default.wf_three_prime_clip_r2
    wf_nextseq_trim = default.wf_nextseq_trim
    wf_cytosine_report = default.wf_cytosine_report
    wf_num_mismatches = default.wf_num_mismatches
    wf_skip_trimming = default.wf_skip_trimming
    wf_skip_deduplication = default.wf_skip_deduplication
    wf_skip_multiqc = default.wf_skip_multiqc
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_776)]

    if not True:
        download_files(channel_vals, LatchDir('latch:///methylseq-outputs'))

    flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/workflows/methylseq.nf','-lib','lib','-profile','mamba','-entry','METHYLSEQ', *flags],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"FASTQC","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"html\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"FASTQC\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"zip\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"FASTQC\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"FASTQC\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":2}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'True',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

@custom_task(cpu=allocate_cpu, memory=allocate_memory, storage_gib=allocate_disk, pre_execute=get_resources, cache=True)
def FASTQC_779(
    default: Dataclass_779_pre
) -> Dataclass_779_post:
    wf_paths = {}
    wf_input = default.wf_input
    wf_input = construct_samplesheet(wf_input)
    wf_genome = default.wf_genome
    wf_save_reference = default.wf_save_reference
    wf_save_align_intermeds = default.wf_save_align_intermeds
    wf_aligner = default.wf_aligner
    wf_clip_r1 = default.wf_clip_r1
    wf_clip_r2 = default.wf_clip_r2
    wf_three_prime_clip_r1 = default.wf_three_prime_clip_r1
    wf_three_prime_clip_r2 = default.wf_three_prime_clip_r2
    wf_nextseq_trim = default.wf_nextseq_trim
    wf_cytosine_report = default.wf_cytosine_report
    wf_num_mismatches = default.wf_num_mismatches
    wf_skip_trimming = default.wf_skip_trimming
    wf_skip_deduplication = default.wf_skip_deduplication
    wf_skip_multiqc = default.wf_skip_multiqc
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_776)]

    if not False:
        download_files(channel_vals, LatchDir('latch:///methylseq-outputs'))

    flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/workflows/methylseq.nf','-lib','lib','-profile','mamba','-entry','METHYLSEQ', *flags],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"FASTQC","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"html\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"FASTQC\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"zip\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"FASTQC\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"FASTQC\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":2}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'False',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = json.loads(file.read_text())

    print(out_channels)

    publish_dir = None
    upload_files(out_channels, LatchDir('latch:///methylseq-outputs'), publish_dir)

    out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    return Dataclass_779_post(
        html=out_channels.get(f"html"),
        zip=out_channels.get(f"zip"),
        versions=out_channels.get(f"versions")
    )


class Resfirst_780(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def first_780(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    channel_779_2: typing.Union[str, None]
) -> Resfirst_780:
    cond = ((channel_779_2 is not None))

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = [json.loads(channel_779_2)]



        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/methylseq.nf', '-lib', 'lib', '-entry', 'METHYLSEQ', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"first","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resfirst_780(
        res=out_channels.get("res")
    )


class Resmix_781(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_781(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    channel_778: typing.Union[str, None],
    channel_780: typing.Union[str, None]
) -> Resmix_781:
    cond = ((channel_778 is not None) and (channel_780 is not None))

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = [json.loads(channel_778), json.loads(channel_780)]



        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/methylseq.nf', '-lib', 'lib', '-entry', 'METHYLSEQ', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_781(
        res=out_channels.get("res")
    )


class Resfirst_786(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def first_786(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_784: typing.Union[bool, None],
    channel_785_5: typing.Union[str, None]
) -> Resfirst_786:
    cond = ((condition_784 == True) and (channel_785_5 is not None))

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = [json.loads(channel_785_5)]



        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/methylseq.nf', '-lib', 'lib', '-entry', 'METHYLSEQ', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"first","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resfirst_786(
        res=out_channels.get("res")
    )


class Resmix_787(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_787(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_784: typing.Union[bool, None],
    channel_781: typing.Union[str, None],
    channel_786: typing.Union[str, None]
) -> Resmix_787:
    cond = ((condition_784 == True) and (channel_781 is not None) and (channel_786 is not None))

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = [json.loads(channel_781), json.loads(channel_786)]



        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/methylseq.nf', '-lib', 'lib', '-entry', 'METHYLSEQ', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_787(
        res=out_channels.get("res")
    )


class ResMerge_ch_versions_789(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_versions_789(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    channel_787: typing.Union[str, None],
    channel_781: typing.Union[str, None]
) -> ResMerge_ch_versions_789:
    cond = True

    if cond:
        res = { 'res': channel_787 or channel_781 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_versions_789(
        res=res.get('res')
    )


class Res_params_cytosine_report____params_nomeseq__796(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def _params_cytosine_report____params_nomeseq__796(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_794: typing.Union[bool, None]
) -> Res_params_cytosine_report____params_nomeseq__796:
    cond = ((condition_794 == True))

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = []



        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/methylseq.nf', '-lib', 'lib', '-entry', 'METHYLSEQ', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"value","arguments":{"ArgumentListExpression":{"expressions":[{"BinaryExpression":{"leftExpression":{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"cytosine_report"}},"operation":"||","rightExpression":{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"nomeseq"}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Res_params_cytosine_report____params_nomeseq__796(
        res=out_channels.get("res")
    )


class Rescytosine_report_813(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def cytosine_report_813(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_794: typing.Union[bool, None],
    channel_796: typing.Union[str, None]
) -> Rescytosine_report_813:
    cond = ((condition_794 == True) and (channel_796 is not None))

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = [json.loads(channel_796)]



        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/bismark.nf', '-lib', 'lib', '-entry', 'BISMARK', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"toBoolean","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Rescytosine_report_813(
        res=out_channels.get("res")
    )


class Resconditional_cytosine_report_814(NamedTuple):
    condition: typing.Union[bool, None]

@task(cache=True)
def conditional_cytosine_report_814(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_794: typing.Union[bool, None],
    channel_813: typing.Union[str, None]
) -> Resconditional_cytosine_report_814:
    cond = ((condition_794 == True) and (channel_813 is not None))

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = [json.loads(channel_813)]



        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/bismark.nf', '-lib', 'lib', '-entry', 'BISMARK', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"condition"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"condition\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'condition': None}

    res = out_channels.get("condition")

    if res is not None:
        res = get_boolean_value(res)

    return Resconditional_cytosine_report_814(condition=res)


class ResChannel_empty___797(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_empty___797(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_794: typing.Union[bool, None]
) -> ResChannel_empty___797:
    cond = ((condition_794 == True))

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = []



        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/bismark.nf', '-lib', 'lib', '-entry', 'BISMARK', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"empty","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResChannel_empty___797(
        res=out_channels.get("res")
    )


class Resmix_799(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_799(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_794: typing.Union[bool, None],
    channel_797: typing.Union[str, None],
    channel_798_3: typing.Union[str, None]
) -> Resmix_799:
    cond = ((condition_794 == True) and (channel_797 is not None) and (channel_798_3 is not None))

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = [json.loads(channel_797), json.loads(channel_798_3)]



        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/bismark.nf', '-lib', 'lib', '-entry', 'BISMARK', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_799(
        res=out_channels.get("res")
    )


class Resmix_801(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_801(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_794: typing.Union[bool, None],
    channel_799: typing.Union[str, None],
    channel_800_2: typing.Union[str, None]
) -> Resmix_801:
    cond = ((condition_794 == True) and (channel_799 is not None) and (channel_800_2 is not None))

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = [json.loads(channel_799), json.loads(channel_800_2)]



        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/bismark.nf', '-lib', 'lib', '-entry', 'BISMARK', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_801(
        res=out_channels.get("res")
    )


class Res_params_skip_deduplication____params_rrbs__795(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def _params_skip_deduplication____params_rrbs__795(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_794: typing.Union[bool, None]
) -> Res_params_skip_deduplication____params_rrbs__795:
    cond = ((condition_794 == True))

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = []



        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/methylseq.nf', '-lib', 'lib', '-entry', 'METHYLSEQ', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"value","arguments":{"ArgumentListExpression":{"expressions":[{"BinaryExpression":{"leftExpression":{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"skip_deduplication"}},"operation":"||","rightExpression":{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"rrbs"}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Res_params_skip_deduplication____params_rrbs__795(
        res=out_channels.get("res")
    )


class Resskip_deduplication_802(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def skip_deduplication_802(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_794: typing.Union[bool, None],
    channel_795: typing.Union[str, None]
) -> Resskip_deduplication_802:
    cond = ((condition_794 == True) and (channel_795 is not None))

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = [json.loads(channel_795)]



        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/bismark.nf', '-lib', 'lib', '-entry', 'BISMARK', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"toBoolean","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resskip_deduplication_802(
        res=out_channels.get("res")
    )


class Resconditional_skip_deduplication_803(NamedTuple):
    condition: typing.Union[bool, None]

@task(cache=True)
def conditional_skip_deduplication_803(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_794: typing.Union[bool, None],
    channel_802: typing.Union[str, None]
) -> Resconditional_skip_deduplication_803:
    cond = ((condition_794 == True) and (channel_802 is not None))

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = [json.loads(channel_802)]



        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/bismark.nf', '-lib', 'lib', '-entry', 'BISMARK', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"condition"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"condition\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'condition': None}

    res = out_channels.get("condition")

    if res is not None:
        res = get_boolean_value(res)

    return Resconditional_skip_deduplication_803(condition=res)


@dataclass
class Dataclass_805_pre:
    wf_input: typing.List[Sample]
    wf_genome: Genome
    wf_save_reference: bool
    wf_save_align_intermeds: bool
    wf_aligner: Aligner
    wf_clip_r1: int
    wf_clip_r2: int
    wf_three_prime_clip_r1: int
    wf_three_prime_clip_r2: int
    wf_nextseq_trim: int
    wf_cytosine_report: bool
    wf_num_mismatches: float
    wf_skip_trimming: bool
    wf_skip_deduplication: bool
    wf_skip_multiqc: bool
    wf_outdir: str
    channel_798_0: str


class Res_805_pre(NamedTuple):
    default: typing.List[Dataclass_805_pre]
    is_skipped: bool

@task(cache=True)
def pre_adapter_BISMARK_DEDUPLICATE_805_pre(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_794: typing.Union[bool, None],
    condition_803: typing.Union[bool, None],
    channel_798_0: typing.Union[str, None]
) -> Res_805_pre:
    cond = ((condition_794 == True) and (condition_803 == False) and (channel_798_0 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_805_pre, {'wf_input': wf_input, 'wf_genome': wf_genome, 'wf_save_reference': wf_save_reference, 'wf_save_align_intermeds': wf_save_align_intermeds, 'wf_aligner': wf_aligner, 'wf_clip_r1': wf_clip_r1, 'wf_clip_r2': wf_clip_r2, 'wf_three_prime_clip_r1': wf_three_prime_clip_r1, 'wf_three_prime_clip_r2': wf_three_prime_clip_r2, 'wf_nextseq_trim': wf_nextseq_trim, 'wf_cytosine_report': wf_cytosine_report, 'wf_num_mismatches': wf_num_mismatches, 'wf_skip_trimming': wf_skip_trimming, 'wf_skip_deduplication': wf_skip_deduplication, 'wf_skip_multiqc': wf_skip_multiqc, 'wf_outdir': wf_outdir}, {'channel_798_0': channel_798_0})
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        result = []

    return Res_805_pre(default=result, is_skipped = not cond)

class Respost_adapter_BISMARK_DEDUPLICATE_805_post(NamedTuple):
    bam: typing.Union[str, None]
    report: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_805_post:
    bam: str
    report: str
    versions: str

@task(cache=True)
def post_adapter_BISMARK_DEDUPLICATE_805_post(
    default: List[Dataclass_805_post],
    is_skipped: bool,
) -> Respost_adapter_BISMARK_DEDUPLICATE_805_post:
    return get_mapper_outputs(Respost_adapter_BISMARK_DEDUPLICATE_805_post, default, is_skipped)


def _read_resources() -> Dict:
    try:
        with open(".latch/resources.json") as f:
            return json.load(f)
    except FileNotFoundError:
        return {}

def allocate_cpu(default: Dataclass_805_pre) -> int:
    res = _read_resources()
    return max(1, res['cpu_cores']) if res.get('cpu_cores') is not None else 12

def allocate_memory(default: Dataclass_805_pre) -> int:
    res = _read_resources()
    return max(1, res['memory_bytes'] // 1024**3) if res.get('memory_bytes') is not None else 72

def allocate_disk(default: Dataclass_805_pre) -> int:
    res = _read_resources()
    return max(1, res['disk_bytes'] // 1024**3) if res.get('disk_bytes') is not None else 4800

def get_resources(default: Dataclass_805_pre):
    wf_paths = {}
    wf_input = default.wf_input
    wf_input = construct_samplesheet(wf_input)
    wf_genome = default.wf_genome
    wf_save_reference = default.wf_save_reference
    wf_save_align_intermeds = default.wf_save_align_intermeds
    wf_aligner = default.wf_aligner
    wf_clip_r1 = default.wf_clip_r1
    wf_clip_r2 = default.wf_clip_r2
    wf_three_prime_clip_r1 = default.wf_three_prime_clip_r1
    wf_three_prime_clip_r2 = default.wf_three_prime_clip_r2
    wf_nextseq_trim = default.wf_nextseq_trim
    wf_cytosine_report = default.wf_cytosine_report
    wf_num_mismatches = default.wf_num_mismatches
    wf_skip_trimming = default.wf_skip_trimming
    wf_skip_deduplication = default.wf_skip_deduplication
    wf_skip_multiqc = default.wf_skip_multiqc
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_798_0)]

    if not True:
        download_files(channel_vals, LatchDir('latch:///methylseq-outputs'))

    flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/local/bismark.nf','-lib','lib','-profile','mamba','-entry','BISMARK', *flags],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"BISMARK_DEDUPLICATE","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"bam\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"BISMARK_DEDUPLICATE\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"report\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"BISMARK_DEDUPLICATE\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"BISMARK_DEDUPLICATE\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":2}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'True',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

@custom_task(cpu=allocate_cpu, memory=allocate_memory, storage_gib=allocate_disk, pre_execute=get_resources, cache=True)
def BISMARK_DEDUPLICATE_805(
    default: Dataclass_805_pre
) -> Dataclass_805_post:
    wf_paths = {}
    wf_input = default.wf_input
    wf_input = construct_samplesheet(wf_input)
    wf_genome = default.wf_genome
    wf_save_reference = default.wf_save_reference
    wf_save_align_intermeds = default.wf_save_align_intermeds
    wf_aligner = default.wf_aligner
    wf_clip_r1 = default.wf_clip_r1
    wf_clip_r2 = default.wf_clip_r2
    wf_three_prime_clip_r1 = default.wf_three_prime_clip_r1
    wf_three_prime_clip_r2 = default.wf_three_prime_clip_r2
    wf_nextseq_trim = default.wf_nextseq_trim
    wf_cytosine_report = default.wf_cytosine_report
    wf_num_mismatches = default.wf_num_mismatches
    wf_skip_trimming = default.wf_skip_trimming
    wf_skip_deduplication = default.wf_skip_deduplication
    wf_skip_multiqc = default.wf_skip_multiqc
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_798_0)]

    if not False:
        download_files(channel_vals, LatchDir('latch:///methylseq-outputs'))

    flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/local/bismark.nf','-lib','lib','-profile','mamba','-entry','BISMARK', *flags],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"BISMARK_DEDUPLICATE","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"bam\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"BISMARK_DEDUPLICATE\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"report\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"BISMARK_DEDUPLICATE\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"BISMARK_DEDUPLICATE\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":2}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'False',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = json.loads(file.read_text())

    print(out_channels)

    publish_dir = None
    upload_files(out_channels, LatchDir('latch:///methylseq-outputs'), publish_dir)

    out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    return Dataclass_805_post(
        bam=out_channels.get(f"bam"),
        report=out_channels.get(f"report"),
        versions=out_channels.get(f"versions")
    )


class Resmix_807(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_807(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_794: typing.Union[bool, None],
    condition_803: typing.Union[bool, None],
    channel_801: typing.Union[str, None],
    channel_805_2: typing.Union[str, None]
) -> Resmix_807:
    cond = ((condition_794 == True) and (condition_803 == False) and (channel_801 is not None) and (channel_805_2 is not None))

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = [json.loads(channel_801), json.loads(channel_805_2)]



        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/bismark.nf', '-lib', 'lib', '-entry', 'BISMARK', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_807(
        res=out_channels.get("res")
    )


class ResMerge_versions_810(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_versions_810(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_794: typing.Union[bool, None],
    channel_801: typing.Union[str, None],
    channel_807: typing.Union[str, None]
) -> ResMerge_versions_810:
    cond = ((condition_794 == True))

    if cond:
        res = { 'res': channel_801 or channel_807 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_versions_810(
        res=res.get('res')
    )


class ResMerge_alignments_808(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_alignments_808(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_794: typing.Union[bool, None],
    channel_798_0: typing.Union[str, None],
    channel_805_0: typing.Union[str, None]
) -> ResMerge_alignments_808:
    cond = ((condition_794 == True))

    if cond:
        res = { 'res': channel_798_0 or channel_805_0 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_alignments_808(
        res=res.get('res')
    )


@dataclass
class Dataclass_811_pre:
    wf_input: typing.List[Sample]
    wf_genome: Genome
    wf_save_reference: bool
    wf_save_align_intermeds: bool
    wf_aligner: Aligner
    wf_clip_r1: int
    wf_clip_r2: int
    wf_three_prime_clip_r1: int
    wf_three_prime_clip_r2: int
    wf_nextseq_trim: int
    wf_cytosine_report: bool
    wf_num_mismatches: float
    wf_skip_trimming: bool
    wf_skip_deduplication: bool
    wf_skip_multiqc: bool
    wf_outdir: str
    channel_808: str
    channel_762: str


class Res_811_pre(NamedTuple):
    default: typing.List[Dataclass_811_pre]
    is_skipped: bool

@task(cache=True)
def pre_adapter_BISMARK_METHYLATIONEXTRACTOR_811_pre(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_794: typing.Union[bool, None],
    channel_808: typing.Union[str, None],
    channel_762: typing.Union[str, None]
) -> Res_811_pre:
    cond = ((condition_794 == True) and (channel_808 is not None) and (channel_762 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_811_pre, {'wf_input': wf_input, 'wf_genome': wf_genome, 'wf_save_reference': wf_save_reference, 'wf_save_align_intermeds': wf_save_align_intermeds, 'wf_aligner': wf_aligner, 'wf_clip_r1': wf_clip_r1, 'wf_clip_r2': wf_clip_r2, 'wf_three_prime_clip_r1': wf_three_prime_clip_r1, 'wf_three_prime_clip_r2': wf_three_prime_clip_r2, 'wf_nextseq_trim': wf_nextseq_trim, 'wf_cytosine_report': wf_cytosine_report, 'wf_num_mismatches': wf_num_mismatches, 'wf_skip_trimming': wf_skip_trimming, 'wf_skip_deduplication': wf_skip_deduplication, 'wf_skip_multiqc': wf_skip_multiqc, 'wf_outdir': wf_outdir}, {'channel_808': channel_808, 'channel_762': channel_762})
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        result = []

    return Res_811_pre(default=result, is_skipped = not cond)

class Respost_adapter_BISMARK_METHYLATIONEXTRACTOR_811_post(NamedTuple):
    bedgraph: typing.Union[str, None]
    methylation_calls: typing.Union[str, None]
    coverage: typing.Union[str, None]
    report: typing.Union[str, None]
    mbias: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_811_post:
    bedgraph: str
    methylation_calls: str
    coverage: str
    report: str
    mbias: str
    versions: str

@task(cache=True)
def post_adapter_BISMARK_METHYLATIONEXTRACTOR_811_post(
    default: List[Dataclass_811_post],
    is_skipped: bool,
) -> Respost_adapter_BISMARK_METHYLATIONEXTRACTOR_811_post:
    return get_mapper_outputs(Respost_adapter_BISMARK_METHYLATIONEXTRACTOR_811_post, default, is_skipped)


def _read_resources() -> Dict:
    try:
        with open(".latch/resources.json") as f:
            return json.load(f)
    except FileNotFoundError:
        return {}

def allocate_cpu(default: Dataclass_811_pre) -> int:
    res = _read_resources()
    return max(1, res['cpu_cores']) if res.get('cpu_cores') is not None else 4

def allocate_memory(default: Dataclass_811_pre) -> int:
    res = _read_resources()
    return max(1, res['memory_bytes'] // 1024**3) if res.get('memory_bytes') is not None else 16

def allocate_disk(default: Dataclass_811_pre) -> int:
    res = _read_resources()
    return max(1, res['disk_bytes'] // 1024**3) if res.get('disk_bytes') is not None else 4800

def get_resources(default: Dataclass_811_pre):
    wf_paths = {}
    wf_input = default.wf_input
    wf_input = construct_samplesheet(wf_input)
    wf_genome = default.wf_genome
    wf_save_reference = default.wf_save_reference
    wf_save_align_intermeds = default.wf_save_align_intermeds
    wf_aligner = default.wf_aligner
    wf_clip_r1 = default.wf_clip_r1
    wf_clip_r2 = default.wf_clip_r2
    wf_three_prime_clip_r1 = default.wf_three_prime_clip_r1
    wf_three_prime_clip_r2 = default.wf_three_prime_clip_r2
    wf_nextseq_trim = default.wf_nextseq_trim
    wf_cytosine_report = default.wf_cytosine_report
    wf_num_mismatches = default.wf_num_mismatches
    wf_skip_trimming = default.wf_skip_trimming
    wf_skip_deduplication = default.wf_skip_deduplication
    wf_skip_multiqc = default.wf_skip_multiqc
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_808),json.loads(default.channel_762)]

    if not True:
        download_files(channel_vals, LatchDir('latch:///methylseq-outputs'))

    flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/local/bismark.nf','-lib','lib','-profile','mamba','-entry','BISMARK', *flags],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"BISMARK_METHYLATIONEXTRACTOR","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"bedgraph\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"BISMARK_METHYLATIONEXTRACTOR\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"methylation_calls\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"BISMARK_METHYLATIONEXTRACTOR\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"coverage\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"BISMARK_METHYLATIONEXTRACTOR\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":2}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"report\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"BISMARK_METHYLATIONEXTRACTOR\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":3}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"mbias\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"BISMARK_METHYLATIONEXTRACTOR\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":4}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"BISMARK_METHYLATIONEXTRACTOR\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":5}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'True',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

@custom_task(cpu=allocate_cpu, memory=allocate_memory, storage_gib=allocate_disk, pre_execute=get_resources, cache=True)
def BISMARK_METHYLATIONEXTRACTOR_811(
    default: Dataclass_811_pre
) -> Dataclass_811_post:
    wf_paths = {}
    wf_input = default.wf_input
    wf_input = construct_samplesheet(wf_input)
    wf_genome = default.wf_genome
    wf_save_reference = default.wf_save_reference
    wf_save_align_intermeds = default.wf_save_align_intermeds
    wf_aligner = default.wf_aligner
    wf_clip_r1 = default.wf_clip_r1
    wf_clip_r2 = default.wf_clip_r2
    wf_three_prime_clip_r1 = default.wf_three_prime_clip_r1
    wf_three_prime_clip_r2 = default.wf_three_prime_clip_r2
    wf_nextseq_trim = default.wf_nextseq_trim
    wf_cytosine_report = default.wf_cytosine_report
    wf_num_mismatches = default.wf_num_mismatches
    wf_skip_trimming = default.wf_skip_trimming
    wf_skip_deduplication = default.wf_skip_deduplication
    wf_skip_multiqc = default.wf_skip_multiqc
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_808),json.loads(default.channel_762)]

    if not False:
        download_files(channel_vals, LatchDir('latch:///methylseq-outputs'))

    flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/local/bismark.nf','-lib','lib','-profile','mamba','-entry','BISMARK', *flags],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"BISMARK_METHYLATIONEXTRACTOR","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"bedgraph\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"BISMARK_METHYLATIONEXTRACTOR\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"methylation_calls\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"BISMARK_METHYLATIONEXTRACTOR\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"coverage\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"BISMARK_METHYLATIONEXTRACTOR\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":2}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"report\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"BISMARK_METHYLATIONEXTRACTOR\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":3}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"mbias\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"BISMARK_METHYLATIONEXTRACTOR\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":4}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"BISMARK_METHYLATIONEXTRACTOR\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":5}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'False',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = json.loads(file.read_text())

    print(out_channels)

    publish_dir = None
    upload_files(out_channels, LatchDir('latch:///methylseq-outputs'), publish_dir)

    out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    return Dataclass_811_post(
        bedgraph=out_channels.get(f"bedgraph"),
        methylation_calls=out_channels.get(f"methylation_calls"),
        coverage=out_channels.get(f"coverage"),
        report=out_channels.get(f"report"),
        mbias=out_channels.get(f"mbias"),
        versions=out_channels.get(f"versions")
    )


class Resmix_812(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_812(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_794: typing.Union[bool, None],
    channel_810: typing.Union[str, None],
    channel_811_5: typing.Union[str, None]
) -> Resmix_812:
    cond = ((condition_794 == True) and (channel_810 is not None) and (channel_811_5 is not None))

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = [json.loads(channel_810), json.loads(channel_811_5)]



        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/bismark.nf', '-lib', 'lib', '-entry', 'BISMARK', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_812(
        res=out_channels.get("res")
    )


@dataclass
class Dataclass_815_pre:
    wf_input: typing.List[Sample]
    wf_genome: Genome
    wf_save_reference: bool
    wf_save_align_intermeds: bool
    wf_aligner: Aligner
    wf_clip_r1: int
    wf_clip_r2: int
    wf_three_prime_clip_r1: int
    wf_three_prime_clip_r2: int
    wf_nextseq_trim: int
    wf_cytosine_report: bool
    wf_num_mismatches: float
    wf_skip_trimming: bool
    wf_skip_deduplication: bool
    wf_skip_multiqc: bool
    wf_outdir: str
    channel_811_2: str
    channel_762: str


class Res_815_pre(NamedTuple):
    default: typing.List[Dataclass_815_pre]
    is_skipped: bool

@task(cache=True)
def pre_adapter_BISMARK_COVERAGE2CYTOSINE_815_pre(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_794: typing.Union[bool, None],
    condition_814: typing.Union[bool, None],
    channel_811_2: typing.Union[str, None],
    channel_762: typing.Union[str, None]
) -> Res_815_pre:
    cond = ((condition_794 == True) and (condition_814 == True) and (channel_811_2 is not None) and (channel_762 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_815_pre, {'wf_input': wf_input, 'wf_genome': wf_genome, 'wf_save_reference': wf_save_reference, 'wf_save_align_intermeds': wf_save_align_intermeds, 'wf_aligner': wf_aligner, 'wf_clip_r1': wf_clip_r1, 'wf_clip_r2': wf_clip_r2, 'wf_three_prime_clip_r1': wf_three_prime_clip_r1, 'wf_three_prime_clip_r2': wf_three_prime_clip_r2, 'wf_nextseq_trim': wf_nextseq_trim, 'wf_cytosine_report': wf_cytosine_report, 'wf_num_mismatches': wf_num_mismatches, 'wf_skip_trimming': wf_skip_trimming, 'wf_skip_deduplication': wf_skip_deduplication, 'wf_skip_multiqc': wf_skip_multiqc, 'wf_outdir': wf_outdir}, {'channel_811_2': channel_811_2, 'channel_762': channel_762})
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        result = []

    return Res_815_pre(default=result, is_skipped = not cond)

class Respost_adapter_BISMARK_COVERAGE2CYTOSINE_815_post(NamedTuple):
    coverage: typing.Union[str, None]
    report: typing.Union[str, None]
    summary: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_815_post:
    coverage: str
    report: str
    summary: str
    versions: str

@task(cache=True)
def post_adapter_BISMARK_COVERAGE2CYTOSINE_815_post(
    default: List[Dataclass_815_post],
    is_skipped: bool,
) -> Respost_adapter_BISMARK_COVERAGE2CYTOSINE_815_post:
    return get_mapper_outputs(Respost_adapter_BISMARK_COVERAGE2CYTOSINE_815_post, default, is_skipped)


def _read_resources() -> Dict:
    try:
        with open(".latch/resources.json") as f:
            return json.load(f)
    except FileNotFoundError:
        return {}

def allocate_cpu(default: Dataclass_815_pre) -> int:
    res = _read_resources()
    return max(1, res['cpu_cores']) if res.get('cpu_cores') is not None else 4

def allocate_memory(default: Dataclass_815_pre) -> int:
    res = _read_resources()
    return max(1, res['memory_bytes'] // 1024**3) if res.get('memory_bytes') is not None else 16

def allocate_disk(default: Dataclass_815_pre) -> int:
    res = _read_resources()
    return max(1, res['disk_bytes'] // 1024**3) if res.get('disk_bytes') is not None else 4800

def get_resources(default: Dataclass_815_pre):
    wf_paths = {}
    wf_input = default.wf_input
    wf_input = construct_samplesheet(wf_input)
    wf_genome = default.wf_genome
    wf_save_reference = default.wf_save_reference
    wf_save_align_intermeds = default.wf_save_align_intermeds
    wf_aligner = default.wf_aligner
    wf_clip_r1 = default.wf_clip_r1
    wf_clip_r2 = default.wf_clip_r2
    wf_three_prime_clip_r1 = default.wf_three_prime_clip_r1
    wf_three_prime_clip_r2 = default.wf_three_prime_clip_r2
    wf_nextseq_trim = default.wf_nextseq_trim
    wf_cytosine_report = default.wf_cytosine_report
    wf_num_mismatches = default.wf_num_mismatches
    wf_skip_trimming = default.wf_skip_trimming
    wf_skip_deduplication = default.wf_skip_deduplication
    wf_skip_multiqc = default.wf_skip_multiqc
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_811_2),json.loads(default.channel_762)]

    if not True:
        download_files(channel_vals, LatchDir('latch:///methylseq-outputs'))

    flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/local/bismark.nf','-lib','lib','-profile','mamba','-entry','BISMARK', *flags],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"BISMARK_COVERAGE2CYTOSINE","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"coverage\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"BISMARK_COVERAGE2CYTOSINE\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"report\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"BISMARK_COVERAGE2CYTOSINE\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"summary\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"BISMARK_COVERAGE2CYTOSINE\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":2}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"BISMARK_COVERAGE2CYTOSINE\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":3}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'True',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

@custom_task(cpu=allocate_cpu, memory=allocate_memory, storage_gib=allocate_disk, pre_execute=get_resources, cache=True)
def BISMARK_COVERAGE2CYTOSINE_815(
    default: Dataclass_815_pre
) -> Dataclass_815_post:
    wf_paths = {}
    wf_input = default.wf_input
    wf_input = construct_samplesheet(wf_input)
    wf_genome = default.wf_genome
    wf_save_reference = default.wf_save_reference
    wf_save_align_intermeds = default.wf_save_align_intermeds
    wf_aligner = default.wf_aligner
    wf_clip_r1 = default.wf_clip_r1
    wf_clip_r2 = default.wf_clip_r2
    wf_three_prime_clip_r1 = default.wf_three_prime_clip_r1
    wf_three_prime_clip_r2 = default.wf_three_prime_clip_r2
    wf_nextseq_trim = default.wf_nextseq_trim
    wf_cytosine_report = default.wf_cytosine_report
    wf_num_mismatches = default.wf_num_mismatches
    wf_skip_trimming = default.wf_skip_trimming
    wf_skip_deduplication = default.wf_skip_deduplication
    wf_skip_multiqc = default.wf_skip_multiqc
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_811_2),json.loads(default.channel_762)]

    if not False:
        download_files(channel_vals, LatchDir('latch:///methylseq-outputs'))

    flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/local/bismark.nf','-lib','lib','-profile','mamba','-entry','BISMARK', *flags],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"BISMARK_COVERAGE2CYTOSINE","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"coverage\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"BISMARK_COVERAGE2CYTOSINE\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"report\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"BISMARK_COVERAGE2CYTOSINE\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"summary\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"BISMARK_COVERAGE2CYTOSINE\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":2}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"BISMARK_COVERAGE2CYTOSINE\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":3}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'False',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = json.loads(file.read_text())

    print(out_channels)

    publish_dir = None
    upload_files(out_channels, LatchDir('latch:///methylseq-outputs'), publish_dir)

    out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    return Dataclass_815_post(
        coverage=out_channels.get(f"coverage"),
        report=out_channels.get(f"report"),
        summary=out_channels.get(f"summary"),
        versions=out_channels.get(f"versions")
    )


class Resmix_816(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_816(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_794: typing.Union[bool, None],
    condition_814: typing.Union[bool, None],
    channel_812: typing.Union[str, None],
    channel_815_3: typing.Union[str, None]
) -> Resmix_816:
    cond = ((condition_794 == True) and (condition_814 == True) and (channel_812 is not None) and (channel_815_3 is not None))

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = [json.loads(channel_812), json.loads(channel_815_3)]



        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/bismark.nf', '-lib', 'lib', '-entry', 'BISMARK', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_816(
        res=out_channels.get("res")
    )


class ResMerge_versions_817(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_versions_817(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_794: typing.Union[bool, None],
    channel_816: typing.Union[str, None],
    channel_812: typing.Union[str, None]
) -> ResMerge_versions_817:
    cond = ((condition_794 == True))

    if cond:
        res = { 'res': channel_816 or channel_812 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_versions_817(
        res=res.get('res')
    )


class Resmap_804(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def map_804(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_794: typing.Union[bool, None],
    condition_803: typing.Union[bool, None],
    channel_798_1: typing.Union[str, None]
) -> Resmap_804:
    cond = ((condition_794 == True) and (condition_803 == True) and (channel_798_1 is not None))

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = [json.loads(channel_798_1)]



        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/bismark.nf', '-lib', 'lib', '-entry', 'BISMARK', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"map","arguments":{"ArgumentListExpression":{"expressions":[{"ClosureExpression":{"code":{"BlockStatement":{"statements":[{"ReturnStatement":{"ListExpression":[{"VariableExpression":"meta"},{"VariableExpression":"report"},{"ListExpression":[]}]}}],"scope":{"declaredVariables":[],"referencedClassVariables":[]},"labels":[]}},"parameters":["meta","report"]}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmap_804(
        res=out_channels.get("res")
    )


class Resjoin_806(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def join_806(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_794: typing.Union[bool, None],
    condition_803: typing.Union[bool, None],
    channel_798_1: typing.Union[str, None],
    channel_805_1: typing.Union[str, None]
) -> Resjoin_806:
    cond = ((condition_794 == True) and (condition_803 == False) and (channel_798_1 is not None) and (channel_805_1 is not None))

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = [json.loads(channel_798_1), json.loads(channel_805_1)]



        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/bismark.nf', '-lib', 'lib', '-entry', 'BISMARK', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"join","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resjoin_806(
        res=out_channels.get("res")
    )


class ResMerge_alignment_reports_809(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_alignment_reports_809(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_794: typing.Union[bool, None],
    channel_804: typing.Union[str, None],
    channel_806: typing.Union[str, None]
) -> ResMerge_alignment_reports_809:
    cond = ((condition_794 == True))

    if cond:
        res = { 'res': channel_804 or channel_806 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_alignment_reports_809(
        res=res.get('res')
    )


class Resjoin_818(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def join_818(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_794: typing.Union[bool, None],
    channel_809: typing.Union[str, None],
    channel_811_3: typing.Union[str, None]
) -> Resjoin_818:
    cond = ((condition_794 == True) and (channel_809 is not None) and (channel_811_3 is not None))

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = [json.loads(channel_809), json.loads(channel_811_3)]



        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/bismark.nf', '-lib', 'lib', '-entry', 'BISMARK', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"join","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resjoin_818(
        res=out_channels.get("res")
    )


class Resjoin_819(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def join_819(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_794: typing.Union[bool, None],
    channel_818: typing.Union[str, None],
    channel_811_4: typing.Union[str, None]
) -> Resjoin_819:
    cond = ((condition_794 == True) and (channel_818 is not None) and (channel_811_4 is not None))

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = [json.loads(channel_818), json.loads(channel_811_4)]



        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/bismark.nf', '-lib', 'lib', '-entry', 'BISMARK', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"join","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resjoin_819(
        res=out_channels.get("res")
    )


@dataclass
class Dataclass_820_pre:
    wf_input: typing.List[Sample]
    wf_genome: Genome
    wf_save_reference: bool
    wf_save_align_intermeds: bool
    wf_aligner: Aligner
    wf_clip_r1: int
    wf_clip_r2: int
    wf_three_prime_clip_r1: int
    wf_three_prime_clip_r2: int
    wf_nextseq_trim: int
    wf_cytosine_report: bool
    wf_num_mismatches: float
    wf_skip_trimming: bool
    wf_skip_deduplication: bool
    wf_skip_multiqc: bool
    wf_outdir: str
    channel_819: str


class Res_820_pre(NamedTuple):
    default: typing.List[Dataclass_820_pre]
    is_skipped: bool

@task(cache=True)
def pre_adapter_BISMARK_REPORT_820_pre(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_794: typing.Union[bool, None],
    channel_819: typing.Union[str, None]
) -> Res_820_pre:
    cond = ((condition_794 == True) and (channel_819 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_820_pre, {'wf_input': wf_input, 'wf_genome': wf_genome, 'wf_save_reference': wf_save_reference, 'wf_save_align_intermeds': wf_save_align_intermeds, 'wf_aligner': wf_aligner, 'wf_clip_r1': wf_clip_r1, 'wf_clip_r2': wf_clip_r2, 'wf_three_prime_clip_r1': wf_three_prime_clip_r1, 'wf_three_prime_clip_r2': wf_three_prime_clip_r2, 'wf_nextseq_trim': wf_nextseq_trim, 'wf_cytosine_report': wf_cytosine_report, 'wf_num_mismatches': wf_num_mismatches, 'wf_skip_trimming': wf_skip_trimming, 'wf_skip_deduplication': wf_skip_deduplication, 'wf_skip_multiqc': wf_skip_multiqc, 'wf_outdir': wf_outdir}, {'channel_819': channel_819})
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        result = []

    return Res_820_pre(default=result, is_skipped = not cond)

class Respost_adapter_BISMARK_REPORT_820_post(NamedTuple):
    report: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_820_post:
    report: str
    versions: str

@task(cache=True)
def post_adapter_BISMARK_REPORT_820_post(
    default: List[Dataclass_820_post],
    is_skipped: bool,
) -> Respost_adapter_BISMARK_REPORT_820_post:
    return get_mapper_outputs(Respost_adapter_BISMARK_REPORT_820_post, default, is_skipped)


def _read_resources() -> Dict:
    try:
        with open(".latch/resources.json") as f:
            return json.load(f)
    except FileNotFoundError:
        return {}

def allocate_cpu(default: Dataclass_820_pre) -> int:
    res = _read_resources()
    return max(1, res['cpu_cores']) if res.get('cpu_cores') is not None else 4

def allocate_memory(default: Dataclass_820_pre) -> int:
    res = _read_resources()
    return max(1, res['memory_bytes'] // 1024**3) if res.get('memory_bytes') is not None else 16

def allocate_disk(default: Dataclass_820_pre) -> int:
    res = _read_resources()
    return max(1, res['disk_bytes'] // 1024**3) if res.get('disk_bytes') is not None else 4800

def get_resources(default: Dataclass_820_pre):
    wf_paths = {}
    wf_input = default.wf_input
    wf_input = construct_samplesheet(wf_input)
    wf_genome = default.wf_genome
    wf_save_reference = default.wf_save_reference
    wf_save_align_intermeds = default.wf_save_align_intermeds
    wf_aligner = default.wf_aligner
    wf_clip_r1 = default.wf_clip_r1
    wf_clip_r2 = default.wf_clip_r2
    wf_three_prime_clip_r1 = default.wf_three_prime_clip_r1
    wf_three_prime_clip_r2 = default.wf_three_prime_clip_r2
    wf_nextseq_trim = default.wf_nextseq_trim
    wf_cytosine_report = default.wf_cytosine_report
    wf_num_mismatches = default.wf_num_mismatches
    wf_skip_trimming = default.wf_skip_trimming
    wf_skip_deduplication = default.wf_skip_deduplication
    wf_skip_multiqc = default.wf_skip_multiqc
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_819)]

    if not True:
        download_files(channel_vals, LatchDir('latch:///methylseq-outputs'))

    flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/local/bismark.nf','-lib','lib','-profile','mamba','-entry','BISMARK', *flags],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"BISMARK_REPORT","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"report\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"BISMARK_REPORT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"BISMARK_REPORT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'True',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

@custom_task(cpu=allocate_cpu, memory=allocate_memory, storage_gib=allocate_disk, pre_execute=get_resources, cache=True)
def BISMARK_REPORT_820(
    default: Dataclass_820_pre
) -> Dataclass_820_post:
    wf_paths = {}
    wf_input = default.wf_input
    wf_input = construct_samplesheet(wf_input)
    wf_genome = default.wf_genome
    wf_save_reference = default.wf_save_reference
    wf_save_align_intermeds = default.wf_save_align_intermeds
    wf_aligner = default.wf_aligner
    wf_clip_r1 = default.wf_clip_r1
    wf_clip_r2 = default.wf_clip_r2
    wf_three_prime_clip_r1 = default.wf_three_prime_clip_r1
    wf_three_prime_clip_r2 = default.wf_three_prime_clip_r2
    wf_nextseq_trim = default.wf_nextseq_trim
    wf_cytosine_report = default.wf_cytosine_report
    wf_num_mismatches = default.wf_num_mismatches
    wf_skip_trimming = default.wf_skip_trimming
    wf_skip_deduplication = default.wf_skip_deduplication
    wf_skip_multiqc = default.wf_skip_multiqc
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_819)]

    if not False:
        download_files(channel_vals, LatchDir('latch:///methylseq-outputs'))

    flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/local/bismark.nf','-lib','lib','-profile','mamba','-entry','BISMARK', *flags],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"BISMARK_REPORT","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"report\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"BISMARK_REPORT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"BISMARK_REPORT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'False',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = json.loads(file.read_text())

    print(out_channels)

    publish_dir = None
    upload_files(out_channels, LatchDir('latch:///methylseq-outputs'), publish_dir)

    out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    return Dataclass_820_post(
        report=out_channels.get(f"report"),
        versions=out_channels.get(f"versions")
    )


class Resmix_821(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_821(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_794: typing.Union[bool, None],
    channel_817: typing.Union[str, None],
    channel_820_1: typing.Union[str, None]
) -> Resmix_821:
    cond = ((condition_794 == True) and (channel_817 is not None) and (channel_820_1 is not None))

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = [json.loads(channel_817), json.loads(channel_820_1)]



        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/bismark.nf', '-lib', 'lib', '-entry', 'BISMARK', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_821(
        res=out_channels.get("res")
    )


class Rescollect_822(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def collect_822(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_794: typing.Union[bool, None],
    channel_798_0: typing.Union[str, None]
) -> Rescollect_822:
    cond = ((condition_794 == True) and (channel_798_0 is not None))

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = [json.loads(channel_798_0)]



        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/bismark.nf', '-lib', 'lib', '-entry', 'BISMARK', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"collect","arguments":{"ArgumentListExpression":{"expressions":[{"ClosureExpression":{"code":{"BlockStatement":{"statements":[{"ReturnStatement":{"PropertyExpression":{"objectExpression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"it"},"operation":"[","rightExpression":{"ConstantExpression":1}}},"property":"name"}}}],"scope":{"declaredVariables":[],"referencedClassVariables":[]},"labels":[]}},"parameters":[]}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Rescollect_822(
        res=out_channels.get("res")
    )


class ResifEmpty_823(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def ifEmpty_823(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_794: typing.Union[bool, None],
    channel_822: typing.Union[str, None]
) -> ResifEmpty_823:
    cond = ((condition_794 == True) and (channel_822 is not None))

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = [json.loads(channel_822)]



        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/bismark.nf', '-lib', 'lib', '-entry', 'BISMARK', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"ifEmpty","arguments":{"ArgumentListExpression":{"expressions":[{"ListExpression":[]}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResifEmpty_823(
        res=out_channels.get("res")
    )


class Rescollect_824(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def collect_824(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_794: typing.Union[bool, None],
    channel_809: typing.Union[str, None]
) -> Rescollect_824:
    cond = ((condition_794 == True) and (channel_809 is not None))

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = [json.loads(channel_809)]



        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/bismark.nf', '-lib', 'lib', '-entry', 'BISMARK', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"collect","arguments":{"ArgumentListExpression":{"expressions":[{"ClosureExpression":{"code":{"BlockStatement":{"statements":[{"ReturnStatement":{"BinaryExpression":{"leftExpression":{"VariableExpression":"it"},"operation":"[","rightExpression":{"ConstantExpression":1}}}}],"scope":{"declaredVariables":[],"referencedClassVariables":[]},"labels":[]}},"parameters":[]}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Rescollect_824(
        res=out_channels.get("res")
    )


class ResifEmpty_825(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def ifEmpty_825(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_794: typing.Union[bool, None],
    channel_824: typing.Union[str, None]
) -> ResifEmpty_825:
    cond = ((condition_794 == True) and (channel_824 is not None))

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = [json.loads(channel_824)]



        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/bismark.nf', '-lib', 'lib', '-entry', 'BISMARK', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"ifEmpty","arguments":{"ArgumentListExpression":{"expressions":[{"ListExpression":[]}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResifEmpty_825(
        res=out_channels.get("res")
    )


class Rescollect_826(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def collect_826(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_794: typing.Union[bool, None],
    channel_809: typing.Union[str, None]
) -> Rescollect_826:
    cond = ((condition_794 == True) and (channel_809 is not None))

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = [json.loads(channel_809)]



        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/bismark.nf', '-lib', 'lib', '-entry', 'BISMARK', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"collect","arguments":{"ArgumentListExpression":{"expressions":[{"ClosureExpression":{"code":{"BlockStatement":{"statements":[{"ReturnStatement":{"BinaryExpression":{"leftExpression":{"VariableExpression":"it"},"operation":"[","rightExpression":{"ConstantExpression":2}}}}],"scope":{"declaredVariables":[],"referencedClassVariables":[]},"labels":[]}},"parameters":[]}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Rescollect_826(
        res=out_channels.get("res")
    )


class ResifEmpty_827(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def ifEmpty_827(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_794: typing.Union[bool, None],
    channel_826: typing.Union[str, None]
) -> ResifEmpty_827:
    cond = ((condition_794 == True) and (channel_826 is not None))

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = [json.loads(channel_826)]



        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/bismark.nf', '-lib', 'lib', '-entry', 'BISMARK', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"ifEmpty","arguments":{"ArgumentListExpression":{"expressions":[{"ListExpression":[]}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResifEmpty_827(
        res=out_channels.get("res")
    )


class Rescollect_828(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def collect_828(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_794: typing.Union[bool, None],
    channel_811_3: typing.Union[str, None]
) -> Rescollect_828:
    cond = ((condition_794 == True) and (channel_811_3 is not None))

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = [json.loads(channel_811_3)]



        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/bismark.nf', '-lib', 'lib', '-entry', 'BISMARK', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"collect","arguments":{"ArgumentListExpression":{"expressions":[{"ClosureExpression":{"code":{"BlockStatement":{"statements":[{"ReturnStatement":{"BinaryExpression":{"leftExpression":{"VariableExpression":"it"},"operation":"[","rightExpression":{"ConstantExpression":1}}}}],"scope":{"declaredVariables":[],"referencedClassVariables":[]},"labels":[]}},"parameters":[]}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Rescollect_828(
        res=out_channels.get("res")
    )


class ResifEmpty_829(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def ifEmpty_829(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_794: typing.Union[bool, None],
    channel_828: typing.Union[str, None]
) -> ResifEmpty_829:
    cond = ((condition_794 == True) and (channel_828 is not None))

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = [json.loads(channel_828)]



        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/bismark.nf', '-lib', 'lib', '-entry', 'BISMARK', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"ifEmpty","arguments":{"ArgumentListExpression":{"expressions":[{"ListExpression":[]}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResifEmpty_829(
        res=out_channels.get("res")
    )


class Rescollect_830(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def collect_830(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_794: typing.Union[bool, None],
    channel_811_4: typing.Union[str, None]
) -> Rescollect_830:
    cond = ((condition_794 == True) and (channel_811_4 is not None))

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = [json.loads(channel_811_4)]



        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/bismark.nf', '-lib', 'lib', '-entry', 'BISMARK', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"collect","arguments":{"ArgumentListExpression":{"expressions":[{"ClosureExpression":{"code":{"BlockStatement":{"statements":[{"ReturnStatement":{"BinaryExpression":{"leftExpression":{"VariableExpression":"it"},"operation":"[","rightExpression":{"ConstantExpression":1}}}}],"scope":{"declaredVariables":[],"referencedClassVariables":[]},"labels":[]}},"parameters":[]}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Rescollect_830(
        res=out_channels.get("res")
    )


class ResifEmpty_831(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def ifEmpty_831(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_794: typing.Union[bool, None],
    channel_830: typing.Union[str, None]
) -> ResifEmpty_831:
    cond = ((condition_794 == True) and (channel_830 is not None))

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = [json.loads(channel_830)]



        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/bismark.nf', '-lib', 'lib', '-entry', 'BISMARK', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"ifEmpty","arguments":{"ArgumentListExpression":{"expressions":[{"ListExpression":[]}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResifEmpty_831(
        res=out_channels.get("res")
    )


@dataclass
class Dataclass_832_pre:
    wf_input: typing.List[Sample]
    wf_genome: Genome
    wf_save_reference: bool
    wf_save_align_intermeds: bool
    wf_aligner: Aligner
    wf_clip_r1: int
    wf_clip_r2: int
    wf_three_prime_clip_r1: int
    wf_three_prime_clip_r2: int
    wf_nextseq_trim: int
    wf_cytosine_report: bool
    wf_num_mismatches: float
    wf_skip_trimming: bool
    wf_skip_deduplication: bool
    wf_skip_multiqc: bool
    wf_outdir: str
    channel_823: str
    channel_825: str
    channel_827: str
    channel_829: str
    channel_831: str


class Res_832_pre(NamedTuple):
    default: typing.List[Dataclass_832_pre]
    is_skipped: bool

@task(cache=True)
def pre_adapter_BISMARK_SUMMARY_832_pre(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_794: typing.Union[bool, None],
    channel_823: typing.Union[str, None],
    channel_825: typing.Union[str, None],
    channel_827: typing.Union[str, None],
    channel_829: typing.Union[str, None],
    channel_831: typing.Union[str, None]
) -> Res_832_pre:
    cond = ((condition_794 == True) and (channel_823 is not None) and (channel_825 is not None) and (channel_827 is not None) and (channel_829 is not None) and (channel_831 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_832_pre, {'wf_input': wf_input, 'wf_genome': wf_genome, 'wf_save_reference': wf_save_reference, 'wf_save_align_intermeds': wf_save_align_intermeds, 'wf_aligner': wf_aligner, 'wf_clip_r1': wf_clip_r1, 'wf_clip_r2': wf_clip_r2, 'wf_three_prime_clip_r1': wf_three_prime_clip_r1, 'wf_three_prime_clip_r2': wf_three_prime_clip_r2, 'wf_nextseq_trim': wf_nextseq_trim, 'wf_cytosine_report': wf_cytosine_report, 'wf_num_mismatches': wf_num_mismatches, 'wf_skip_trimming': wf_skip_trimming, 'wf_skip_deduplication': wf_skip_deduplication, 'wf_skip_multiqc': wf_skip_multiqc, 'wf_outdir': wf_outdir}, {'channel_823': channel_823, 'channel_825': channel_825, 'channel_827': channel_827, 'channel_829': channel_829, 'channel_831': channel_831})
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        result = []

    return Res_832_pre(default=result, is_skipped = not cond)

class Respost_adapter_BISMARK_SUMMARY_832_post(NamedTuple):
    summary: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_832_post:
    summary: str
    versions: str

@task(cache=True)
def post_adapter_BISMARK_SUMMARY_832_post(
    default: List[Dataclass_832_post],
    is_skipped: bool,
) -> Respost_adapter_BISMARK_SUMMARY_832_post:
    return get_mapper_outputs(Respost_adapter_BISMARK_SUMMARY_832_post, default, is_skipped)


def _read_resources() -> Dict:
    try:
        with open(".latch/resources.json") as f:
            return json.load(f)
    except FileNotFoundError:
        return {}

def allocate_cpu(default: Dataclass_832_pre) -> int:
    res = _read_resources()
    return max(1, res['cpu_cores']) if res.get('cpu_cores') is not None else 4

def allocate_memory(default: Dataclass_832_pre) -> int:
    res = _read_resources()
    return max(1, res['memory_bytes'] // 1024**3) if res.get('memory_bytes') is not None else 16

def allocate_disk(default: Dataclass_832_pre) -> int:
    res = _read_resources()
    return max(1, res['disk_bytes'] // 1024**3) if res.get('disk_bytes') is not None else 4800

def get_resources(default: Dataclass_832_pre):
    wf_paths = {}
    wf_input = default.wf_input
    wf_input = construct_samplesheet(wf_input)
    wf_genome = default.wf_genome
    wf_save_reference = default.wf_save_reference
    wf_save_align_intermeds = default.wf_save_align_intermeds
    wf_aligner = default.wf_aligner
    wf_clip_r1 = default.wf_clip_r1
    wf_clip_r2 = default.wf_clip_r2
    wf_three_prime_clip_r1 = default.wf_three_prime_clip_r1
    wf_three_prime_clip_r2 = default.wf_three_prime_clip_r2
    wf_nextseq_trim = default.wf_nextseq_trim
    wf_cytosine_report = default.wf_cytosine_report
    wf_num_mismatches = default.wf_num_mismatches
    wf_skip_trimming = default.wf_skip_trimming
    wf_skip_deduplication = default.wf_skip_deduplication
    wf_skip_multiqc = default.wf_skip_multiqc
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_823),json.loads(default.channel_825),json.loads(default.channel_827),json.loads(default.channel_829),json.loads(default.channel_831)]

    if not True:
        download_files(channel_vals, LatchDir('latch:///methylseq-outputs'))

    flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/local/bismark.nf','-lib','lib','-profile','mamba','-entry','BISMARK', *flags],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"BISMARK_SUMMARY","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"summary\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"BISMARK_SUMMARY\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"BISMARK_SUMMARY\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'True',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

@custom_task(cpu=allocate_cpu, memory=allocate_memory, storage_gib=allocate_disk, pre_execute=get_resources, cache=True)
def BISMARK_SUMMARY_832(
    default: Dataclass_832_pre
) -> Dataclass_832_post:
    wf_paths = {}
    wf_input = default.wf_input
    wf_input = construct_samplesheet(wf_input)
    wf_genome = default.wf_genome
    wf_save_reference = default.wf_save_reference
    wf_save_align_intermeds = default.wf_save_align_intermeds
    wf_aligner = default.wf_aligner
    wf_clip_r1 = default.wf_clip_r1
    wf_clip_r2 = default.wf_clip_r2
    wf_three_prime_clip_r1 = default.wf_three_prime_clip_r1
    wf_three_prime_clip_r2 = default.wf_three_prime_clip_r2
    wf_nextseq_trim = default.wf_nextseq_trim
    wf_cytosine_report = default.wf_cytosine_report
    wf_num_mismatches = default.wf_num_mismatches
    wf_skip_trimming = default.wf_skip_trimming
    wf_skip_deduplication = default.wf_skip_deduplication
    wf_skip_multiqc = default.wf_skip_multiqc
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_823),json.loads(default.channel_825),json.loads(default.channel_827),json.loads(default.channel_829),json.loads(default.channel_831)]

    if not False:
        download_files(channel_vals, LatchDir('latch:///methylseq-outputs'))

    flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/local/bismark.nf','-lib','lib','-profile','mamba','-entry','BISMARK', *flags],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"BISMARK_SUMMARY","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"summary\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"BISMARK_SUMMARY\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"BISMARK_SUMMARY\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'False',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = json.loads(file.read_text())

    print(out_channels)

    publish_dir = None
    upload_files(out_channels, LatchDir('latch:///methylseq-outputs'), publish_dir)

    out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    return Dataclass_832_post(
        summary=out_channels.get(f"summary"),
        versions=out_channels.get(f"versions")
    )


class Resmix_833(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_833(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_794: typing.Union[bool, None],
    channel_821: typing.Union[str, None],
    channel_832_1: typing.Union[str, None]
) -> Resmix_833:
    cond = ((condition_794 == True) and (channel_821 is not None) and (channel_832_1 is not None))

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = [json.loads(channel_821), json.loads(channel_832_1)]



        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/bismark.nf', '-lib', 'lib', '-entry', 'BISMARK', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_833(
        res=out_channels.get("res")
    )


@dataclass
class Dataclass_834_pre:
    wf_input: typing.List[Sample]
    wf_genome: Genome
    wf_save_reference: bool
    wf_save_align_intermeds: bool
    wf_aligner: Aligner
    wf_clip_r1: int
    wf_clip_r2: int
    wf_three_prime_clip_r1: int
    wf_three_prime_clip_r2: int
    wf_nextseq_trim: int
    wf_cytosine_report: bool
    wf_num_mismatches: float
    wf_skip_trimming: bool
    wf_skip_deduplication: bool
    wf_skip_multiqc: bool
    wf_outdir: str
    channel_808: str


class Res_834_pre(NamedTuple):
    default: typing.List[Dataclass_834_pre]
    is_skipped: bool

@task(cache=True)
def pre_adapter_SAMTOOLS_SORT_DEDUPLICATED_834_pre(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_794: typing.Union[bool, None],
    channel_808: typing.Union[str, None]
) -> Res_834_pre:
    cond = ((condition_794 == True) and (channel_808 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_834_pre, {'wf_input': wf_input, 'wf_genome': wf_genome, 'wf_save_reference': wf_save_reference, 'wf_save_align_intermeds': wf_save_align_intermeds, 'wf_aligner': wf_aligner, 'wf_clip_r1': wf_clip_r1, 'wf_clip_r2': wf_clip_r2, 'wf_three_prime_clip_r1': wf_three_prime_clip_r1, 'wf_three_prime_clip_r2': wf_three_prime_clip_r2, 'wf_nextseq_trim': wf_nextseq_trim, 'wf_cytosine_report': wf_cytosine_report, 'wf_num_mismatches': wf_num_mismatches, 'wf_skip_trimming': wf_skip_trimming, 'wf_skip_deduplication': wf_skip_deduplication, 'wf_skip_multiqc': wf_skip_multiqc, 'wf_outdir': wf_outdir}, {'channel_808': channel_808})
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        result = []

    return Res_834_pre(default=result, is_skipped = not cond)

class Respost_adapter_SAMTOOLS_SORT_DEDUPLICATED_834_post(NamedTuple):
    bam: typing.Union[str, None]
    csi: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_834_post:
    bam: str
    csi: str
    versions: str

@task(cache=True)
def post_adapter_SAMTOOLS_SORT_DEDUPLICATED_834_post(
    default: List[Dataclass_834_post],
    is_skipped: bool,
) -> Respost_adapter_SAMTOOLS_SORT_DEDUPLICATED_834_post:
    return get_mapper_outputs(Respost_adapter_SAMTOOLS_SORT_DEDUPLICATED_834_post, default, is_skipped)


def _read_resources() -> Dict:
    try:
        with open(".latch/resources.json") as f:
            return json.load(f)
    except FileNotFoundError:
        return {}

def allocate_cpu(default: Dataclass_834_pre) -> int:
    res = _read_resources()
    return max(1, res['cpu_cores']) if res.get('cpu_cores') is not None else 8

def allocate_memory(default: Dataclass_834_pre) -> int:
    res = _read_resources()
    return max(1, res['memory_bytes'] // 1024**3) if res.get('memory_bytes') is not None else 48

def allocate_disk(default: Dataclass_834_pre) -> int:
    res = _read_resources()
    return max(1, res['disk_bytes'] // 1024**3) if res.get('disk_bytes') is not None else 4800

def get_resources(default: Dataclass_834_pre):
    wf_paths = {}
    wf_input = default.wf_input
    wf_input = construct_samplesheet(wf_input)
    wf_genome = default.wf_genome
    wf_save_reference = default.wf_save_reference
    wf_save_align_intermeds = default.wf_save_align_intermeds
    wf_aligner = default.wf_aligner
    wf_clip_r1 = default.wf_clip_r1
    wf_clip_r2 = default.wf_clip_r2
    wf_three_prime_clip_r1 = default.wf_three_prime_clip_r1
    wf_three_prime_clip_r2 = default.wf_three_prime_clip_r2
    wf_nextseq_trim = default.wf_nextseq_trim
    wf_cytosine_report = default.wf_cytosine_report
    wf_num_mismatches = default.wf_num_mismatches
    wf_skip_trimming = default.wf_skip_trimming
    wf_skip_deduplication = default.wf_skip_deduplication
    wf_skip_multiqc = default.wf_skip_multiqc
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_808)]

    if not True:
        download_files(channel_vals, LatchDir('latch:///methylseq-outputs'))

    flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/local/bismark.nf','-lib','lib','-profile','mamba','-entry','BISMARK', *flags],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"SAMTOOLS_SORT_DEDUPLICATED","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"bam\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_SORT_DEDUPLICATED\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"csi\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_SORT_DEDUPLICATED\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_SORT_DEDUPLICATED\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":2}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'True',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

@custom_task(cpu=allocate_cpu, memory=allocate_memory, storage_gib=allocate_disk, pre_execute=get_resources, cache=True)
def SAMTOOLS_SORT_DEDUPLICATED_834(
    default: Dataclass_834_pre
) -> Dataclass_834_post:
    wf_paths = {}
    wf_input = default.wf_input
    wf_input = construct_samplesheet(wf_input)
    wf_genome = default.wf_genome
    wf_save_reference = default.wf_save_reference
    wf_save_align_intermeds = default.wf_save_align_intermeds
    wf_aligner = default.wf_aligner
    wf_clip_r1 = default.wf_clip_r1
    wf_clip_r2 = default.wf_clip_r2
    wf_three_prime_clip_r1 = default.wf_three_prime_clip_r1
    wf_three_prime_clip_r2 = default.wf_three_prime_clip_r2
    wf_nextseq_trim = default.wf_nextseq_trim
    wf_cytosine_report = default.wf_cytosine_report
    wf_num_mismatches = default.wf_num_mismatches
    wf_skip_trimming = default.wf_skip_trimming
    wf_skip_deduplication = default.wf_skip_deduplication
    wf_skip_multiqc = default.wf_skip_multiqc
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_808)]

    if not False:
        download_files(channel_vals, LatchDir('latch:///methylseq-outputs'))

    flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/local/bismark.nf','-lib','lib','-profile','mamba','-entry','BISMARK', *flags],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"SAMTOOLS_SORT_DEDUPLICATED","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"bam\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_SORT_DEDUPLICATED\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"csi\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_SORT_DEDUPLICATED\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_SORT_DEDUPLICATED\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":2}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'False',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = json.loads(file.read_text())

    print(out_channels)

    publish_dir = None
    upload_files(out_channels, LatchDir('latch:///methylseq-outputs'), publish_dir)

    out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    return Dataclass_834_post(
        bam=out_channels.get(f"bam"),
        csi=out_channels.get(f"csi"),
        versions=out_channels.get(f"versions")
    )


class Resmix_835(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_835(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_794: typing.Union[bool, None],
    channel_833: typing.Union[str, None],
    channel_834_2: typing.Union[str, None]
) -> Resmix_835:
    cond = ((condition_794 == True) and (channel_833 is not None) and (channel_834_2 is not None))

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = [json.loads(channel_833), json.loads(channel_834_2)]



        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/bismark.nf', '-lib', 'lib', '-entry', 'BISMARK', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_835(
        res=out_channels.get("res")
    )


class Resunique_847(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def unique_847(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_794: typing.Union[bool, None],
    channel_835: typing.Union[str, None]
) -> Resunique_847:
    cond = ((condition_794 == True) and (channel_835 is not None))

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = [json.loads(channel_835)]



        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/methylseq.nf', '-lib', 'lib', '-entry', 'METHYLSEQ', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"unique","arguments":{"ArgumentListExpression":{"expressions":[{"ClosureExpression":{"code":{"BlockStatement":{"statements":[{"ReturnStatement":{"PropertyExpression":{"objectExpression":{"VariableExpression":"it"},"property":"baseName"}}}],"scope":{"declaredVariables":[],"referencedClassVariables":[]},"labels":[]}},"parameters":[]}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resunique_847(
        res=out_channels.get("res")
    )


class Resmix_848(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_848(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_794: typing.Union[bool, None],
    channel_789: typing.Union[str, None],
    channel_847: typing.Union[str, None]
) -> Resmix_848:
    cond = ((condition_794 == True) and (channel_789 is not None) and (channel_847 is not None))

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = [json.loads(channel_789), json.loads(channel_847)]



        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/methylseq.nf', '-lib', 'lib', '-entry', 'METHYLSEQ', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_848(
        res=out_channels.get("res")
    )


class ResChannel_empty___853(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_empty___853(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_794: typing.Union[bool, None],
    condition_851: typing.Union[bool, None]
) -> ResChannel_empty___853:
    cond = ((condition_794 == False) and (condition_851 == True))

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = []



        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/bwameth.nf', '-lib', 'lib', '-entry', 'BWAMETH', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"empty","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResChannel_empty___853(
        res=out_channels.get("res")
    )


class Resmix_855(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_855(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_794: typing.Union[bool, None],
    condition_851: typing.Union[bool, None],
    channel_853: typing.Union[str, None],
    channel_854_1: typing.Union[str, None]
) -> Resmix_855:
    cond = ((condition_794 == False) and (condition_851 == True) and (channel_853 is not None) and (channel_854_1 is not None))

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = [json.loads(channel_853), json.loads(channel_854_1)]



        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/bwameth.nf', '-lib', 'lib', '-entry', 'BWAMETH', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_855(
        res=out_channels.get("res")
    )


class Resmix_857(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_857(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_794: typing.Union[bool, None],
    condition_851: typing.Union[bool, None],
    channel_855: typing.Union[str, None],
    channel_856_2: typing.Union[str, None]
) -> Resmix_857:
    cond = ((condition_794 == False) and (condition_851 == True) and (channel_855 is not None) and (channel_856_2 is not None))

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = [json.loads(channel_855), json.loads(channel_856_2)]



        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/bwameth.nf', '-lib', 'lib', '-entry', 'BWAMETH', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_857(
        res=out_channels.get("res")
    )


@dataclass
class Dataclass_858_pre:
    wf_input: typing.List[Sample]
    wf_genome: Genome
    wf_save_reference: bool
    wf_save_align_intermeds: bool
    wf_aligner: Aligner
    wf_clip_r1: int
    wf_clip_r2: int
    wf_three_prime_clip_r1: int
    wf_three_prime_clip_r2: int
    wf_nextseq_trim: int
    wf_cytosine_report: bool
    wf_num_mismatches: float
    wf_skip_trimming: bool
    wf_skip_deduplication: bool
    wf_skip_multiqc: bool
    wf_outdir: str
    channel_856_0: str


class Res_858_pre(NamedTuple):
    default: typing.List[Dataclass_858_pre]
    is_skipped: bool

@task(cache=True)
def pre_adapter_SAMTOOLS_INDEX_ALIGNMENTS_858_pre(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_794: typing.Union[bool, None],
    condition_851: typing.Union[bool, None],
    channel_856_0: typing.Union[str, None]
) -> Res_858_pre:
    cond = ((condition_794 == False) and (condition_851 == True) and (channel_856_0 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_858_pre, {'wf_input': wf_input, 'wf_genome': wf_genome, 'wf_save_reference': wf_save_reference, 'wf_save_align_intermeds': wf_save_align_intermeds, 'wf_aligner': wf_aligner, 'wf_clip_r1': wf_clip_r1, 'wf_clip_r2': wf_clip_r2, 'wf_three_prime_clip_r1': wf_three_prime_clip_r1, 'wf_three_prime_clip_r2': wf_three_prime_clip_r2, 'wf_nextseq_trim': wf_nextseq_trim, 'wf_cytosine_report': wf_cytosine_report, 'wf_num_mismatches': wf_num_mismatches, 'wf_skip_trimming': wf_skip_trimming, 'wf_skip_deduplication': wf_skip_deduplication, 'wf_skip_multiqc': wf_skip_multiqc, 'wf_outdir': wf_outdir}, {'channel_856_0': channel_856_0})
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        result = []

    return Res_858_pre(default=result, is_skipped = not cond)

class Respost_adapter_SAMTOOLS_INDEX_ALIGNMENTS_858_post(NamedTuple):
    bai: typing.Union[str, None]
    csi: typing.Union[str, None]
    crai: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_858_post:
    bai: str
    csi: str
    crai: str
    versions: str

@task(cache=True)
def post_adapter_SAMTOOLS_INDEX_ALIGNMENTS_858_post(
    default: List[Dataclass_858_post],
    is_skipped: bool,
) -> Respost_adapter_SAMTOOLS_INDEX_ALIGNMENTS_858_post:
    return get_mapper_outputs(Respost_adapter_SAMTOOLS_INDEX_ALIGNMENTS_858_post, default, is_skipped)


def _read_resources() -> Dict:
    try:
        with open(".latch/resources.json") as f:
            return json.load(f)
    except FileNotFoundError:
        return {}

def allocate_cpu(default: Dataclass_858_pre) -> int:
    res = _read_resources()
    return max(1, res['cpu_cores']) if res.get('cpu_cores') is not None else 4

def allocate_memory(default: Dataclass_858_pre) -> int:
    res = _read_resources()
    return max(1, res['memory_bytes'] // 1024**3) if res.get('memory_bytes') is not None else 16

def allocate_disk(default: Dataclass_858_pre) -> int:
    res = _read_resources()
    return max(1, res['disk_bytes'] // 1024**3) if res.get('disk_bytes') is not None else 4800

def get_resources(default: Dataclass_858_pre):
    wf_paths = {}
    wf_input = default.wf_input
    wf_input = construct_samplesheet(wf_input)
    wf_genome = default.wf_genome
    wf_save_reference = default.wf_save_reference
    wf_save_align_intermeds = default.wf_save_align_intermeds
    wf_aligner = default.wf_aligner
    wf_clip_r1 = default.wf_clip_r1
    wf_clip_r2 = default.wf_clip_r2
    wf_three_prime_clip_r1 = default.wf_three_prime_clip_r1
    wf_three_prime_clip_r2 = default.wf_three_prime_clip_r2
    wf_nextseq_trim = default.wf_nextseq_trim
    wf_cytosine_report = default.wf_cytosine_report
    wf_num_mismatches = default.wf_num_mismatches
    wf_skip_trimming = default.wf_skip_trimming
    wf_skip_deduplication = default.wf_skip_deduplication
    wf_skip_multiqc = default.wf_skip_multiqc
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_856_0)]

    if not True:
        download_files(channel_vals, LatchDir('latch:///methylseq-outputs'))

    flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/local/bwameth.nf','-lib','lib','-profile','mamba','-entry','BWAMETH', *flags],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"SAMTOOLS_INDEX_ALIGNMENTS","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"bai\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_INDEX_ALIGNMENTS\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"csi\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_INDEX_ALIGNMENTS\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"crai\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_INDEX_ALIGNMENTS\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":2}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_INDEX_ALIGNMENTS\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":3}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'True',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

@custom_task(cpu=allocate_cpu, memory=allocate_memory, storage_gib=allocate_disk, pre_execute=get_resources, cache=True)
def SAMTOOLS_INDEX_ALIGNMENTS_858(
    default: Dataclass_858_pre
) -> Dataclass_858_post:
    wf_paths = {}
    wf_input = default.wf_input
    wf_input = construct_samplesheet(wf_input)
    wf_genome = default.wf_genome
    wf_save_reference = default.wf_save_reference
    wf_save_align_intermeds = default.wf_save_align_intermeds
    wf_aligner = default.wf_aligner
    wf_clip_r1 = default.wf_clip_r1
    wf_clip_r2 = default.wf_clip_r2
    wf_three_prime_clip_r1 = default.wf_three_prime_clip_r1
    wf_three_prime_clip_r2 = default.wf_three_prime_clip_r2
    wf_nextseq_trim = default.wf_nextseq_trim
    wf_cytosine_report = default.wf_cytosine_report
    wf_num_mismatches = default.wf_num_mismatches
    wf_skip_trimming = default.wf_skip_trimming
    wf_skip_deduplication = default.wf_skip_deduplication
    wf_skip_multiqc = default.wf_skip_multiqc
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_856_0)]

    if not False:
        download_files(channel_vals, LatchDir('latch:///methylseq-outputs'))

    flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/local/bwameth.nf','-lib','lib','-profile','mamba','-entry','BWAMETH', *flags],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"SAMTOOLS_INDEX_ALIGNMENTS","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"bai\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_INDEX_ALIGNMENTS\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"csi\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_INDEX_ALIGNMENTS\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"crai\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_INDEX_ALIGNMENTS\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":2}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_INDEX_ALIGNMENTS\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":3}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'False',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = json.loads(file.read_text())

    print(out_channels)

    publish_dir = None
    upload_files(out_channels, LatchDir('latch:///methylseq-outputs'), publish_dir)

    out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    return Dataclass_858_post(
        bai=out_channels.get(f"bai"),
        csi=out_channels.get(f"csi"),
        crai=out_channels.get(f"crai"),
        versions=out_channels.get(f"versions")
    )


class Resmix_859(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_859(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_794: typing.Union[bool, None],
    condition_851: typing.Union[bool, None],
    channel_857: typing.Union[str, None],
    channel_858_3: typing.Union[str, None]
) -> Resmix_859:
    cond = ((condition_794 == False) and (condition_851 == True) and (channel_857 is not None) and (channel_858_3 is not None))

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = [json.loads(channel_857), json.loads(channel_858_3)]



        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/bwameth.nf', '-lib', 'lib', '-entry', 'BWAMETH', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_859(
        res=out_channels.get("res")
    )


class Resjoin_860(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def join_860(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_794: typing.Union[bool, None],
    condition_851: typing.Union[bool, None],
    channel_854_0: typing.Union[str, None],
    channel_858_0: typing.Union[str, None]
) -> Resjoin_860:
    cond = ((condition_794 == False) and (condition_851 == True) and (channel_854_0 is not None) and (channel_858_0 is not None))

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = [json.loads(channel_854_0), json.loads(channel_858_0)]



        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/bwameth.nf', '-lib', 'lib', '-entry', 'BWAMETH', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"join","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resjoin_860(
        res=out_channels.get("res")
    )


@dataclass
class Dataclass_861_pre:
    wf_input: typing.List[Sample]
    wf_genome: Genome
    wf_save_reference: bool
    wf_save_align_intermeds: bool
    wf_aligner: Aligner
    wf_clip_r1: int
    wf_clip_r2: int
    wf_three_prime_clip_r1: int
    wf_three_prime_clip_r2: int
    wf_nextseq_trim: int
    wf_cytosine_report: bool
    wf_num_mismatches: float
    wf_skip_trimming: bool
    wf_skip_deduplication: bool
    wf_skip_multiqc: bool
    wf_outdir: str
    channel_860: str


class Res_861_pre(NamedTuple):
    default: typing.List[Dataclass_861_pre]
    is_skipped: bool

@task(cache=True)
def pre_adapter_SAMTOOLS_FLAGSTAT_861_pre(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_794: typing.Union[bool, None],
    condition_851: typing.Union[bool, None],
    channel_860: typing.Union[str, None]
) -> Res_861_pre:
    cond = ((condition_794 == False) and (condition_851 == True) and (channel_860 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_861_pre, {'wf_input': wf_input, 'wf_genome': wf_genome, 'wf_save_reference': wf_save_reference, 'wf_save_align_intermeds': wf_save_align_intermeds, 'wf_aligner': wf_aligner, 'wf_clip_r1': wf_clip_r1, 'wf_clip_r2': wf_clip_r2, 'wf_three_prime_clip_r1': wf_three_prime_clip_r1, 'wf_three_prime_clip_r2': wf_three_prime_clip_r2, 'wf_nextseq_trim': wf_nextseq_trim, 'wf_cytosine_report': wf_cytosine_report, 'wf_num_mismatches': wf_num_mismatches, 'wf_skip_trimming': wf_skip_trimming, 'wf_skip_deduplication': wf_skip_deduplication, 'wf_skip_multiqc': wf_skip_multiqc, 'wf_outdir': wf_outdir}, {'channel_860': channel_860})
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        result = []

    return Res_861_pre(default=result, is_skipped = not cond)

class Respost_adapter_SAMTOOLS_FLAGSTAT_861_post(NamedTuple):
    flagstat: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_861_post:
    flagstat: str
    versions: str

@task(cache=True)
def post_adapter_SAMTOOLS_FLAGSTAT_861_post(
    default: List[Dataclass_861_post],
    is_skipped: bool,
) -> Respost_adapter_SAMTOOLS_FLAGSTAT_861_post:
    return get_mapper_outputs(Respost_adapter_SAMTOOLS_FLAGSTAT_861_post, default, is_skipped)


def _read_resources() -> Dict:
    try:
        with open(".latch/resources.json") as f:
            return json.load(f)
    except FileNotFoundError:
        return {}

def allocate_cpu(default: Dataclass_861_pre) -> int:
    res = _read_resources()
    return max(1, res['cpu_cores']) if res.get('cpu_cores') is not None else 4

def allocate_memory(default: Dataclass_861_pre) -> int:
    res = _read_resources()
    return max(1, res['memory_bytes'] // 1024**3) if res.get('memory_bytes') is not None else 16

def allocate_disk(default: Dataclass_861_pre) -> int:
    res = _read_resources()
    return max(1, res['disk_bytes'] // 1024**3) if res.get('disk_bytes') is not None else 4800

def get_resources(default: Dataclass_861_pre):
    wf_paths = {}
    wf_input = default.wf_input
    wf_input = construct_samplesheet(wf_input)
    wf_genome = default.wf_genome
    wf_save_reference = default.wf_save_reference
    wf_save_align_intermeds = default.wf_save_align_intermeds
    wf_aligner = default.wf_aligner
    wf_clip_r1 = default.wf_clip_r1
    wf_clip_r2 = default.wf_clip_r2
    wf_three_prime_clip_r1 = default.wf_three_prime_clip_r1
    wf_three_prime_clip_r2 = default.wf_three_prime_clip_r2
    wf_nextseq_trim = default.wf_nextseq_trim
    wf_cytosine_report = default.wf_cytosine_report
    wf_num_mismatches = default.wf_num_mismatches
    wf_skip_trimming = default.wf_skip_trimming
    wf_skip_deduplication = default.wf_skip_deduplication
    wf_skip_multiqc = default.wf_skip_multiqc
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_860)]

    if not True:
        download_files(channel_vals, LatchDir('latch:///methylseq-outputs'))

    flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/local/bwameth.nf','-lib','lib','-profile','mamba','-entry','BWAMETH', *flags],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"SAMTOOLS_FLAGSTAT","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"flagstat\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_FLAGSTAT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_FLAGSTAT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'True',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

@custom_task(cpu=allocate_cpu, memory=allocate_memory, storage_gib=allocate_disk, pre_execute=get_resources, cache=True)
def SAMTOOLS_FLAGSTAT_861(
    default: Dataclass_861_pre
) -> Dataclass_861_post:
    wf_paths = {}
    wf_input = default.wf_input
    wf_input = construct_samplesheet(wf_input)
    wf_genome = default.wf_genome
    wf_save_reference = default.wf_save_reference
    wf_save_align_intermeds = default.wf_save_align_intermeds
    wf_aligner = default.wf_aligner
    wf_clip_r1 = default.wf_clip_r1
    wf_clip_r2 = default.wf_clip_r2
    wf_three_prime_clip_r1 = default.wf_three_prime_clip_r1
    wf_three_prime_clip_r2 = default.wf_three_prime_clip_r2
    wf_nextseq_trim = default.wf_nextseq_trim
    wf_cytosine_report = default.wf_cytosine_report
    wf_num_mismatches = default.wf_num_mismatches
    wf_skip_trimming = default.wf_skip_trimming
    wf_skip_deduplication = default.wf_skip_deduplication
    wf_skip_multiqc = default.wf_skip_multiqc
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_860)]

    if not False:
        download_files(channel_vals, LatchDir('latch:///methylseq-outputs'))

    flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/local/bwameth.nf','-lib','lib','-profile','mamba','-entry','BWAMETH', *flags],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"SAMTOOLS_FLAGSTAT","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"flagstat\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_FLAGSTAT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_FLAGSTAT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'False',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = json.loads(file.read_text())

    print(out_channels)

    publish_dir = None
    upload_files(out_channels, LatchDir('latch:///methylseq-outputs'), publish_dir)

    out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    return Dataclass_861_post(
        flagstat=out_channels.get(f"flagstat"),
        versions=out_channels.get(f"versions")
    )


class Resmix_864(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_864(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_794: typing.Union[bool, None],
    condition_851: typing.Union[bool, None],
    channel_859: typing.Union[str, None],
    channel_861_1: typing.Union[str, None]
) -> Resmix_864:
    cond = ((condition_794 == False) and (condition_851 == True) and (channel_859 is not None) and (channel_861_1 is not None))

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = [json.loads(channel_859), json.loads(channel_861_1)]



        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/bwameth.nf', '-lib', 'lib', '-entry', 'BWAMETH', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_864(
        res=out_channels.get("res")
    )


class Resjoin_862(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def join_862(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_794: typing.Union[bool, None],
    condition_851: typing.Union[bool, None],
    channel_854_0: typing.Union[str, None],
    channel_858_0: typing.Union[str, None]
) -> Resjoin_862:
    cond = ((condition_794 == False) and (condition_851 == True) and (channel_854_0 is not None) and (channel_858_0 is not None))

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = [json.loads(channel_854_0), json.loads(channel_858_0)]



        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/bwameth.nf', '-lib', 'lib', '-entry', 'BWAMETH', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"join","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resjoin_862(
        res=out_channels.get("res")
    )


@dataclass
class Dataclass_863_pre:
    wf_input: typing.List[Sample]
    wf_genome: Genome
    wf_save_reference: bool
    wf_save_align_intermeds: bool
    wf_aligner: Aligner
    wf_clip_r1: int
    wf_clip_r2: int
    wf_three_prime_clip_r1: int
    wf_three_prime_clip_r2: int
    wf_nextseq_trim: int
    wf_cytosine_report: bool
    wf_num_mismatches: float
    wf_skip_trimming: bool
    wf_skip_deduplication: bool
    wf_skip_multiqc: bool
    wf_outdir: str
    channel_862: str


class Res_863_pre(NamedTuple):
    default: typing.List[Dataclass_863_pre]
    is_skipped: bool

@task(cache=True)
def pre_adapter_SAMTOOLS_STATS_863_pre(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_794: typing.Union[bool, None],
    condition_851: typing.Union[bool, None],
    channel_862: typing.Union[str, None]
) -> Res_863_pre:
    cond = ((condition_794 == False) and (condition_851 == True) and (channel_862 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_863_pre, {'wf_input': wf_input, 'wf_genome': wf_genome, 'wf_save_reference': wf_save_reference, 'wf_save_align_intermeds': wf_save_align_intermeds, 'wf_aligner': wf_aligner, 'wf_clip_r1': wf_clip_r1, 'wf_clip_r2': wf_clip_r2, 'wf_three_prime_clip_r1': wf_three_prime_clip_r1, 'wf_three_prime_clip_r2': wf_three_prime_clip_r2, 'wf_nextseq_trim': wf_nextseq_trim, 'wf_cytosine_report': wf_cytosine_report, 'wf_num_mismatches': wf_num_mismatches, 'wf_skip_trimming': wf_skip_trimming, 'wf_skip_deduplication': wf_skip_deduplication, 'wf_skip_multiqc': wf_skip_multiqc, 'wf_outdir': wf_outdir}, {'channel_862': channel_862})
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        result = []

    return Res_863_pre(default=result, is_skipped = not cond)

class Respost_adapter_SAMTOOLS_STATS_863_post(NamedTuple):
    stats: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_863_post:
    stats: str
    versions: str

@task(cache=True)
def post_adapter_SAMTOOLS_STATS_863_post(
    default: List[Dataclass_863_post],
    is_skipped: bool,
) -> Respost_adapter_SAMTOOLS_STATS_863_post:
    return get_mapper_outputs(Respost_adapter_SAMTOOLS_STATS_863_post, default, is_skipped)


def _read_resources() -> Dict:
    try:
        with open(".latch/resources.json") as f:
            return json.load(f)
    except FileNotFoundError:
        return {}

def allocate_cpu(default: Dataclass_863_pre) -> int:
    res = _read_resources()
    return max(1, res['cpu_cores']) if res.get('cpu_cores') is not None else 4

def allocate_memory(default: Dataclass_863_pre) -> int:
    res = _read_resources()
    return max(1, res['memory_bytes'] // 1024**3) if res.get('memory_bytes') is not None else 16

def allocate_disk(default: Dataclass_863_pre) -> int:
    res = _read_resources()
    return max(1, res['disk_bytes'] // 1024**3) if res.get('disk_bytes') is not None else 4800

def get_resources(default: Dataclass_863_pre):
    wf_paths = {}
    wf_input = default.wf_input
    wf_input = construct_samplesheet(wf_input)
    wf_genome = default.wf_genome
    wf_save_reference = default.wf_save_reference
    wf_save_align_intermeds = default.wf_save_align_intermeds
    wf_aligner = default.wf_aligner
    wf_clip_r1 = default.wf_clip_r1
    wf_clip_r2 = default.wf_clip_r2
    wf_three_prime_clip_r1 = default.wf_three_prime_clip_r1
    wf_three_prime_clip_r2 = default.wf_three_prime_clip_r2
    wf_nextseq_trim = default.wf_nextseq_trim
    wf_cytosine_report = default.wf_cytosine_report
    wf_num_mismatches = default.wf_num_mismatches
    wf_skip_trimming = default.wf_skip_trimming
    wf_skip_deduplication = default.wf_skip_deduplication
    wf_skip_multiqc = default.wf_skip_multiqc
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_862)]

    if not True:
        download_files(channel_vals, LatchDir('latch:///methylseq-outputs'))

    flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/local/bwameth.nf','-lib','lib','-profile','mamba','-entry','BWAMETH', *flags],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"SAMTOOLS_STATS","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"ListExpression":[]}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"stats\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_STATS\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_STATS\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'True',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

@custom_task(cpu=allocate_cpu, memory=allocate_memory, storage_gib=allocate_disk, pre_execute=get_resources, cache=True)
def SAMTOOLS_STATS_863(
    default: Dataclass_863_pre
) -> Dataclass_863_post:
    wf_paths = {}
    wf_input = default.wf_input
    wf_input = construct_samplesheet(wf_input)
    wf_genome = default.wf_genome
    wf_save_reference = default.wf_save_reference
    wf_save_align_intermeds = default.wf_save_align_intermeds
    wf_aligner = default.wf_aligner
    wf_clip_r1 = default.wf_clip_r1
    wf_clip_r2 = default.wf_clip_r2
    wf_three_prime_clip_r1 = default.wf_three_prime_clip_r1
    wf_three_prime_clip_r2 = default.wf_three_prime_clip_r2
    wf_nextseq_trim = default.wf_nextseq_trim
    wf_cytosine_report = default.wf_cytosine_report
    wf_num_mismatches = default.wf_num_mismatches
    wf_skip_trimming = default.wf_skip_trimming
    wf_skip_deduplication = default.wf_skip_deduplication
    wf_skip_multiqc = default.wf_skip_multiqc
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_862)]

    if not False:
        download_files(channel_vals, LatchDir('latch:///methylseq-outputs'))

    flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/local/bwameth.nf','-lib','lib','-profile','mamba','-entry','BWAMETH', *flags],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"SAMTOOLS_STATS","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"ListExpression":[]}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"stats\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_STATS\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_STATS\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'False',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = json.loads(file.read_text())

    print(out_channels)

    publish_dir = None
    upload_files(out_channels, LatchDir('latch:///methylseq-outputs'), publish_dir)

    out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    return Dataclass_863_post(
        stats=out_channels.get(f"stats"),
        versions=out_channels.get(f"versions")
    )


class Resmix_865(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_865(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_794: typing.Union[bool, None],
    condition_851: typing.Union[bool, None],
    channel_864: typing.Union[str, None],
    channel_863_1: typing.Union[str, None]
) -> Resmix_865:
    cond = ((condition_794 == False) and (condition_851 == True) and (channel_864 is not None) and (channel_863_1 is not None))

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = [json.loads(channel_864), json.loads(channel_863_1)]



        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/bwameth.nf', '-lib', 'lib', '-entry', 'BWAMETH', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_865(
        res=out_channels.get("res")
    )


class Resmix_872(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_872(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_794: typing.Union[bool, None],
    condition_851: typing.Union[bool, None],
    condition_867: typing.Union[bool, None],
    channel_865: typing.Union[str, None],
    channel_870_3: typing.Union[str, None]
) -> Resmix_872:
    cond = ((condition_794 == False) and (condition_851 == True) and (condition_867 == False) and (channel_865 is not None) and (channel_870_3 is not None))

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = [json.loads(channel_865), json.loads(channel_870_3)]



        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/bwameth.nf', '-lib', 'lib', '-entry', 'BWAMETH', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_872(
        res=out_channels.get("res")
    )


class ResMerge_versions_877(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_versions_877(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_794: typing.Union[bool, None],
    condition_851: typing.Union[bool, None],
    channel_865: typing.Union[str, None],
    channel_872: typing.Union[str, None]
) -> ResMerge_versions_877:
    cond = ((condition_794 == False) and (condition_851 == True))

    if cond:
        res = { 'res': channel_865 or channel_872 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_versions_877(
        res=res.get('res')
    )


class ResMerge_alignments_874(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_alignments_874(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_794: typing.Union[bool, None],
    condition_851: typing.Union[bool, None],
    channel_856_0: typing.Union[str, None],
    channel_870_0: typing.Union[str, None]
) -> ResMerge_alignments_874:
    cond = ((condition_794 == False) and (condition_851 == True))

    if cond:
        res = { 'res': channel_856_0 or channel_870_0 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_alignments_874(
        res=res.get('res')
    )


@dataclass
class Dataclass_871_pre:
    wf_input: typing.List[Sample]
    wf_genome: Genome
    wf_save_reference: bool
    wf_save_align_intermeds: bool
    wf_aligner: Aligner
    wf_clip_r1: int
    wf_clip_r2: int
    wf_three_prime_clip_r1: int
    wf_three_prime_clip_r2: int
    wf_nextseq_trim: int
    wf_cytosine_report: bool
    wf_num_mismatches: float
    wf_skip_trimming: bool
    wf_skip_deduplication: bool
    wf_skip_multiqc: bool
    wf_outdir: str
    channel_870_0: str


class Res_871_pre(NamedTuple):
    default: typing.List[Dataclass_871_pre]
    is_skipped: bool

@task(cache=True)
def pre_adapter_SAMTOOLS_INDEX_DEDUPLICATED_871_pre(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_794: typing.Union[bool, None],
    condition_851: typing.Union[bool, None],
    condition_867: typing.Union[bool, None],
    channel_870_0: typing.Union[str, None]
) -> Res_871_pre:
    cond = ((condition_794 == False) and (condition_851 == True) and (condition_867 == False) and (channel_870_0 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_871_pre, {'wf_input': wf_input, 'wf_genome': wf_genome, 'wf_save_reference': wf_save_reference, 'wf_save_align_intermeds': wf_save_align_intermeds, 'wf_aligner': wf_aligner, 'wf_clip_r1': wf_clip_r1, 'wf_clip_r2': wf_clip_r2, 'wf_three_prime_clip_r1': wf_three_prime_clip_r1, 'wf_three_prime_clip_r2': wf_three_prime_clip_r2, 'wf_nextseq_trim': wf_nextseq_trim, 'wf_cytosine_report': wf_cytosine_report, 'wf_num_mismatches': wf_num_mismatches, 'wf_skip_trimming': wf_skip_trimming, 'wf_skip_deduplication': wf_skip_deduplication, 'wf_skip_multiqc': wf_skip_multiqc, 'wf_outdir': wf_outdir}, {'channel_870_0': channel_870_0})
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        result = []

    return Res_871_pre(default=result, is_skipped = not cond)

class Respost_adapter_SAMTOOLS_INDEX_DEDUPLICATED_871_post(NamedTuple):
    bai: typing.Union[str, None]
    csi: typing.Union[str, None]
    crai: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_871_post:
    bai: str
    csi: str
    crai: str
    versions: str

@task(cache=True)
def post_adapter_SAMTOOLS_INDEX_DEDUPLICATED_871_post(
    default: List[Dataclass_871_post],
    is_skipped: bool,
) -> Respost_adapter_SAMTOOLS_INDEX_DEDUPLICATED_871_post:
    return get_mapper_outputs(Respost_adapter_SAMTOOLS_INDEX_DEDUPLICATED_871_post, default, is_skipped)


def _read_resources() -> Dict:
    try:
        with open(".latch/resources.json") as f:
            return json.load(f)
    except FileNotFoundError:
        return {}

def allocate_cpu(default: Dataclass_871_pre) -> int:
    res = _read_resources()
    return max(1, res['cpu_cores']) if res.get('cpu_cores') is not None else 4

def allocate_memory(default: Dataclass_871_pre) -> int:
    res = _read_resources()
    return max(1, res['memory_bytes'] // 1024**3) if res.get('memory_bytes') is not None else 16

def allocate_disk(default: Dataclass_871_pre) -> int:
    res = _read_resources()
    return max(1, res['disk_bytes'] // 1024**3) if res.get('disk_bytes') is not None else 4800

def get_resources(default: Dataclass_871_pre):
    wf_paths = {}
    wf_input = default.wf_input
    wf_input = construct_samplesheet(wf_input)
    wf_genome = default.wf_genome
    wf_save_reference = default.wf_save_reference
    wf_save_align_intermeds = default.wf_save_align_intermeds
    wf_aligner = default.wf_aligner
    wf_clip_r1 = default.wf_clip_r1
    wf_clip_r2 = default.wf_clip_r2
    wf_three_prime_clip_r1 = default.wf_three_prime_clip_r1
    wf_three_prime_clip_r2 = default.wf_three_prime_clip_r2
    wf_nextseq_trim = default.wf_nextseq_trim
    wf_cytosine_report = default.wf_cytosine_report
    wf_num_mismatches = default.wf_num_mismatches
    wf_skip_trimming = default.wf_skip_trimming
    wf_skip_deduplication = default.wf_skip_deduplication
    wf_skip_multiqc = default.wf_skip_multiqc
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_870_0)]

    if not True:
        download_files(channel_vals, LatchDir('latch:///methylseq-outputs'))

    flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/local/bwameth.nf','-lib','lib','-profile','mamba','-entry','BWAMETH', *flags],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"SAMTOOLS_INDEX_DEDUPLICATED","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"bai\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_INDEX_DEDUPLICATED\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"csi\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_INDEX_DEDUPLICATED\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"crai\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_INDEX_DEDUPLICATED\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":2}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_INDEX_DEDUPLICATED\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":3}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'True',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

@custom_task(cpu=allocate_cpu, memory=allocate_memory, storage_gib=allocate_disk, pre_execute=get_resources, cache=True)
def SAMTOOLS_INDEX_DEDUPLICATED_871(
    default: Dataclass_871_pre
) -> Dataclass_871_post:
    wf_paths = {}
    wf_input = default.wf_input
    wf_input = construct_samplesheet(wf_input)
    wf_genome = default.wf_genome
    wf_save_reference = default.wf_save_reference
    wf_save_align_intermeds = default.wf_save_align_intermeds
    wf_aligner = default.wf_aligner
    wf_clip_r1 = default.wf_clip_r1
    wf_clip_r2 = default.wf_clip_r2
    wf_three_prime_clip_r1 = default.wf_three_prime_clip_r1
    wf_three_prime_clip_r2 = default.wf_three_prime_clip_r2
    wf_nextseq_trim = default.wf_nextseq_trim
    wf_cytosine_report = default.wf_cytosine_report
    wf_num_mismatches = default.wf_num_mismatches
    wf_skip_trimming = default.wf_skip_trimming
    wf_skip_deduplication = default.wf_skip_deduplication
    wf_skip_multiqc = default.wf_skip_multiqc
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_870_0)]

    if not False:
        download_files(channel_vals, LatchDir('latch:///methylseq-outputs'))

    flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/local/bwameth.nf','-lib','lib','-profile','mamba','-entry','BWAMETH', *flags],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"SAMTOOLS_INDEX_DEDUPLICATED","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"bai\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_INDEX_DEDUPLICATED\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"csi\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_INDEX_DEDUPLICATED\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"crai\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_INDEX_DEDUPLICATED\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":2}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_INDEX_DEDUPLICATED\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":3}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'False',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = json.loads(file.read_text())

    print(out_channels)

    publish_dir = None
    upload_files(out_channels, LatchDir('latch:///methylseq-outputs'), publish_dir)

    out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    return Dataclass_871_post(
        bai=out_channels.get(f"bai"),
        csi=out_channels.get(f"csi"),
        crai=out_channels.get(f"crai"),
        versions=out_channels.get(f"versions")
    )


class ResMerge_bam_index_873(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_bam_index_873(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_794: typing.Union[bool, None],
    condition_851: typing.Union[bool, None],
    channel_858_0: typing.Union[str, None],
    channel_871_0: typing.Union[str, None]
) -> ResMerge_bam_index_873:
    cond = ((condition_794 == False) and (condition_851 == True))

    if cond:
        res = { 'res': channel_858_0 or channel_871_0 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_bam_index_873(
        res=res.get('res')
    )


class Resjoin_878(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def join_878(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_794: typing.Union[bool, None],
    condition_851: typing.Union[bool, None],
    channel_874: typing.Union[str, None],
    channel_873: typing.Union[str, None]
) -> Resjoin_878:
    cond = ((condition_794 == False) and (condition_851 == True) and (channel_874 is not None) and (channel_873 is not None))

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = [json.loads(channel_874), json.loads(channel_873)]



        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/bwameth.nf', '-lib', 'lib', '-entry', 'BWAMETH', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"join","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resjoin_878(
        res=out_channels.get("res")
    )


@dataclass
class Dataclass_879_pre:
    wf_input: typing.List[Sample]
    wf_genome: Genome
    wf_save_reference: bool
    wf_save_align_intermeds: bool
    wf_aligner: Aligner
    wf_clip_r1: int
    wf_clip_r2: int
    wf_three_prime_clip_r1: int
    wf_three_prime_clip_r2: int
    wf_nextseq_trim: int
    wf_cytosine_report: bool
    wf_num_mismatches: float
    wf_skip_trimming: bool
    wf_skip_deduplication: bool
    wf_skip_multiqc: bool
    wf_outdir: str
    channel_878: str
    channel_709: str
    channel_765: str


class Res_879_pre(NamedTuple):
    default: typing.List[Dataclass_879_pre]
    is_skipped: bool

@task(cache=True)
def pre_adapter_METHYLDACKEL_EXTRACT_879_pre(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_794: typing.Union[bool, None],
    condition_851: typing.Union[bool, None],
    channel_878: typing.Union[str, None],
    channel_709: typing.Union[str, None],
    channel_765: typing.Union[str, None]
) -> Res_879_pre:
    cond = ((condition_794 == False) and (condition_851 == True) and (channel_878 is not None) and (channel_709 is not None) and (channel_765 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_879_pre, {'wf_input': wf_input, 'wf_genome': wf_genome, 'wf_save_reference': wf_save_reference, 'wf_save_align_intermeds': wf_save_align_intermeds, 'wf_aligner': wf_aligner, 'wf_clip_r1': wf_clip_r1, 'wf_clip_r2': wf_clip_r2, 'wf_three_prime_clip_r1': wf_three_prime_clip_r1, 'wf_three_prime_clip_r2': wf_three_prime_clip_r2, 'wf_nextseq_trim': wf_nextseq_trim, 'wf_cytosine_report': wf_cytosine_report, 'wf_num_mismatches': wf_num_mismatches, 'wf_skip_trimming': wf_skip_trimming, 'wf_skip_deduplication': wf_skip_deduplication, 'wf_skip_multiqc': wf_skip_multiqc, 'wf_outdir': wf_outdir}, {'channel_878': channel_878, 'channel_709': channel_709, 'channel_765': channel_765})
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        result = []

    return Res_879_pre(default=result, is_skipped = not cond)

class Respost_adapter_METHYLDACKEL_EXTRACT_879_post(NamedTuple):
    bedgraph: typing.Union[str, None]
    methylkit: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_879_post:
    bedgraph: str
    methylkit: str
    versions: str

@task(cache=True)
def post_adapter_METHYLDACKEL_EXTRACT_879_post(
    default: List[Dataclass_879_post],
    is_skipped: bool,
) -> Respost_adapter_METHYLDACKEL_EXTRACT_879_post:
    return get_mapper_outputs(Respost_adapter_METHYLDACKEL_EXTRACT_879_post, default, is_skipped)


def _read_resources() -> Dict:
    try:
        with open(".latch/resources.json") as f:
            return json.load(f)
    except FileNotFoundError:
        return {}

def allocate_cpu(default: Dataclass_879_pre) -> int:
    res = _read_resources()
    return max(1, res['cpu_cores']) if res.get('cpu_cores') is not None else 8

def allocate_memory(default: Dataclass_879_pre) -> int:
    res = _read_resources()
    return max(1, res['memory_bytes'] // 1024**3) if res.get('memory_bytes') is not None else 48

def allocate_disk(default: Dataclass_879_pre) -> int:
    res = _read_resources()
    return max(1, res['disk_bytes'] // 1024**3) if res.get('disk_bytes') is not None else 4800

def get_resources(default: Dataclass_879_pre):
    wf_paths = {}
    wf_input = default.wf_input
    wf_input = construct_samplesheet(wf_input)
    wf_genome = default.wf_genome
    wf_save_reference = default.wf_save_reference
    wf_save_align_intermeds = default.wf_save_align_intermeds
    wf_aligner = default.wf_aligner
    wf_clip_r1 = default.wf_clip_r1
    wf_clip_r2 = default.wf_clip_r2
    wf_three_prime_clip_r1 = default.wf_three_prime_clip_r1
    wf_three_prime_clip_r2 = default.wf_three_prime_clip_r2
    wf_nextseq_trim = default.wf_nextseq_trim
    wf_cytosine_report = default.wf_cytosine_report
    wf_num_mismatches = default.wf_num_mismatches
    wf_skip_trimming = default.wf_skip_trimming
    wf_skip_deduplication = default.wf_skip_deduplication
    wf_skip_multiqc = default.wf_skip_multiqc
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_878),json.loads(default.channel_709),json.loads(default.channel_765)]

    if not True:
        download_files(channel_vals, LatchDir('latch:///methylseq-outputs'))

    flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/local/bwameth.nf','-lib','lib','-profile','mamba','-entry','BWAMETH', *flags],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"METHYLDACKEL_EXTRACT","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"bedgraph\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"METHYLDACKEL_EXTRACT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"methylkit\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"METHYLDACKEL_EXTRACT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"METHYLDACKEL_EXTRACT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":2}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'True',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

@custom_task(cpu=allocate_cpu, memory=allocate_memory, storage_gib=allocate_disk, pre_execute=get_resources, cache=True)
def METHYLDACKEL_EXTRACT_879(
    default: Dataclass_879_pre
) -> Dataclass_879_post:
    wf_paths = {}
    wf_input = default.wf_input
    wf_input = construct_samplesheet(wf_input)
    wf_genome = default.wf_genome
    wf_save_reference = default.wf_save_reference
    wf_save_align_intermeds = default.wf_save_align_intermeds
    wf_aligner = default.wf_aligner
    wf_clip_r1 = default.wf_clip_r1
    wf_clip_r2 = default.wf_clip_r2
    wf_three_prime_clip_r1 = default.wf_three_prime_clip_r1
    wf_three_prime_clip_r2 = default.wf_three_prime_clip_r2
    wf_nextseq_trim = default.wf_nextseq_trim
    wf_cytosine_report = default.wf_cytosine_report
    wf_num_mismatches = default.wf_num_mismatches
    wf_skip_trimming = default.wf_skip_trimming
    wf_skip_deduplication = default.wf_skip_deduplication
    wf_skip_multiqc = default.wf_skip_multiqc
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_878),json.loads(default.channel_709),json.loads(default.channel_765)]

    if not False:
        download_files(channel_vals, LatchDir('latch:///methylseq-outputs'))

    flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/local/bwameth.nf','-lib','lib','-profile','mamba','-entry','BWAMETH', *flags],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"METHYLDACKEL_EXTRACT","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"bedgraph\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"METHYLDACKEL_EXTRACT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"methylkit\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"METHYLDACKEL_EXTRACT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"METHYLDACKEL_EXTRACT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":2}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'False',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = json.loads(file.read_text())

    print(out_channels)

    publish_dir = None
    upload_files(out_channels, LatchDir('latch:///methylseq-outputs'), publish_dir)

    out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    return Dataclass_879_post(
        bedgraph=out_channels.get(f"bedgraph"),
        methylkit=out_channels.get(f"methylkit"),
        versions=out_channels.get(f"versions")
    )


class Resmix_882(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_882(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_794: typing.Union[bool, None],
    condition_851: typing.Union[bool, None],
    channel_877: typing.Union[str, None],
    channel_879_2: typing.Union[str, None]
) -> Resmix_882:
    cond = ((condition_794 == False) and (condition_851 == True) and (channel_877 is not None) and (channel_879_2 is not None))

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = [json.loads(channel_877), json.loads(channel_879_2)]



        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/bwameth.nf', '-lib', 'lib', '-entry', 'BWAMETH', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_882(
        res=out_channels.get("res")
    )


class Resjoin_880(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def join_880(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_794: typing.Union[bool, None],
    condition_851: typing.Union[bool, None],
    channel_874: typing.Union[str, None],
    channel_873: typing.Union[str, None]
) -> Resjoin_880:
    cond = ((condition_794 == False) and (condition_851 == True) and (channel_874 is not None) and (channel_873 is not None))

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = [json.loads(channel_874), json.loads(channel_873)]



        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/bwameth.nf', '-lib', 'lib', '-entry', 'BWAMETH', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"join","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resjoin_880(
        res=out_channels.get("res")
    )


@dataclass
class Dataclass_881_pre:
    wf_input: typing.List[Sample]
    wf_genome: Genome
    wf_save_reference: bool
    wf_save_align_intermeds: bool
    wf_aligner: Aligner
    wf_clip_r1: int
    wf_clip_r2: int
    wf_three_prime_clip_r1: int
    wf_three_prime_clip_r2: int
    wf_nextseq_trim: int
    wf_cytosine_report: bool
    wf_num_mismatches: float
    wf_skip_trimming: bool
    wf_skip_deduplication: bool
    wf_skip_multiqc: bool
    wf_outdir: str
    channel_880: str
    channel_709: str
    channel_765: str


class Res_881_pre(NamedTuple):
    default: typing.List[Dataclass_881_pre]
    is_skipped: bool

@task(cache=True)
def pre_adapter_METHYLDACKEL_MBIAS_881_pre(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_794: typing.Union[bool, None],
    condition_851: typing.Union[bool, None],
    channel_880: typing.Union[str, None],
    channel_709: typing.Union[str, None],
    channel_765: typing.Union[str, None]
) -> Res_881_pre:
    cond = ((condition_794 == False) and (condition_851 == True) and (channel_880 is not None) and (channel_709 is not None) and (channel_765 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_881_pre, {'wf_input': wf_input, 'wf_genome': wf_genome, 'wf_save_reference': wf_save_reference, 'wf_save_align_intermeds': wf_save_align_intermeds, 'wf_aligner': wf_aligner, 'wf_clip_r1': wf_clip_r1, 'wf_clip_r2': wf_clip_r2, 'wf_three_prime_clip_r1': wf_three_prime_clip_r1, 'wf_three_prime_clip_r2': wf_three_prime_clip_r2, 'wf_nextseq_trim': wf_nextseq_trim, 'wf_cytosine_report': wf_cytosine_report, 'wf_num_mismatches': wf_num_mismatches, 'wf_skip_trimming': wf_skip_trimming, 'wf_skip_deduplication': wf_skip_deduplication, 'wf_skip_multiqc': wf_skip_multiqc, 'wf_outdir': wf_outdir}, {'channel_880': channel_880, 'channel_709': channel_709, 'channel_765': channel_765})
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        result = []

    return Res_881_pre(default=result, is_skipped = not cond)

class Respost_adapter_METHYLDACKEL_MBIAS_881_post(NamedTuple):
    txt: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_881_post:
    txt: str
    versions: str

@task(cache=True)
def post_adapter_METHYLDACKEL_MBIAS_881_post(
    default: List[Dataclass_881_post],
    is_skipped: bool,
) -> Respost_adapter_METHYLDACKEL_MBIAS_881_post:
    return get_mapper_outputs(Respost_adapter_METHYLDACKEL_MBIAS_881_post, default, is_skipped)


def _read_resources() -> Dict:
    try:
        with open(".latch/resources.json") as f:
            return json.load(f)
    except FileNotFoundError:
        return {}

def allocate_cpu(default: Dataclass_881_pre) -> int:
    res = _read_resources()
    return max(1, res['cpu_cores']) if res.get('cpu_cores') is not None else 4

def allocate_memory(default: Dataclass_881_pre) -> int:
    res = _read_resources()
    return max(1, res['memory_bytes'] // 1024**3) if res.get('memory_bytes') is not None else 16

def allocate_disk(default: Dataclass_881_pre) -> int:
    res = _read_resources()
    return max(1, res['disk_bytes'] // 1024**3) if res.get('disk_bytes') is not None else 4800

def get_resources(default: Dataclass_881_pre):
    wf_paths = {}
    wf_input = default.wf_input
    wf_input = construct_samplesheet(wf_input)
    wf_genome = default.wf_genome
    wf_save_reference = default.wf_save_reference
    wf_save_align_intermeds = default.wf_save_align_intermeds
    wf_aligner = default.wf_aligner
    wf_clip_r1 = default.wf_clip_r1
    wf_clip_r2 = default.wf_clip_r2
    wf_three_prime_clip_r1 = default.wf_three_prime_clip_r1
    wf_three_prime_clip_r2 = default.wf_three_prime_clip_r2
    wf_nextseq_trim = default.wf_nextseq_trim
    wf_cytosine_report = default.wf_cytosine_report
    wf_num_mismatches = default.wf_num_mismatches
    wf_skip_trimming = default.wf_skip_trimming
    wf_skip_deduplication = default.wf_skip_deduplication
    wf_skip_multiqc = default.wf_skip_multiqc
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_880),json.loads(default.channel_709),json.loads(default.channel_765)]

    if not True:
        download_files(channel_vals, LatchDir('latch:///methylseq-outputs'))

    flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/local/bwameth.nf','-lib','lib','-profile','mamba','-entry','BWAMETH', *flags],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"METHYLDACKEL_MBIAS","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"txt\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"METHYLDACKEL_MBIAS\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"METHYLDACKEL_MBIAS\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'True',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

@custom_task(cpu=allocate_cpu, memory=allocate_memory, storage_gib=allocate_disk, pre_execute=get_resources, cache=True)
def METHYLDACKEL_MBIAS_881(
    default: Dataclass_881_pre
) -> Dataclass_881_post:
    wf_paths = {}
    wf_input = default.wf_input
    wf_input = construct_samplesheet(wf_input)
    wf_genome = default.wf_genome
    wf_save_reference = default.wf_save_reference
    wf_save_align_intermeds = default.wf_save_align_intermeds
    wf_aligner = default.wf_aligner
    wf_clip_r1 = default.wf_clip_r1
    wf_clip_r2 = default.wf_clip_r2
    wf_three_prime_clip_r1 = default.wf_three_prime_clip_r1
    wf_three_prime_clip_r2 = default.wf_three_prime_clip_r2
    wf_nextseq_trim = default.wf_nextseq_trim
    wf_cytosine_report = default.wf_cytosine_report
    wf_num_mismatches = default.wf_num_mismatches
    wf_skip_trimming = default.wf_skip_trimming
    wf_skip_deduplication = default.wf_skip_deduplication
    wf_skip_multiqc = default.wf_skip_multiqc
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_880),json.loads(default.channel_709),json.loads(default.channel_765)]

    if not False:
        download_files(channel_vals, LatchDir('latch:///methylseq-outputs'))

    flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/local/bwameth.nf','-lib','lib','-profile','mamba','-entry','BWAMETH', *flags],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"METHYLDACKEL_MBIAS","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"txt\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"METHYLDACKEL_MBIAS\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"METHYLDACKEL_MBIAS\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'False',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = json.loads(file.read_text())

    print(out_channels)

    publish_dir = None
    upload_files(out_channels, LatchDir('latch:///methylseq-outputs'), publish_dir)

    out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    return Dataclass_881_post(
        txt=out_channels.get(f"txt"),
        versions=out_channels.get(f"versions")
    )


class Resmix_883(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_883(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_794: typing.Union[bool, None],
    condition_851: typing.Union[bool, None],
    channel_882: typing.Union[str, None],
    channel_881_1: typing.Union[str, None]
) -> Resmix_883:
    cond = ((condition_794 == False) and (condition_851 == True) and (channel_882 is not None) and (channel_881_1 is not None))

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = [json.loads(channel_882), json.loads(channel_881_1)]



        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/bwameth.nf', '-lib', 'lib', '-entry', 'BWAMETH', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_883(
        res=out_channels.get("res")
    )


class Resunique_893(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def unique_893(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_794: typing.Union[bool, None],
    condition_851: typing.Union[bool, None],
    channel_883: typing.Union[str, None]
) -> Resunique_893:
    cond = ((condition_794 == False) and (condition_851 == True) and (channel_883 is not None))

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = [json.loads(channel_883)]



        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/methylseq.nf', '-lib', 'lib', '-entry', 'METHYLSEQ', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"unique","arguments":{"ArgumentListExpression":{"expressions":[{"ClosureExpression":{"code":{"BlockStatement":{"statements":[{"ReturnStatement":{"PropertyExpression":{"objectExpression":{"VariableExpression":"it"},"property":"baseName"}}}],"scope":{"declaredVariables":[],"referencedClassVariables":[]},"labels":[]}},"parameters":[]}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resunique_893(
        res=out_channels.get("res")
    )


class Resmix_894(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_894(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_794: typing.Union[bool, None],
    condition_851: typing.Union[bool, None],
    channel_789: typing.Union[str, None],
    channel_893: typing.Union[str, None]
) -> Resmix_894:
    cond = ((condition_794 == False) and (condition_851 == True) and (channel_789 is not None) and (channel_893 is not None))

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = [json.loads(channel_789), json.loads(channel_893)]



        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/methylseq.nf', '-lib', 'lib', '-entry', 'METHYLSEQ', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_894(
        res=out_channels.get("res")
    )


class ResMerge_ch_versions_895(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_versions_895(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_794: typing.Union[bool, None],
    channel_894: typing.Union[str, None],
    channel_789: typing.Union[str, None]
) -> ResMerge_ch_versions_895:
    cond = ((condition_794 == False))

    if cond:
        res = { 'res': channel_894 or channel_789 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_versions_895(
        res=res.get('res')
    )


class ResMerge_ch_versions_899(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_versions_899(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    channel_848: typing.Union[str, None],
    channel_895: typing.Union[str, None]
) -> ResMerge_ch_versions_899:
    cond = True

    if cond:
        res = { 'res': channel_848 or channel_895 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_versions_899(
        res=res.get('res')
    )


class ResMerge_ch_dedup_898(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_dedup_898(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    channel_834_0: typing.Union[str, None],
    channel_874: typing.Union[str, None]
) -> ResMerge_ch_dedup_898:
    cond = True

    if cond:
        res = { 'res': channel_834_0 or channel_874 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_dedup_898(
        res=res.get('res')
    )


class Resparams_bamqc_regions_file_900(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def params_bamqc_regions_file_900(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str
) -> Resparams_bamqc_regions_file_900:
    cond = True

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = []



        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/methylseq.nf', '-lib', 'lib', '-entry', 'METHYLSEQ', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"NotExpression":{"NotExpression":{"BooleanExpression":{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"bamqc_regions_file"}}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resparams_bamqc_regions_file_900(
        res=out_channels.get("res")
    )


class Resconditional_params_bamqc_regions_file_901(NamedTuple):
    condition: typing.Union[bool, None]

@task(cache=True)
def conditional_params_bamqc_regions_file_901(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    channel_900: typing.Union[str, None]
) -> Resconditional_params_bamqc_regions_file_901:
    cond = ((channel_900 is not None))

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = [json.loads(channel_900)]



        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/methylseq.nf', '-lib', 'lib', '-entry', 'METHYLSEQ', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"condition"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"condition\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'condition': None}

    res = out_channels.get("condition")

    if res is not None:
        res = get_boolean_value(res)

    return Resconditional_params_bamqc_regions_file_901(condition=res)


class ResChannel_fromPath__checkIfExists_true___params_bamqc_regions_file_902(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_fromPath__checkIfExists_true___params_bamqc_regions_file_902(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_901: typing.Union[bool, None]
) -> ResChannel_fromPath__checkIfExists_true___params_bamqc_regions_file_902:
    cond = ((condition_901 == True))

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = []

        download_files(channel_vals, LatchDir('latch:///methylseq-outputs'))

        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/methylseq.nf', '-lib', 'lib', '-entry', 'METHYLSEQ', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"fromPath","arguments":{"ArgumentListExpression":{"expressions":[{"MapExpression":[{"MapEntryExpression":{"keyExpression":{"ConstantExpression":"checkIfExists"},"valueExpression":{"ConstantExpression":true}}}]},{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"bamqc_regions_file"}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())

        upload_files(out_channels, LatchDir('latch:///methylseq-outputs'))

        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResChannel_fromPath__checkIfExists_true___params_bamqc_regions_file_902(
        res=out_channels.get("res")
    )


class RestoList_903(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def toList_903(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_901: typing.Union[bool, None],
    channel_902: typing.Union[str, None]
) -> RestoList_903:
    cond = ((condition_901 == True) and (channel_902 is not None))

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = [json.loads(channel_902)]



        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/methylseq.nf', '-lib', 'lib', '-entry', 'METHYLSEQ', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"toList","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return RestoList_903(
        res=out_channels.get("res")
    )


class Res___904(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def ___904(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_901: typing.Union[bool, None]
) -> Res___904:
    cond = ((condition_901 == False))

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = []



        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/methylseq.nf', '-lib', 'lib', '-entry', 'METHYLSEQ', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"value","arguments":{"ArgumentListExpression":{"expressions":[{"ListExpression":[]}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Res___904(
        res=out_channels.get("res")
    )


class Res_params_bamqc_regions_file____Channel_fromPath__checkIfExists_tr_905(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def _params_bamqc_regions_file____Channel_fromPath__checkIfExists_tr_905(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    channel_903: typing.Union[str, None],
    channel_904: typing.Union[str, None]
) -> Res_params_bamqc_regions_file____Channel_fromPath__checkIfExists_tr_905:
    cond = True

    if cond:
        res = { 'res': channel_903 or channel_904 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return Res_params_bamqc_regions_file____Channel_fromPath__checkIfExists_tr_905(
        res=res.get('res')
    )


@dataclass
class Dataclass_906_pre:
    wf_input: typing.List[Sample]
    wf_genome: Genome
    wf_save_reference: bool
    wf_save_align_intermeds: bool
    wf_aligner: Aligner
    wf_clip_r1: int
    wf_clip_r2: int
    wf_three_prime_clip_r1: int
    wf_three_prime_clip_r2: int
    wf_nextseq_trim: int
    wf_cytosine_report: bool
    wf_num_mismatches: float
    wf_skip_trimming: bool
    wf_skip_deduplication: bool
    wf_skip_multiqc: bool
    wf_outdir: str
    channel_898: str
    channel_905: str


class Res_906_pre(NamedTuple):
    default: typing.List[Dataclass_906_pre]
    is_skipped: bool

@task(cache=True)
def pre_adapter_QUALIMAP_BAMQC_906_pre(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    channel_898: typing.Union[str, None],
    channel_905: typing.Union[str, None]
) -> Res_906_pre:
    cond = ((channel_898 is not None) and (channel_905 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_906_pre, {'wf_input': wf_input, 'wf_genome': wf_genome, 'wf_save_reference': wf_save_reference, 'wf_save_align_intermeds': wf_save_align_intermeds, 'wf_aligner': wf_aligner, 'wf_clip_r1': wf_clip_r1, 'wf_clip_r2': wf_clip_r2, 'wf_three_prime_clip_r1': wf_three_prime_clip_r1, 'wf_three_prime_clip_r2': wf_three_prime_clip_r2, 'wf_nextseq_trim': wf_nextseq_trim, 'wf_cytosine_report': wf_cytosine_report, 'wf_num_mismatches': wf_num_mismatches, 'wf_skip_trimming': wf_skip_trimming, 'wf_skip_deduplication': wf_skip_deduplication, 'wf_skip_multiqc': wf_skip_multiqc, 'wf_outdir': wf_outdir}, {'channel_898': channel_898, 'channel_905': channel_905})
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        result = []

    return Res_906_pre(default=result, is_skipped = not cond)

class Respost_adapter_QUALIMAP_BAMQC_906_post(NamedTuple):
    results: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_906_post:
    results: str
    versions: str

@task(cache=True)
def post_adapter_QUALIMAP_BAMQC_906_post(
    default: List[Dataclass_906_post],
    is_skipped: bool,
) -> Respost_adapter_QUALIMAP_BAMQC_906_post:
    return get_mapper_outputs(Respost_adapter_QUALIMAP_BAMQC_906_post, default, is_skipped)


def _read_resources() -> Dict:
    try:
        with open(".latch/resources.json") as f:
            return json.load(f)
    except FileNotFoundError:
        return {}

def allocate_cpu(default: Dataclass_906_pre) -> int:
    res = _read_resources()
    return max(1, res['cpu_cores']) if res.get('cpu_cores') is not None else 8

def allocate_memory(default: Dataclass_906_pre) -> int:
    res = _read_resources()
    return max(1, res['memory_bytes'] // 1024**3) if res.get('memory_bytes') is not None else 48

def allocate_disk(default: Dataclass_906_pre) -> int:
    res = _read_resources()
    return max(1, res['disk_bytes'] // 1024**3) if res.get('disk_bytes') is not None else 4800

def get_resources(default: Dataclass_906_pre):
    wf_paths = {}
    wf_input = default.wf_input
    wf_input = construct_samplesheet(wf_input)
    wf_genome = default.wf_genome
    wf_save_reference = default.wf_save_reference
    wf_save_align_intermeds = default.wf_save_align_intermeds
    wf_aligner = default.wf_aligner
    wf_clip_r1 = default.wf_clip_r1
    wf_clip_r2 = default.wf_clip_r2
    wf_three_prime_clip_r1 = default.wf_three_prime_clip_r1
    wf_three_prime_clip_r2 = default.wf_three_prime_clip_r2
    wf_nextseq_trim = default.wf_nextseq_trim
    wf_cytosine_report = default.wf_cytosine_report
    wf_num_mismatches = default.wf_num_mismatches
    wf_skip_trimming = default.wf_skip_trimming
    wf_skip_deduplication = default.wf_skip_deduplication
    wf_skip_multiqc = default.wf_skip_multiqc
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_898),json.loads(default.channel_905)]

    if not True:
        download_files(channel_vals, LatchDir('latch:///methylseq-outputs'))

    flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/workflows/methylseq.nf','-lib','lib','-profile','mamba','-entry','METHYLSEQ', *flags],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"QUALIMAP_BAMQC","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"results\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"QUALIMAP_BAMQC\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"QUALIMAP_BAMQC\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'True',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

@custom_task(cpu=allocate_cpu, memory=allocate_memory, storage_gib=allocate_disk, pre_execute=get_resources, cache=True)
def QUALIMAP_BAMQC_906(
    default: Dataclass_906_pre
) -> Dataclass_906_post:
    wf_paths = {}
    wf_input = default.wf_input
    wf_input = construct_samplesheet(wf_input)
    wf_genome = default.wf_genome
    wf_save_reference = default.wf_save_reference
    wf_save_align_intermeds = default.wf_save_align_intermeds
    wf_aligner = default.wf_aligner
    wf_clip_r1 = default.wf_clip_r1
    wf_clip_r2 = default.wf_clip_r2
    wf_three_prime_clip_r1 = default.wf_three_prime_clip_r1
    wf_three_prime_clip_r2 = default.wf_three_prime_clip_r2
    wf_nextseq_trim = default.wf_nextseq_trim
    wf_cytosine_report = default.wf_cytosine_report
    wf_num_mismatches = default.wf_num_mismatches
    wf_skip_trimming = default.wf_skip_trimming
    wf_skip_deduplication = default.wf_skip_deduplication
    wf_skip_multiqc = default.wf_skip_multiqc
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_898),json.loads(default.channel_905)]

    if not False:
        download_files(channel_vals, LatchDir('latch:///methylseq-outputs'))

    flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/workflows/methylseq.nf','-lib','lib','-profile','mamba','-entry','METHYLSEQ', *flags],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"QUALIMAP_BAMQC","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"results\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"QUALIMAP_BAMQC\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"QUALIMAP_BAMQC\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'False',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = json.loads(file.read_text())

    print(out_channels)

    publish_dir = None
    upload_files(out_channels, LatchDir('latch:///methylseq-outputs'), publish_dir)

    out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    return Dataclass_906_post(
        results=out_channels.get(f"results"),
        versions=out_channels.get(f"versions")
    )


class Resfirst_907(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def first_907(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    channel_906_1: typing.Union[str, None]
) -> Resfirst_907:
    cond = ((channel_906_1 is not None))

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = [json.loads(channel_906_1)]



        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/methylseq.nf', '-lib', 'lib', '-entry', 'METHYLSEQ', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"first","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resfirst_907(
        res=out_channels.get("res")
    )


class Resmix_908(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_908(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    channel_899: typing.Union[str, None],
    channel_907: typing.Union[str, None]
) -> Resmix_908:
    cond = ((channel_899 is not None) and (channel_907 is not None))

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = [json.loads(channel_899), json.loads(channel_907)]



        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/methylseq.nf', '-lib', 'lib', '-entry', 'METHYLSEQ', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_908(
        res=out_channels.get("res")
    )


class Resunique_909(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def unique_909(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    channel_908: typing.Union[str, None]
) -> Resunique_909:
    cond = ((channel_908 is not None))

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = [json.loads(channel_908)]



        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/methylseq.nf', '-lib', 'lib', '-entry', 'METHYLSEQ', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"unique","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resunique_909(
        res=out_channels.get("res")
    )


class RescollectFile_910(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def collectFile_910(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    channel_909: typing.Union[str, None]
) -> RescollectFile_910:
    cond = ((channel_909 is not None))

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = [json.loads(channel_909)]

        download_files(channel_vals, LatchDir('latch:///methylseq-outputs'))

        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/methylseq.nf', '-lib', 'lib', '-entry', 'METHYLSEQ', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"collectFile","arguments":{"ArgumentListExpression":{"expressions":[{"MapExpression":[{"MapEntryExpression":{"keyExpression":{"ConstantExpression":"name"},"valueExpression":{"ConstantExpression":"collated_versions.yml"}}}]}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())

        upload_files(out_channels, LatchDir('latch:///methylseq-outputs'))

        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return RescollectFile_910(
        res=out_channels.get("res")
    )


@dataclass
class Dataclass_911_pre:
    wf_input: typing.List[Sample]
    wf_genome: Genome
    wf_save_reference: bool
    wf_save_align_intermeds: bool
    wf_aligner: Aligner
    wf_clip_r1: int
    wf_clip_r2: int
    wf_three_prime_clip_r1: int
    wf_three_prime_clip_r2: int
    wf_nextseq_trim: int
    wf_cytosine_report: bool
    wf_num_mismatches: float
    wf_skip_trimming: bool
    wf_skip_deduplication: bool
    wf_skip_multiqc: bool
    wf_outdir: str
    channel_910: str


class Res_911_pre(NamedTuple):
    default: typing.List[Dataclass_911_pre]
    is_skipped: bool

@task(cache=True)
def pre_adapter_CUSTOM_DUMPSOFTWAREVERSIONS_911_pre(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    channel_910: typing.Union[str, None]
) -> Res_911_pre:
    cond = ((channel_910 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_911_pre, {'wf_input': wf_input, 'wf_genome': wf_genome, 'wf_save_reference': wf_save_reference, 'wf_save_align_intermeds': wf_save_align_intermeds, 'wf_aligner': wf_aligner, 'wf_clip_r1': wf_clip_r1, 'wf_clip_r2': wf_clip_r2, 'wf_three_prime_clip_r1': wf_three_prime_clip_r1, 'wf_three_prime_clip_r2': wf_three_prime_clip_r2, 'wf_nextseq_trim': wf_nextseq_trim, 'wf_cytosine_report': wf_cytosine_report, 'wf_num_mismatches': wf_num_mismatches, 'wf_skip_trimming': wf_skip_trimming, 'wf_skip_deduplication': wf_skip_deduplication, 'wf_skip_multiqc': wf_skip_multiqc, 'wf_outdir': wf_outdir}, {'channel_910': channel_910})
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        result = []

    return Res_911_pre(default=result, is_skipped = not cond)

class Respost_adapter_CUSTOM_DUMPSOFTWAREVERSIONS_911_post(NamedTuple):
    yml: typing.Union[str, None]
    mqc_yml: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_911_post:
    yml: str
    mqc_yml: str
    versions: str

@task(cache=True)
def post_adapter_CUSTOM_DUMPSOFTWAREVERSIONS_911_post(
    default: List[Dataclass_911_post],
    is_skipped: bool,
) -> Respost_adapter_CUSTOM_DUMPSOFTWAREVERSIONS_911_post:
    return get_mapper_outputs(Respost_adapter_CUSTOM_DUMPSOFTWAREVERSIONS_911_post, default, is_skipped)


def _read_resources() -> Dict:
    try:
        with open(".latch/resources.json") as f:
            return json.load(f)
    except FileNotFoundError:
        return {}

def allocate_cpu(default: Dataclass_911_pre) -> int:
    res = _read_resources()
    return max(1, res['cpu_cores']) if res.get('cpu_cores') is not None else 4

def allocate_memory(default: Dataclass_911_pre) -> int:
    res = _read_resources()
    return max(1, res['memory_bytes'] // 1024**3) if res.get('memory_bytes') is not None else 16

def allocate_disk(default: Dataclass_911_pre) -> int:
    res = _read_resources()
    return max(1, res['disk_bytes'] // 1024**3) if res.get('disk_bytes') is not None else 4800

def get_resources(default: Dataclass_911_pre):
    wf_paths = {}
    wf_input = default.wf_input
    wf_input = construct_samplesheet(wf_input)
    wf_genome = default.wf_genome
    wf_save_reference = default.wf_save_reference
    wf_save_align_intermeds = default.wf_save_align_intermeds
    wf_aligner = default.wf_aligner
    wf_clip_r1 = default.wf_clip_r1
    wf_clip_r2 = default.wf_clip_r2
    wf_three_prime_clip_r1 = default.wf_three_prime_clip_r1
    wf_three_prime_clip_r2 = default.wf_three_prime_clip_r2
    wf_nextseq_trim = default.wf_nextseq_trim
    wf_cytosine_report = default.wf_cytosine_report
    wf_num_mismatches = default.wf_num_mismatches
    wf_skip_trimming = default.wf_skip_trimming
    wf_skip_deduplication = default.wf_skip_deduplication
    wf_skip_multiqc = default.wf_skip_multiqc
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_910)]

    if not True:
        download_files(channel_vals, LatchDir('latch:///methylseq-outputs'))

    flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/workflows/methylseq.nf','-lib','lib','-profile','mamba','-entry','METHYLSEQ', *flags],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"CUSTOM_DUMPSOFTWAREVERSIONS","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"yml\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"CUSTOM_DUMPSOFTWAREVERSIONS\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"mqc_yml\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"CUSTOM_DUMPSOFTWAREVERSIONS\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"CUSTOM_DUMPSOFTWAREVERSIONS\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":2}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'True',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

@custom_task(cpu=allocate_cpu, memory=allocate_memory, storage_gib=allocate_disk, pre_execute=get_resources, cache=True)
def CUSTOM_DUMPSOFTWAREVERSIONS_911(
    default: Dataclass_911_pre
) -> Dataclass_911_post:
    wf_paths = {}
    wf_input = default.wf_input
    wf_input = construct_samplesheet(wf_input)
    wf_genome = default.wf_genome
    wf_save_reference = default.wf_save_reference
    wf_save_align_intermeds = default.wf_save_align_intermeds
    wf_aligner = default.wf_aligner
    wf_clip_r1 = default.wf_clip_r1
    wf_clip_r2 = default.wf_clip_r2
    wf_three_prime_clip_r1 = default.wf_three_prime_clip_r1
    wf_three_prime_clip_r2 = default.wf_three_prime_clip_r2
    wf_nextseq_trim = default.wf_nextseq_trim
    wf_cytosine_report = default.wf_cytosine_report
    wf_num_mismatches = default.wf_num_mismatches
    wf_skip_trimming = default.wf_skip_trimming
    wf_skip_deduplication = default.wf_skip_deduplication
    wf_skip_multiqc = default.wf_skip_multiqc
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_910)]

    if not False:
        download_files(channel_vals, LatchDir('latch:///methylseq-outputs'))

    flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/workflows/methylseq.nf','-lib','lib','-profile','mamba','-entry','METHYLSEQ', *flags],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"CUSTOM_DUMPSOFTWAREVERSIONS","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"yml\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"CUSTOM_DUMPSOFTWAREVERSIONS\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"mqc_yml\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"CUSTOM_DUMPSOFTWAREVERSIONS\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"CUSTOM_DUMPSOFTWAREVERSIONS\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":2}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'False',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = json.loads(file.read_text())

    print(out_channels)

    publish_dir = None
    upload_files(out_channels, LatchDir('latch:///methylseq-outputs'), publish_dir)

    out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    return Dataclass_911_post(
        yml=out_channels.get(f"yml"),
        mqc_yml=out_channels.get(f"mqc_yml"),
        versions=out_channels.get(f"versions")
    )


class Rescollect_922(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def collect_922(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_914: typing.Union[bool, None],
    channel_911_1: typing.Union[str, None]
) -> Rescollect_922:
    cond = ((condition_914 == True) and (channel_911_1 is not None))

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = [json.loads(channel_911_1)]



        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/methylseq.nf', '-lib', 'lib', '-entry', 'METHYLSEQ', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"collect","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Rescollect_922(
        res=out_channels.get("res")
    )


class Resmix_923(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_923(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_914: typing.Union[bool, None],
    channel_921: typing.Union[str, None],
    channel_922: typing.Union[str, None]
) -> Resmix_923:
    cond = ((condition_914 == True) and (channel_921 is not None) and (channel_922 is not None))

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = [json.loads(channel_921), json.loads(channel_922)]



        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/methylseq.nf', '-lib', 'lib', '-entry', 'METHYLSEQ', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_923(
        res=out_channels.get("res")
    )


class Rescollect_924(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def collect_924(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_914: typing.Union[bool, None],
    channel_906_0: typing.Union[str, None]
) -> Rescollect_924:
    cond = ((condition_914 == True) and (channel_906_0 is not None))

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = [json.loads(channel_906_0)]



        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/methylseq.nf', '-lib', 'lib', '-entry', 'METHYLSEQ', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"collect","arguments":{"ArgumentListExpression":{"expressions":[{"ClosureExpression":{"code":{"BlockStatement":{"statements":[{"ReturnStatement":{"BinaryExpression":{"leftExpression":{"VariableExpression":"it"},"operation":"[","rightExpression":{"ConstantExpression":1}}}}],"scope":{"declaredVariables":[],"referencedClassVariables":[]},"labels":[]}},"parameters":[]}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Rescollect_924(
        res=out_channels.get("res")
    )


class ResifEmpty_925(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def ifEmpty_925(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_914: typing.Union[bool, None],
    channel_924: typing.Union[str, None]
) -> ResifEmpty_925:
    cond = ((condition_914 == True) and (channel_924 is not None))

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = [json.loads(channel_924)]



        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/methylseq.nf', '-lib', 'lib', '-entry', 'METHYLSEQ', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"ifEmpty","arguments":{"ArgumentListExpression":{"expressions":[{"ListExpression":[]}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResifEmpty_925(
        res=out_channels.get("res")
    )


class Resmix_926(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_926(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_914: typing.Union[bool, None],
    channel_923: typing.Union[str, None],
    channel_925: typing.Union[str, None]
) -> Resmix_926:
    cond = ((condition_914 == True) and (channel_923 is not None) and (channel_925 is not None))

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = [json.loads(channel_923), json.loads(channel_925)]



        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/methylseq.nf', '-lib', 'lib', '-entry', 'METHYLSEQ', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_926(
        res=out_channels.get("res")
    )


class ResifEmpty_836(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def ifEmpty_836(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_794: typing.Union[bool, None],
    channel_832_0: typing.Union[str, None]
) -> ResifEmpty_836:
    cond = ((condition_794 == True) and (channel_832_0 is not None))

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = [json.loads(channel_832_0)]



        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/bismark.nf', '-lib', 'lib', '-entry', 'BISMARK', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"ifEmpty","arguments":{"ArgumentListExpression":{"expressions":[{"ListExpression":[]}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResifEmpty_836(
        res=out_channels.get("res")
    )


class Rescollect_837(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def collect_837(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_794: typing.Union[bool, None],
    channel_809: typing.Union[str, None]
) -> Rescollect_837:
    cond = ((condition_794 == True) and (channel_809 is not None))

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = [json.loads(channel_809)]



        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/bismark.nf', '-lib', 'lib', '-entry', 'BISMARK', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"collect","arguments":{"ArgumentListExpression":{"expressions":[{"ClosureExpression":{"code":{"BlockStatement":{"statements":[{"ReturnStatement":{"BinaryExpression":{"leftExpression":{"VariableExpression":"it"},"operation":"[","rightExpression":{"ConstantExpression":1}}}}],"scope":{"declaredVariables":[],"referencedClassVariables":[]},"labels":[]}},"parameters":[]}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Rescollect_837(
        res=out_channels.get("res")
    )


class Resmix_838(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_838(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_794: typing.Union[bool, None],
    channel_836: typing.Union[str, None],
    channel_837: typing.Union[str, None]
) -> Resmix_838:
    cond = ((condition_794 == True) and (channel_836 is not None) and (channel_837 is not None))

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = [json.loads(channel_836), json.loads(channel_837)]



        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/bismark.nf', '-lib', 'lib', '-entry', 'BISMARK', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_838(
        res=out_channels.get("res")
    )


class Rescollect_839(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def collect_839(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_794: typing.Union[bool, None],
    channel_809: typing.Union[str, None]
) -> Rescollect_839:
    cond = ((condition_794 == True) and (channel_809 is not None))

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = [json.loads(channel_809)]



        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/bismark.nf', '-lib', 'lib', '-entry', 'BISMARK', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"collect","arguments":{"ArgumentListExpression":{"expressions":[{"ClosureExpression":{"code":{"BlockStatement":{"statements":[{"ReturnStatement":{"BinaryExpression":{"leftExpression":{"VariableExpression":"it"},"operation":"[","rightExpression":{"ConstantExpression":2}}}}],"scope":{"declaredVariables":[],"referencedClassVariables":[]},"labels":[]}},"parameters":[]}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Rescollect_839(
        res=out_channels.get("res")
    )


class Resmix_840(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_840(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_794: typing.Union[bool, None],
    channel_838: typing.Union[str, None],
    channel_839: typing.Union[str, None]
) -> Resmix_840:
    cond = ((condition_794 == True) and (channel_838 is not None) and (channel_839 is not None))

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = [json.loads(channel_838), json.loads(channel_839)]



        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/bismark.nf', '-lib', 'lib', '-entry', 'BISMARK', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_840(
        res=out_channels.get("res")
    )


class Rescollect_841(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def collect_841(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_794: typing.Union[bool, None],
    channel_811_3: typing.Union[str, None]
) -> Rescollect_841:
    cond = ((condition_794 == True) and (channel_811_3 is not None))

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = [json.loads(channel_811_3)]



        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/bismark.nf', '-lib', 'lib', '-entry', 'BISMARK', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"collect","arguments":{"ArgumentListExpression":{"expressions":[{"ClosureExpression":{"code":{"BlockStatement":{"statements":[{"ReturnStatement":{"BinaryExpression":{"leftExpression":{"VariableExpression":"it"},"operation":"[","rightExpression":{"ConstantExpression":1}}}}],"scope":{"declaredVariables":[],"referencedClassVariables":[]},"labels":[]}},"parameters":[]}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Rescollect_841(
        res=out_channels.get("res")
    )


class Resmix_842(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_842(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_794: typing.Union[bool, None],
    channel_840: typing.Union[str, None],
    channel_841: typing.Union[str, None]
) -> Resmix_842:
    cond = ((condition_794 == True) and (channel_840 is not None) and (channel_841 is not None))

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = [json.loads(channel_840), json.loads(channel_841)]



        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/bismark.nf', '-lib', 'lib', '-entry', 'BISMARK', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_842(
        res=out_channels.get("res")
    )


class Rescollect_843(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def collect_843(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_794: typing.Union[bool, None],
    channel_811_4: typing.Union[str, None]
) -> Rescollect_843:
    cond = ((condition_794 == True) and (channel_811_4 is not None))

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = [json.loads(channel_811_4)]



        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/bismark.nf', '-lib', 'lib', '-entry', 'BISMARK', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"collect","arguments":{"ArgumentListExpression":{"expressions":[{"ClosureExpression":{"code":{"BlockStatement":{"statements":[{"ReturnStatement":{"BinaryExpression":{"leftExpression":{"VariableExpression":"it"},"operation":"[","rightExpression":{"ConstantExpression":1}}}}],"scope":{"declaredVariables":[],"referencedClassVariables":[]},"labels":[]}},"parameters":[]}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Rescollect_843(
        res=out_channels.get("res")
    )


class Resmix_844(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_844(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_794: typing.Union[bool, None],
    channel_842: typing.Union[str, None],
    channel_843: typing.Union[str, None]
) -> Resmix_844:
    cond = ((condition_794 == True) and (channel_842 is not None) and (channel_843 is not None))

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = [json.loads(channel_842), json.loads(channel_843)]



        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/bismark.nf', '-lib', 'lib', '-entry', 'BISMARK', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_844(
        res=out_channels.get("res")
    )


class Rescollect_845(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def collect_845(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_794: typing.Union[bool, None],
    channel_820_0: typing.Union[str, None]
) -> Rescollect_845:
    cond = ((condition_794 == True) and (channel_820_0 is not None))

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = [json.loads(channel_820_0)]



        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/bismark.nf', '-lib', 'lib', '-entry', 'BISMARK', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"collect","arguments":{"ArgumentListExpression":{"expressions":[{"ClosureExpression":{"code":{"BlockStatement":{"statements":[{"ReturnStatement":{"BinaryExpression":{"leftExpression":{"VariableExpression":"it"},"operation":"[","rightExpression":{"ConstantExpression":1}}}}],"scope":{"declaredVariables":[],"referencedClassVariables":[]},"labels":[]}},"parameters":[]}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Rescollect_845(
        res=out_channels.get("res")
    )


class Resmix_846(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_846(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_794: typing.Union[bool, None],
    channel_844: typing.Union[str, None],
    channel_845: typing.Union[str, None]
) -> Resmix_846:
    cond = ((condition_794 == True) and (channel_844 is not None) and (channel_845 is not None))

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = [json.loads(channel_844), json.loads(channel_845)]



        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/bismark.nf', '-lib', 'lib', '-entry', 'BISMARK', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_846(
        res=out_channels.get("res")
    )


class ResChannel_empty___868(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_empty___868(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_794: typing.Union[bool, None],
    condition_851: typing.Union[bool, None],
    condition_867: typing.Union[bool, None]
) -> ResChannel_empty___868:
    cond = ((condition_794 == False) and (condition_851 == True) and (condition_867 == True))

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = []



        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/bwameth.nf', '-lib', 'lib', '-entry', 'BWAMETH', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"empty","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResChannel_empty___868(
        res=out_channels.get("res")
    )


class ResMerge_picard_metrics_875(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_picard_metrics_875(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_794: typing.Union[bool, None],
    condition_851: typing.Union[bool, None],
    channel_868: typing.Union[str, None],
    channel_870_2: typing.Union[str, None]
) -> ResMerge_picard_metrics_875:
    cond = ((condition_794 == False) and (condition_851 == True))

    if cond:
        res = { 'res': channel_868 or channel_870_2 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_picard_metrics_875(
        res=res.get('res')
    )


class Rescollect_884(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def collect_884(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_794: typing.Union[bool, None],
    condition_851: typing.Union[bool, None],
    channel_875: typing.Union[str, None]
) -> Rescollect_884:
    cond = ((condition_794 == False) and (condition_851 == True) and (channel_875 is not None))

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = [json.loads(channel_875)]



        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/bwameth.nf', '-lib', 'lib', '-entry', 'BWAMETH', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"collect","arguments":{"ArgumentListExpression":{"expressions":[{"ClosureExpression":{"code":{"BlockStatement":{"statements":[{"ReturnStatement":{"BinaryExpression":{"leftExpression":{"VariableExpression":"it"},"operation":"[","rightExpression":{"ConstantExpression":1}}}}],"scope":{"declaredVariables":[],"referencedClassVariables":[]},"labels":[]}},"parameters":[]}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Rescollect_884(
        res=out_channels.get("res")
    )


class Rescollect_885(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def collect_885(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_794: typing.Union[bool, None],
    condition_851: typing.Union[bool, None],
    channel_861_0: typing.Union[str, None]
) -> Rescollect_885:
    cond = ((condition_794 == False) and (condition_851 == True) and (channel_861_0 is not None))

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = [json.loads(channel_861_0)]



        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/bwameth.nf', '-lib', 'lib', '-entry', 'BWAMETH', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"collect","arguments":{"ArgumentListExpression":{"expressions":[{"ClosureExpression":{"code":{"BlockStatement":{"statements":[{"ReturnStatement":{"BinaryExpression":{"leftExpression":{"VariableExpression":"it"},"operation":"[","rightExpression":{"ConstantExpression":1}}}}],"scope":{"declaredVariables":[],"referencedClassVariables":[]},"labels":[]}},"parameters":[]}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Rescollect_885(
        res=out_channels.get("res")
    )


class Resmix_886(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_886(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_794: typing.Union[bool, None],
    condition_851: typing.Union[bool, None],
    channel_884: typing.Union[str, None],
    channel_885: typing.Union[str, None]
) -> Resmix_886:
    cond = ((condition_794 == False) and (condition_851 == True) and (channel_884 is not None) and (channel_885 is not None))

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = [json.loads(channel_884), json.loads(channel_885)]



        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/bwameth.nf', '-lib', 'lib', '-entry', 'BWAMETH', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_886(
        res=out_channels.get("res")
    )


class Rescollect_887(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def collect_887(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_794: typing.Union[bool, None],
    condition_851: typing.Union[bool, None],
    channel_863_0: typing.Union[str, None]
) -> Rescollect_887:
    cond = ((condition_794 == False) and (condition_851 == True) and (channel_863_0 is not None))

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = [json.loads(channel_863_0)]



        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/bwameth.nf', '-lib', 'lib', '-entry', 'BWAMETH', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"collect","arguments":{"ArgumentListExpression":{"expressions":[{"ClosureExpression":{"code":{"BlockStatement":{"statements":[{"ReturnStatement":{"BinaryExpression":{"leftExpression":{"VariableExpression":"it"},"operation":"[","rightExpression":{"ConstantExpression":1}}}}],"scope":{"declaredVariables":[],"referencedClassVariables":[]},"labels":[]}},"parameters":[]}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Rescollect_887(
        res=out_channels.get("res")
    )


class Resmix_888(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_888(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_794: typing.Union[bool, None],
    condition_851: typing.Union[bool, None],
    channel_886: typing.Union[str, None],
    channel_887: typing.Union[str, None]
) -> Resmix_888:
    cond = ((condition_794 == False) and (condition_851 == True) and (channel_886 is not None) and (channel_887 is not None))

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = [json.loads(channel_886), json.loads(channel_887)]



        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/bwameth.nf', '-lib', 'lib', '-entry', 'BWAMETH', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_888(
        res=out_channels.get("res")
    )


class Rescollect_889(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def collect_889(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_794: typing.Union[bool, None],
    condition_851: typing.Union[bool, None],
    channel_879_0: typing.Union[str, None]
) -> Rescollect_889:
    cond = ((condition_794 == False) and (condition_851 == True) and (channel_879_0 is not None))

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = [json.loads(channel_879_0)]



        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/bwameth.nf', '-lib', 'lib', '-entry', 'BWAMETH', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"collect","arguments":{"ArgumentListExpression":{"expressions":[{"ClosureExpression":{"code":{"BlockStatement":{"statements":[{"ReturnStatement":{"BinaryExpression":{"leftExpression":{"VariableExpression":"it"},"operation":"[","rightExpression":{"ConstantExpression":1}}}}],"scope":{"declaredVariables":[],"referencedClassVariables":[]},"labels":[]}},"parameters":[]}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Rescollect_889(
        res=out_channels.get("res")
    )


class Resmix_890(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_890(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_794: typing.Union[bool, None],
    condition_851: typing.Union[bool, None],
    channel_888: typing.Union[str, None],
    channel_889: typing.Union[str, None]
) -> Resmix_890:
    cond = ((condition_794 == False) and (condition_851 == True) and (channel_888 is not None) and (channel_889 is not None))

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = [json.loads(channel_888), json.loads(channel_889)]



        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/bwameth.nf', '-lib', 'lib', '-entry', 'BWAMETH', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_890(
        res=out_channels.get("res")
    )


class Rescollect_891(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def collect_891(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_794: typing.Union[bool, None],
    condition_851: typing.Union[bool, None],
    channel_881_0: typing.Union[str, None]
) -> Rescollect_891:
    cond = ((condition_794 == False) and (condition_851 == True) and (channel_881_0 is not None))

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = [json.loads(channel_881_0)]



        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/bwameth.nf', '-lib', 'lib', '-entry', 'BWAMETH', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"collect","arguments":{"ArgumentListExpression":{"expressions":[{"ClosureExpression":{"code":{"BlockStatement":{"statements":[{"ReturnStatement":{"BinaryExpression":{"leftExpression":{"VariableExpression":"it"},"operation":"[","rightExpression":{"ConstantExpression":1}}}}],"scope":{"declaredVariables":[],"referencedClassVariables":[]},"labels":[]}},"parameters":[]}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Rescollect_891(
        res=out_channels.get("res")
    )


class Resmix_892(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_892(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_794: typing.Union[bool, None],
    condition_851: typing.Union[bool, None],
    channel_890: typing.Union[str, None],
    channel_891: typing.Union[str, None]
) -> Resmix_892:
    cond = ((condition_794 == False) and (condition_851 == True) and (channel_890 is not None) and (channel_891 is not None))

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = [json.loads(channel_890), json.loads(channel_891)]



        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/bwameth.nf', '-lib', 'lib', '-entry', 'BWAMETH', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_892(
        res=out_channels.get("res")
    )


class ResMerge_ch_aligner_mqc_897(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_aligner_mqc_897(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    channel_846: typing.Union[str, None],
    channel_892: typing.Union[str, None]
) -> ResMerge_ch_aligner_mqc_897:
    cond = True

    if cond:
        res = { 'res': channel_846 or channel_892 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_aligner_mqc_897(
        res=res.get('res')
    )


class ResifEmpty_927(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def ifEmpty_927(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_914: typing.Union[bool, None],
    channel_897: typing.Union[str, None]
) -> ResifEmpty_927:
    cond = ((condition_914 == True) and (channel_897 is not None))

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = [json.loads(channel_897)]



        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/methylseq.nf', '-lib', 'lib', '-entry', 'METHYLSEQ', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"ifEmpty","arguments":{"ArgumentListExpression":{"expressions":[{"ListExpression":[]}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResifEmpty_927(
        res=out_channels.get("res")
    )


class Resmix_928(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_928(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_914: typing.Union[bool, None],
    channel_926: typing.Union[str, None],
    channel_927: typing.Union[str, None]
) -> Resmix_928:
    cond = ((condition_914 == True) and (channel_926 is not None) and (channel_927 is not None))

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = [json.loads(channel_926), json.loads(channel_927)]



        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/methylseq.nf', '-lib', 'lib', '-entry', 'METHYLSEQ', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_928(
        res=out_channels.get("res")
    )


class Rescollect_932(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def collect_932(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_914: typing.Union[bool, None],
    condition_931: typing.Union[bool, None],
    channel_785_1: typing.Union[str, None]
) -> Rescollect_932:
    cond = ((condition_914 == True) and (condition_931 == True) and (channel_785_1 is not None))

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = [json.loads(channel_785_1)]



        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/methylseq.nf', '-lib', 'lib', '-entry', 'METHYLSEQ', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"collect","arguments":{"ArgumentListExpression":{"expressions":[{"ClosureExpression":{"code":{"BlockStatement":{"statements":[{"ReturnStatement":{"BinaryExpression":{"leftExpression":{"VariableExpression":"it"},"operation":"[","rightExpression":{"ConstantExpression":1}}}}],"scope":{"declaredVariables":[],"referencedClassVariables":[]},"labels":[]}},"parameters":[]}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Rescollect_932(
        res=out_channels.get("res")
    )


class Resmix_933(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_933(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_914: typing.Union[bool, None],
    condition_931: typing.Union[bool, None],
    channel_928: typing.Union[str, None],
    channel_932: typing.Union[str, None]
) -> Resmix_933:
    cond = ((condition_914 == True) and (condition_931 == True) and (channel_928 is not None) and (channel_932 is not None))

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = [json.loads(channel_928), json.loads(channel_932)]



        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/methylseq.nf', '-lib', 'lib', '-entry', 'METHYLSEQ', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_933(
        res=out_channels.get("res")
    )


class ResMerge_ch_multiqc_files_934(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_multiqc_files_934(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_914: typing.Union[bool, None],
    channel_933: typing.Union[str, None],
    channel_928: typing.Union[str, None]
) -> ResMerge_ch_multiqc_files_934:
    cond = ((condition_914 == True))

    if cond:
        res = { 'res': channel_933 or channel_928 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_multiqc_files_934(
        res=res.get('res')
    )


class Rescollect_935(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def collect_935(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_914: typing.Union[bool, None],
    channel_779_1: typing.Union[str, None]
) -> Rescollect_935:
    cond = ((condition_914 == True) and (channel_779_1 is not None))

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = [json.loads(channel_779_1)]



        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/methylseq.nf', '-lib', 'lib', '-entry', 'METHYLSEQ', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"collect","arguments":{"ArgumentListExpression":{"expressions":[{"ClosureExpression":{"code":{"BlockStatement":{"statements":[{"ReturnStatement":{"BinaryExpression":{"leftExpression":{"VariableExpression":"it"},"operation":"[","rightExpression":{"ConstantExpression":1}}}}],"scope":{"declaredVariables":[],"referencedClassVariables":[]},"labels":[]}},"parameters":[]}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Rescollect_935(
        res=out_channels.get("res")
    )


class ResifEmpty_936(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def ifEmpty_936(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_914: typing.Union[bool, None],
    channel_935: typing.Union[str, None]
) -> ResifEmpty_936:
    cond = ((condition_914 == True) and (channel_935 is not None))

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = [json.loads(channel_935)]



        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/methylseq.nf', '-lib', 'lib', '-entry', 'METHYLSEQ', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"ifEmpty","arguments":{"ArgumentListExpression":{"expressions":[{"ListExpression":[]}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResifEmpty_936(
        res=out_channels.get("res")
    )


class Resmix_937(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_937(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_914: typing.Union[bool, None],
    channel_934: typing.Union[str, None],
    channel_936: typing.Union[str, None]
) -> Resmix_937:
    cond = ((condition_914 == True) and (channel_934 is not None) and (channel_936 is not None))

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = [json.loads(channel_934), json.loads(channel_936)]



        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/methylseq.nf', '-lib', 'lib', '-entry', 'METHYLSEQ', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_937(
        res=out_channels.get("res")
    )


class Rescollect_938(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def collect_938(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_914: typing.Union[bool, None],
    channel_937: typing.Union[str, None]
) -> Rescollect_938:
    cond = ((condition_914 == True) and (channel_937 is not None))

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = [json.loads(channel_937)]



        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/methylseq.nf', '-lib', 'lib', '-entry', 'METHYLSEQ', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"collect","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Rescollect_938(
        res=out_channels.get("res")
    )


class ResChannel_fromPath__checkIfExists_true____projectDir_assets_multiq_690(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_fromPath__checkIfExists_true____projectDir_assets_multiq_690(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str
) -> ResChannel_fromPath__checkIfExists_true____projectDir_assets_multiq_690:
    cond = True

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = []

        download_files(channel_vals, LatchDir('latch:///methylseq-outputs'))

        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/methylseq.nf', '-lib', 'lib', '-entry', 'METHYLSEQ', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"fromPath","arguments":{"ArgumentListExpression":{"expressions":[{"MapExpression":[{"MapEntryExpression":{"keyExpression":{"ConstantExpression":"checkIfExists"},"valueExpression":{"ConstantExpression":true}}}]},{"GStringExpression":{"verbatimText":"$projectDir/assets/multiqc_config.yml","strings":[{"ConstantExpression":""},{"ConstantExpression":"/assets/multiqc_config.yml"}],"values":[{"VariableExpression":"projectDir"}]}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())

        upload_files(out_channels, LatchDir('latch:///methylseq-outputs'))

        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResChannel_fromPath__checkIfExists_true____projectDir_assets_multiq_690(
        res=out_channels.get("res")
    )


class RestoList_939(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def toList_939(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_914: typing.Union[bool, None],
    channel_690: typing.Union[str, None]
) -> RestoList_939:
    cond = ((condition_914 == True) and (channel_690 is not None))

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = [json.loads(channel_690)]



        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/methylseq.nf', '-lib', 'lib', '-entry', 'METHYLSEQ', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"toList","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return RestoList_939(
        res=out_channels.get("res")
    )


class Resparams_multiqc_config_691(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def params_multiqc_config_691(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str
) -> Resparams_multiqc_config_691:
    cond = True

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = []



        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/methylseq.nf', '-lib', 'lib', '-entry', 'METHYLSEQ', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"NotExpression":{"NotExpression":{"BooleanExpression":{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"multiqc_config"}}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resparams_multiqc_config_691(
        res=out_channels.get("res")
    )


class Resconditional_params_multiqc_config_692(NamedTuple):
    condition: typing.Union[bool, None]

@task(cache=True)
def conditional_params_multiqc_config_692(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    channel_691: typing.Union[str, None]
) -> Resconditional_params_multiqc_config_692:
    cond = ((channel_691 is not None))

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = [json.loads(channel_691)]



        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/methylseq.nf', '-lib', 'lib', '-entry', 'METHYLSEQ', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"condition"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"condition\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'condition': None}

    res = out_channels.get("condition")

    if res is not None:
        res = get_boolean_value(res)

    return Resconditional_params_multiqc_config_692(condition=res)


class ResChannel_fromPath__checkIfExists_true___params_multiqc_config__693(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_fromPath__checkIfExists_true___params_multiqc_config__693(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_692: typing.Union[bool, None]
) -> ResChannel_fromPath__checkIfExists_true___params_multiqc_config__693:
    cond = ((condition_692 == True))

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = []

        download_files(channel_vals, LatchDir('latch:///methylseq-outputs'))

        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/methylseq.nf', '-lib', 'lib', '-entry', 'METHYLSEQ', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"fromPath","arguments":{"ArgumentListExpression":{"expressions":[{"MapExpression":[{"MapEntryExpression":{"keyExpression":{"ConstantExpression":"checkIfExists"},"valueExpression":{"ConstantExpression":true}}}]},{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"multiqc_config"}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())

        upload_files(out_channels, LatchDir('latch:///methylseq-outputs'))

        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResChannel_fromPath__checkIfExists_true___params_multiqc_config__693(
        res=out_channels.get("res")
    )


class ResChannel_empty___694(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_empty___694(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_692: typing.Union[bool, None]
) -> ResChannel_empty___694:
    cond = ((condition_692 == False))

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = []



        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/methylseq.nf', '-lib', 'lib', '-entry', 'METHYLSEQ', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"empty","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResChannel_empty___694(
        res=out_channels.get("res")
    )


class Res_params_multiqc_config____Channel_fromPath__checkIfExists_true___695(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def _params_multiqc_config____Channel_fromPath__checkIfExists_true___695(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    channel_693: typing.Union[str, None],
    channel_694: typing.Union[str, None]
) -> Res_params_multiqc_config____Channel_fromPath__checkIfExists_true___695:
    cond = True

    if cond:
        res = { 'res': channel_693 or channel_694 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return Res_params_multiqc_config____Channel_fromPath__checkIfExists_true___695(
        res=res.get('res')
    )


class RestoList_940(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def toList_940(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_914: typing.Union[bool, None],
    channel_695: typing.Union[str, None]
) -> RestoList_940:
    cond = ((condition_914 == True) and (channel_695 is not None))

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = [json.loads(channel_695)]



        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/methylseq.nf', '-lib', 'lib', '-entry', 'METHYLSEQ', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"toList","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return RestoList_940(
        res=out_channels.get("res")
    )


class Resparams_multiqc_logo_696(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def params_multiqc_logo_696(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str
) -> Resparams_multiqc_logo_696:
    cond = True

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = []



        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/methylseq.nf', '-lib', 'lib', '-entry', 'METHYLSEQ', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"NotExpression":{"NotExpression":{"BooleanExpression":{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"multiqc_logo"}}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resparams_multiqc_logo_696(
        res=out_channels.get("res")
    )


class Resconditional_params_multiqc_logo_697(NamedTuple):
    condition: typing.Union[bool, None]

@task(cache=True)
def conditional_params_multiqc_logo_697(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    channel_696: typing.Union[str, None]
) -> Resconditional_params_multiqc_logo_697:
    cond = ((channel_696 is not None))

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = [json.loads(channel_696)]



        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/methylseq.nf', '-lib', 'lib', '-entry', 'METHYLSEQ', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"condition"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"condition\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'condition': None}

    res = out_channels.get("condition")

    if res is not None:
        res = get_boolean_value(res)

    return Resconditional_params_multiqc_logo_697(condition=res)


class ResChannel_fromPath__checkIfExists_true___params_multiqc_logo__698(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_fromPath__checkIfExists_true___params_multiqc_logo__698(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_697: typing.Union[bool, None]
) -> ResChannel_fromPath__checkIfExists_true___params_multiqc_logo__698:
    cond = ((condition_697 == True))

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = []

        download_files(channel_vals, LatchDir('latch:///methylseq-outputs'))

        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/methylseq.nf', '-lib', 'lib', '-entry', 'METHYLSEQ', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"fromPath","arguments":{"ArgumentListExpression":{"expressions":[{"MapExpression":[{"MapEntryExpression":{"keyExpression":{"ConstantExpression":"checkIfExists"},"valueExpression":{"ConstantExpression":true}}}]},{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"multiqc_logo"}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())

        upload_files(out_channels, LatchDir('latch:///methylseq-outputs'))

        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResChannel_fromPath__checkIfExists_true___params_multiqc_logo__698(
        res=out_channels.get("res")
    )


class ResChannel_empty___699(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_empty___699(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_697: typing.Union[bool, None]
) -> ResChannel_empty___699:
    cond = ((condition_697 == False))

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = []



        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/methylseq.nf', '-lib', 'lib', '-entry', 'METHYLSEQ', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"empty","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResChannel_empty___699(
        res=out_channels.get("res")
    )


class Res_params_multiqc_logo____Channel_fromPath__checkIfExists_true___p_700(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def _params_multiqc_logo____Channel_fromPath__checkIfExists_true___p_700(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    channel_698: typing.Union[str, None],
    channel_699: typing.Union[str, None]
) -> Res_params_multiqc_logo____Channel_fromPath__checkIfExists_true___p_700:
    cond = True

    if cond:
        res = { 'res': channel_698 or channel_699 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return Res_params_multiqc_logo____Channel_fromPath__checkIfExists_true___p_700(
        res=res.get('res')
    )


class RestoList_941(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def toList_941(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_914: typing.Union[bool, None],
    channel_700: typing.Union[str, None]
) -> RestoList_941:
    cond = ((condition_914 == True) and (channel_700 is not None))

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = [json.loads(channel_700)]



        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/methylseq.nf', '-lib', 'lib', '-entry', 'METHYLSEQ', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"toList","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return RestoList_941(
        res=out_channels.get("res")
    )


@dataclass
class Dataclass_942_pre:
    wf_input: typing.List[Sample]
    wf_genome: Genome
    wf_save_reference: bool
    wf_save_align_intermeds: bool
    wf_aligner: Aligner
    wf_clip_r1: int
    wf_clip_r2: int
    wf_three_prime_clip_r1: int
    wf_three_prime_clip_r2: int
    wf_nextseq_trim: int
    wf_cytosine_report: bool
    wf_num_mismatches: float
    wf_skip_trimming: bool
    wf_skip_deduplication: bool
    wf_skip_multiqc: bool
    wf_outdir: str
    channel_938: str
    channel_939: str
    channel_940: str
    channel_941: str


class Res_942_pre(NamedTuple):
    default: typing.List[Dataclass_942_pre]
    is_skipped: bool

@task(cache=True)
def pre_adapter_MULTIQC_942_pre(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_914: typing.Union[bool, None],
    channel_938: typing.Union[str, None],
    channel_939: typing.Union[str, None],
    channel_940: typing.Union[str, None],
    channel_941: typing.Union[str, None]
) -> Res_942_pre:
    cond = ((condition_914 == True) and (channel_938 is not None) and (channel_939 is not None) and (channel_940 is not None) and (channel_941 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_942_pre, {'wf_input': wf_input, 'wf_genome': wf_genome, 'wf_save_reference': wf_save_reference, 'wf_save_align_intermeds': wf_save_align_intermeds, 'wf_aligner': wf_aligner, 'wf_clip_r1': wf_clip_r1, 'wf_clip_r2': wf_clip_r2, 'wf_three_prime_clip_r1': wf_three_prime_clip_r1, 'wf_three_prime_clip_r2': wf_three_prime_clip_r2, 'wf_nextseq_trim': wf_nextseq_trim, 'wf_cytosine_report': wf_cytosine_report, 'wf_num_mismatches': wf_num_mismatches, 'wf_skip_trimming': wf_skip_trimming, 'wf_skip_deduplication': wf_skip_deduplication, 'wf_skip_multiqc': wf_skip_multiqc, 'wf_outdir': wf_outdir}, {'channel_938': channel_938, 'channel_939': channel_939, 'channel_940': channel_940, 'channel_941': channel_941})
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        result = []

    return Res_942_pre(default=result, is_skipped = not cond)

class Respost_adapter_MULTIQC_942_post(NamedTuple):
    report: typing.Union[str, None]
    data: typing.Union[str, None]
    plots: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_942_post:
    report: str
    data: str
    plots: str
    versions: str

@task(cache=True)
def post_adapter_MULTIQC_942_post(
    default: List[Dataclass_942_post],
    is_skipped: bool,
) -> Respost_adapter_MULTIQC_942_post:
    return get_mapper_outputs(Respost_adapter_MULTIQC_942_post, default, is_skipped)


def _read_resources() -> Dict:
    try:
        with open(".latch/resources.json") as f:
            return json.load(f)
    except FileNotFoundError:
        return {}

def allocate_cpu(default: Dataclass_942_pre) -> int:
    res = _read_resources()
    return max(1, res['cpu_cores']) if res.get('cpu_cores') is not None else 4

def allocate_memory(default: Dataclass_942_pre) -> int:
    res = _read_resources()
    return max(1, res['memory_bytes'] // 1024**3) if res.get('memory_bytes') is not None else 16

def allocate_disk(default: Dataclass_942_pre) -> int:
    res = _read_resources()
    return max(1, res['disk_bytes'] // 1024**3) if res.get('disk_bytes') is not None else 4800

def get_resources(default: Dataclass_942_pre):
    wf_paths = {}
    wf_input = default.wf_input
    wf_input = construct_samplesheet(wf_input)
    wf_genome = default.wf_genome
    wf_save_reference = default.wf_save_reference
    wf_save_align_intermeds = default.wf_save_align_intermeds
    wf_aligner = default.wf_aligner
    wf_clip_r1 = default.wf_clip_r1
    wf_clip_r2 = default.wf_clip_r2
    wf_three_prime_clip_r1 = default.wf_three_prime_clip_r1
    wf_three_prime_clip_r2 = default.wf_three_prime_clip_r2
    wf_nextseq_trim = default.wf_nextseq_trim
    wf_cytosine_report = default.wf_cytosine_report
    wf_num_mismatches = default.wf_num_mismatches
    wf_skip_trimming = default.wf_skip_trimming
    wf_skip_deduplication = default.wf_skip_deduplication
    wf_skip_multiqc = default.wf_skip_multiqc
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_938),json.loads(default.channel_939),json.loads(default.channel_940),json.loads(default.channel_941)]

    if not True:
        download_files(channel_vals, LatchDir('latch:///methylseq-outputs'))

    flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/workflows/methylseq.nf','-lib','lib','-profile','mamba','-entry','METHYLSEQ', *flags],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"MULTIQC","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"report\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"MULTIQC\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"data\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"MULTIQC\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"plots\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"MULTIQC\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":2}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"MULTIQC\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":3}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'True',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

@custom_task(cpu=allocate_cpu, memory=allocate_memory, storage_gib=allocate_disk, pre_execute=get_resources, cache=True)
def MULTIQC_942(
    default: Dataclass_942_pre
) -> Dataclass_942_post:
    wf_paths = {}
    wf_input = default.wf_input
    wf_input = construct_samplesheet(wf_input)
    wf_genome = default.wf_genome
    wf_save_reference = default.wf_save_reference
    wf_save_align_intermeds = default.wf_save_align_intermeds
    wf_aligner = default.wf_aligner
    wf_clip_r1 = default.wf_clip_r1
    wf_clip_r2 = default.wf_clip_r2
    wf_three_prime_clip_r1 = default.wf_three_prime_clip_r1
    wf_three_prime_clip_r2 = default.wf_three_prime_clip_r2
    wf_nextseq_trim = default.wf_nextseq_trim
    wf_cytosine_report = default.wf_cytosine_report
    wf_num_mismatches = default.wf_num_mismatches
    wf_skip_trimming = default.wf_skip_trimming
    wf_skip_deduplication = default.wf_skip_deduplication
    wf_skip_multiqc = default.wf_skip_multiqc
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_938),json.loads(default.channel_939),json.loads(default.channel_940),json.loads(default.channel_941)]

    if not False:
        download_files(channel_vals, LatchDir('latch:///methylseq-outputs'))

    flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/workflows/methylseq.nf','-lib','lib','-profile','mamba','-entry','METHYLSEQ', *flags],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"MULTIQC","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"report\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"MULTIQC\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"data\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"MULTIQC\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"plots\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"MULTIQC\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":2}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"MULTIQC\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":3}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'False',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = json.loads(file.read_text())

    print(out_channels)

    publish_dir = None
    upload_files(out_channels, LatchDir('latch:///methylseq-outputs'), publish_dir)

    out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    return Dataclass_942_post(
        report=out_channels.get(f"report"),
        data=out_channels.get(f"data"),
        plots=out_channels.get(f"plots"),
        versions=out_channels.get(f"versions")
    )


class RestoList_943(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def toList_943(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_914: typing.Union[bool, None],
    channel_942_0: typing.Union[str, None]
) -> RestoList_943:
    cond = ((condition_914 == True) and (channel_942_0 is not None))

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = [json.loads(channel_942_0)]



        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/methylseq.nf', '-lib', 'lib', '-entry', 'METHYLSEQ', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"toList","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return RestoList_943(
        res=out_channels.get("res")
    )


class Resmix_944(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_944(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    condition_914: typing.Union[bool, None],
    channel_908: typing.Union[str, None],
    channel_942_3: typing.Union[str, None]
) -> Resmix_944:
    cond = ((condition_914 == True) and (channel_908 is not None) and (channel_942_3 is not None))

    if cond:
        wf_paths = {}
        wf_input = construct_samplesheet(wf_input)


        channel_vals = [json.loads(channel_908), json.loads(channel_942_3)]



        flags = get_flags(wf_paths, input=wf_input, genome=wf_genome, save_reference=wf_save_reference, save_align_intermeds=wf_save_align_intermeds, aligner=wf_aligner, clip_r1=wf_clip_r1, clip_r2=wf_clip_r2, three_prime_clip_r1=wf_three_prime_clip_r1, three_prime_clip_r2=wf_three_prime_clip_r2, nextseq_trim=wf_nextseq_trim, cytosine_report=wf_cytosine_report, num_mismatches=wf_num_mismatches, skip_trimming=wf_skip_trimming, skip_deduplication=wf_skip_deduplication, skip_multiqc=wf_skip_multiqc, outdir=wf_outdir)

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/methylseq.nf', '-lib', 'lib', '-entry', 'METHYLSEQ', *flags],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_944(
        res=out_channels.get("res")
    )


class ResMerge_ch_versions_945(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_versions_945(
    wf_input: typing.List[Sample],
    wf_genome: Genome,
    wf_save_reference: bool,
    wf_save_align_intermeds: bool,
    wf_aligner: Aligner,
    wf_clip_r1: int,
    wf_clip_r2: int,
    wf_three_prime_clip_r1: int,
    wf_three_prime_clip_r2: int,
    wf_nextseq_trim: int,
    wf_cytosine_report: bool,
    wf_num_mismatches: float,
    wf_skip_trimming: bool,
    wf_skip_deduplication: bool,
    wf_skip_multiqc: bool,
    wf_outdir: str,
    channel_944: typing.Union[str, None],
    channel_908: typing.Union[str, None]
) -> ResMerge_ch_versions_945:
    cond = True

    if cond:
        res = { 'res': channel_944 or channel_908 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_versions_945(
        res=res.get('res')
    )
